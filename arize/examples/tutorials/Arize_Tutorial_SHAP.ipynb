{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Arize HelloWorld.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arize SHAP Values Tutorial\n",
    "This tutorial demonstrates how to use the Arize Python SDK to send SHAP values (SHapley Additive exPlanations) into the Arize platform.\n",
    "\n",
    "The following cells mirror what you will find in the Arize HelloWorld tutorial, but also adds an example of how you can generate SHAP values using the [SHAP Python library](https://shap.readthedocs.io) and log them in the Arize platform for further inspection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/Arize-ai/client_python/blob/main/arize/examples/tutorials/Arize_Tutorial_SHAP.ipynb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "heVdVKyS87je",
    "tags": []
   },
   "source": [
    "!wget https://storage.googleapis.com/arize-assets/tutorials/b_open_source_dataset.csv"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0RkvKyk579NL"
   },
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "model_data = pd.read_csv('b_open_source_dataset.csv',delimiter=\";\",header='infer')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C1kAUcHQ8J4u"
   },
   "source": [
    "model_data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X6TdLP3O8Lzu"
   },
   "source": [
    "#Converting object type data into numeric type using One-Hot encoding method which is\n",
    "#majorly used for XGBoost (for better accuracy) [Applicable only for non numeric categorical features]\n",
    "data_new = pd.get_dummies(model_data, columns=['job','marital',\n",
    "                                         'education','default',\n",
    "                                         'housing','loan',\n",
    "                                         'contact','month',\n",
    "                                         'poutcome'])\n",
    "#pd is instance of pandas. Using get_dummies method we can directly convert any type of data into One-Hot encoded format."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GqlbH6r09r-u"
   },
   "source": [
    "#Since y is a class variable we will have to convert it into binary format. (Since 2 unique class values)\n",
    "data_new.y.replace(('yes', 'no'), (1, 0), inplace=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K9HNuzp39zCc",
    "tags": []
   },
   "source": [
    "#Spliting data as X -> features and y -> class variable\n",
    "data_y = pd.DataFrame(data_new['y'])\n",
    "data_X = data_new.drop(['y'], axis=1)\n",
    "print(data_X.columns)\n",
    "print(data_y.columns)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "szo3q73g90nK",
    "tags": []
   },
   "source": [
    "#Dividing records in training and testing sets along with its shape (rows, cols)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.3, random_state=2, stratify=data_y)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6dgs3r6w_uL1"
   },
   "source": [
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "# create a default XGBoost classifier\n",
    "model = XGBClassifier(n_estimators=500, random_state=0)\n",
    "# define the eval set and metric\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h4IoGWha_w4N"
   },
   "source": [
    "#Create an XGB classifier and train it on 70% of the data set.\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "clf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VCc4vBhJ-1cG",
    "tags": []
   },
   "source": [
    "clf.fit(X_train, y_train.values.ravel())\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w3J13qMf_JKt"
   },
   "source": [
    "y_pred = clf.predict(X_test)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mCLbUKXyBbwT",
    "tags": []
   },
   "source": [
    "# final model assessment\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "pred_test = clf.predict(X_test)\n",
    "pred_train = clf.predict(X_train)\n",
    "print('Train Accuracy: ', accuracy_score(y_train, pred_train))\n",
    "print('Test Accuraccy: ', accuracy_score(y_test, pred_test))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test,pred_test,digits=5))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y3uvLfPCBoY8",
    "tags": []
   },
   "source": [
    "!pip install ../../../"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EKxpdY6lAxfr",
    "tags": []
   },
   "source": [
    "#Creating feature data to send\n",
    "#X_Test is 1 hot encoded lets get features pre: 1-hot to send back more human readable\n",
    "readable_features = model_data.loc[X_test.index].drop(labels=['y'],axis=1)\n",
    "\n",
    "print(readable_features)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TbeWx2bMCCrr"
   },
   "source": [
    "from arize.api import Client\n",
    "#ORGINIZATION KEY - SUPPLIED BY ARIZE\n",
    "org_key = 'ORG_KEY'\n",
    "#API KEY - GENERATED IN ARIZE ACCOUNT OR SUPPLIED\n",
    "api_key = 'API_KEY'\n",
    "\n",
    "arize_client = Client(organization_key=org_key, api_key=api_key)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dSRwvmjdDXrA"
   },
   "source": [
    "import datetime\n",
    "model_name = 'colab_model_class'\n",
    "#This colab generates a different Model ID every run / you don't have to do it this way & can send traffic by build\n",
    "datetime_rightnow = datetime.datetime.today()\n",
    "model_version_id_now = 'test_' + datetime_rightnow.strftime('%m_%d_%Y__%H_%M_%S')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "36MEMy03tEel"
   },
   "source": [
    "#Turn Predictions into strings - classification 1/0\n",
    "pred = pd.DataFrame([str(x) for x in pred_test]) # (going to add to SDK to handle this)\n",
    "ids = pd.DataFrame([str(x) for x in X_test.index]) \n",
    "tfuture = arize_client.log_bulk_predictions(model_id=model_name, model_version=model_version_id_now,\n",
    "                            features=readable_features, prediction_ids=ids,\n",
    "                            prediction_labels=pred)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1ahXjv9_tW2_"
   },
   "source": [
    "tfuture[0].result()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d0WKHHeuAkkn"
   },
   "source": [
    "#Y_test is a DataFrame convert to str for classification versus 1/0 (going to add to SDK to handle this)\n",
    "actuals_df = y_test.astype(str)\n",
    "tfuture = arize_client.log_bulk_actuals(model_id=model_name, prediction_ids=ids, actual_labels=actuals_df)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfuture[0].result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells illustrate how you can generate and send SHAP values into the Arize platform. Note that the example generates the SHAP values for all of the predictions at once and then passes them to the Python SDK in bulk. The Python SDK also supports passing individual sets of SHAP values per prediction when generating predictions one-by-one in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Generate SHAP values for the X_test prediction set \n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Convert the generated array of SHAP values into a Pandas dataframe with the model features as the column names\n",
    "shap_df = pd.DataFrame(shap_values, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log all of the SHAP values along with their correspording prediction ids to Arize\n",
    "tfuture_shap = arize_client.log_bulk_shap_values(model_id=model_name, prediction_ids=ids, shap_values=shap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfuture[0].result()"
   ]
  }
 ]
}

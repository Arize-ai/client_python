{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Arize_Tutorial_Delayed_SHAP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit ('env-01': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "b72fb6e7218a7ba9b0ea2d899c6447cf37e05630d8cf381a78bf2982129f31d5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Arize Tutorial: Logging Predictions First, Then Logging SHAP After\n",
        "\n",
        "Let's get started on using Arize! ‚ú®\n",
        "\n",
        "Arize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models.\n",
        "\n",
        "In this tutorial, we will using our Score Categorical model for predicting if someone has breast cancer or not to showcase one of the many ways of using the `arize.pandas.log` to log (i.e. send) data from a Pandas dataframe to the Arize platform.\n",
        "\n",
        "### Why Use Multiple `log` Calls ü§î\n",
        "Sometimes, we want to `log` predictions during production and store our `prediction_ids` right away for model tracking, but we don't have ground truth labels avaliable until much later. Othertimes, they become avaliable at the same time. Depending on your situation, you may need to use `log` differently.\n",
        "\n",
        "**In this notebook, we will show how to `log` using `prediction_ids` to log only your predictions, then follow up to log the delayed SHAP values üöÄ**\n",
        "\n",
        "For more of our usage case tutorials, visit our other [example tutorials](https://arize.gitbook.io/arize/examples).\n",
        "\n",
        "In general, if any part if your data (including `features`) become avaliable later and you can't log them right away, Arize provides the functionality of matching them through using `prediction_ids`, which is a required input for all `log` calls.\n",
        "\n",
        "### Running This Notebook\n",
        "1. Save a copy in Google Drive for yourself.\n",
        "2. Step through each section below, pressing play on the code blocks to run the cells.\n",
        "3. In Step 2, use your own Org and API key from your Arize account.\n"
      ],
      "metadata": {
        "id": "SJEgUhyh-k4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load Data and Build Model"
      ],
      "metadata": {
        "id": "aUUdm-QfF8xG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "###############################################################################\n",
        "# 1 Load data and split data\n",
        "data = datasets.load_breast_cancer()\n",
        "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# NOTE: We need to set y.astype(str) since BINARY expected non-integer.\n",
        "X, y = X.astype(np.float32), y.astype(str)\n",
        "X, y = pd.DataFrame(X, columns=data[\"feature_names\"]), pd.Series(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)\n",
        "\n",
        "###############################################################################\n",
        "# 2 Fit a simple logistic regression model\n",
        "clf = LogisticRegression(max_iter=3000, verbose=False).fit(X_train, y_train)\n",
        "\n",
        "# 3 Use the model to generate predictions\n",
        "def predict(model, X):\n",
        "    proba = model.predict_proba(X)\n",
        "    pred = pd.Series((str(np.argmax(p)) for p in proba), index=X.index)\n",
        "    score = pd.Series((p[1] for p in proba), index=X.index)\n",
        "    return pred, score\n",
        "\n",
        "\n",
        "y_train_pred, y_train_pred_score = predict(clf, X_train)\n",
        "y_val_pred, y_val_pred_score = predict(clf, X_val)\n",
        "y_test_pred, y_test_pred_score = predict(clf, X_test)\n",
        "\n",
        "print(\"Step 1 ‚úÖ: Load Data & Build Model Done!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "OWSc0hFn-Y4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Import and Setup Arize Client\n",
        "First, copy the Arize `API_KEY` and `ORG_KEY` from your admin page linked below!\n",
        "\n",
        "[![Button_Open.png](https://storage.googleapis.com/arize-assets/fixtures/Button_Open.png)](https://app.arize.com/admin)\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.jpeg\" width=\"600\">"
      ],
      "metadata": {
        "id": "PcVdPGFkGF2t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install -q arize\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import ModelTypes, Environments\n",
        "\n",
        "ORGANIZATION_KEY = \"ORGANIZATION_KEY\"\n",
        "API_KEY = \"API_KEY\"\n",
        "arize_client = Client(organization_key=ORGANIZATION_KEY, api_key=API_KEY)\n",
        "\n",
        "model_id = \"logging_tutorial_delayed_shap\"\n",
        "model_version = \"1.0\"\n",
        "model_type = ModelTypes.SCORE_CATEGORICAL\n",
        "\n",
        "if ORGANIZATION_KEY == \"ORGANIZATION_KEY\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE ORGANIZATION AND/OR API_KEY\")\n",
        "else:\n",
        "    print(\"Step 2 ‚úÖ: Import and Setup Arize Client Done! Now we can start using Arize!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "btoJ-OY5DW5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logging Tutorial\n",
        "We'll use the following helper functions to generate prediction IDs and timestamps to simulate a production environment."
      ],
      "metadata": {
        "id": "ZtuHsrFvg6vf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Prediction ID is required for all datasets\n",
        "def generate_prediction_ids(X):\n",
        "    return pd.Series((str(uuid.uuid4()) for _ in range(len(X))), index=X.index)\n",
        "\n",
        "\n",
        "# OPTIONAL: We can directly specify when inferences were made\n",
        "def simulate_production_timestamps(X, days=30):\n",
        "    t = datetime.now()\n",
        "    current_ts, earlier_ts = t.timestamp(), (t - timedelta(days=days)).timestamp()\n",
        "    return pd.Series(np.linspace(earlier_ts, current_ts, num=len(X)), index=X.index)"
      ],
      "outputs": [],
      "metadata": {
        "id": "qrasyM6llqW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Logging Predictions\n",
        "We can log predictions to Arize first, and match various other values such as actuals, explainability (i.e SHAP), or even features later.\n",
        "\n",
        "In this example, we will use `arize.pandas.log` to only log the `prediction_labels` and `features` directly assuming you had it avaliable. This is to simulate predictions making in production as features become avaliable.\n",
        "\n",
        "You can see our `arize.pandas.log()` documentations by clicking the button below.\n",
        "\n",
        "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)"
      ],
      "metadata": {
        "id": "TDjRIV2ijdbs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# For this example we need to first assemble our data into a pandas DataFrame\n",
        "production_dataset = X_test.join(\n",
        "    pd.DataFrame(\n",
        "        {\n",
        "            \"prediction_id\": generate_prediction_ids(X_test),\n",
        "            \"prediction_ts\": simulate_production_timestamps(X_test, days=30),\n",
        "            \"prediction_label\": y_test_pred,\n",
        "            \"prediction_score\": y_test_pred_score,\n",
        "        }\n",
        "    )\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "XgpD4pBgjitA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three easy steps to log a `pandas.DataFrame`. See [docs](https://docs.arize.com/arize/api-reference/python-sdk/arize.pandas) for more details.\n",
        "\n",
        "1.   Define `Schema` to designate column names\n",
        "2.   Call `arize.pandas.log()`\n",
        "3.   Check `response.status_code`"
      ],
      "metadata": {
        "id": "kIcdyLl0lIz4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
        "production_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",  # REQUIRED\n",
        "    timestamp_column_name=\"prediction_ts\",\n",
        "    prediction_label_column_name=\"prediction_label\",\n",
        "    prediction_score_column_name=\"prediction_score\",\n",
        "    feature_column_names=data[\"feature_names\"],\n",
        ")\n",
        "\n",
        "# arize_client.log returns a Response object from Python's requests module\n",
        "response = arize_client.log(\n",
        "    dataframe=production_dataset,\n",
        "    schema=production_schema,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=model_type,\n",
        "    environment=Environments.PRODUCTION,\n",
        "    path=\"inferences.bin\",\n",
        "    batch_id=None,\n",
        ")\n",
        "\n",
        "# If successful, the server will return a status_code of 200\n",
        "if response.status_code != 200:\n",
        "    print(\n",
        "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        f\"Step 3 ‚úÖ: You have successfully logged {len(production_dataset)} data points to Arize!\"\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZrglsFw_lIPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4.1: Generating and Formatting SHAP Values\n",
        "**SHAP (SHapley Additive exPlanations)** is a game theoretic approach to explain the output of any machine learning model.\n",
        "\n",
        "For more in-depth usage of the `shap` library, visit [SHAP Core Explainers](https://shap-lrjball.readthedocs.io/en/docs_update/generated/shap.Explainer.html) and pick an explainer specific to your machine learning model. `shap.Explainer` is the default explainer that will matches model type, but you can specify your own type. For example, you can choose to use for example `shap.TreeExplainer`, but it won't work on models such as `sklearn.LinearModel.LogisticRegression`.\n",
        "\n",
        "We create this helper function `get_shap_values` to format the data and/or create visualizations for our shap values. We will store our results in a `pd.DataFrame` with matching columns for logging later."
      ],
      "metadata": {
        "id": "Q3tPwyCfz_Ic"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install -q shap\n",
        "import shap\n",
        "\n",
        "\n",
        "def get_shap_values(model, X_train, X_test, ExplainerType, show_graph=False):\n",
        "    # Linear Models directly generate in the shape loggable to Arize\n",
        "    if ExplainerType == shap.LinearExplainer:\n",
        "        explainer = shap.LinearExplainer(model, X_train)\n",
        "        shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "    # Tree Model Explainers\n",
        "    elif ExplainerType == shap.TreeExplainer:\n",
        "        explainer = shap.TreeExplainer(model, X_train)\n",
        "        shap_values = np.array(explainer.shap_values(X_test)[1])\n",
        "\n",
        "    # Model Agnostic Explainers\n",
        "    else:\n",
        "        explainer = shap.KernelExplainer(model.predict_proba, X_train)\n",
        "        shap_values = np.array(explainer.shap_values(X_test)[1])\n",
        "\n",
        "    # When not in production, it can be helpful to check graphs for feature explainability\n",
        "    if show_graph:\n",
        "        shap.summary_plot(shap_values, X_test, feature_names=data[\"feature_names\"])\n",
        "\n",
        "    return pd.DataFrame(shap_values, columns=data[\"feature_names\"], index=X_test.index)\n",
        "\n",
        "\n",
        "shap_values = get_shap_values(\n",
        "    clf, X_train, X_test, shap.LinearExplainer, show_graph=True\n",
        ")\n",
        "print(\n",
        "    f\"Part 4.1 ‚úÖ: If no errors showed up, you have just generated {len(shap_values)} shap values!\"\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "h-dQnToOz83C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4.2: Matching Explainability\n",
        "Sometimes, we want to log explainability metric later than during production time when we logged our prediction. If `log` calls are made separately, the shape, length, and order of the `prediction_labels` and `shap_values` do not need to match.\n",
        "\n",
        "**IMPORTANT:** To match a SHAP value with a prediction, both MUST be logged with the same `prediction_id`"
      ],
      "metadata": {
        "id": "1jilaPIDzhyn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# A mapping is needed to pair up each SHAP value column with its feature name\n",
        "shap_values_column_names_mapping = {\n",
        "    f\"{feat}\": f\"{feat}_shap\" for feat in data[\"feature_names\"]\n",
        "}\n",
        "\n",
        "# Here we create a SHAP values DataFrame with matching prediction_ids\n",
        "shap_dataset = production_dataset[[\"prediction_id\"]].join(\n",
        "    shap_values.rename(columns=shap_values_column_names_mapping)\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "s4BG_p_lzhMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three easy steps to log a `pandas.DataFrame`. See [docs](https://docs.arize.com/arize/api-reference/python-sdk/arize.pandas) for more details.\n",
        "\n",
        "1.   Define `Schema` to designate column names\n",
        "2.   Call `arize.pandas.log()`\n",
        "3.   Check `response.status_code`"
      ],
      "metadata": {
        "id": "viJ998Edk_Dh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
        "shap_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",  # REQUIRED\n",
        "    shap_values_column_names=shap_values_column_names_mapping,\n",
        "    feature_column_names=[],\n",
        ")\n",
        "\n",
        "# arize_client.log returns a Response object from Python's requests module\n",
        "response = arize_client.log(\n",
        "    dataframe=shap_dataset,\n",
        "    schema=shap_schema,\n",
        "    path=\"inferences.bin\",\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=model_type,\n",
        "    environment=Environments.PRODUCTION,\n",
        "    batch_id=None,\n",
        ")\n",
        "\n",
        "# If successful, the server will return a status_code of 200\n",
        "if response.status_code != 200:\n",
        "    print(\n",
        "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        f\"Step 4.2 ‚úÖ: You have successfully logged {len(shap_dataset)} data points to Arize!\"\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "vINXJNlCk-up"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview\n",
        "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
        "- Automated ML monitoring and model monitoring\n",
        "- Workflows to troubleshoot model performance\n",
        "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
        "- Model prediction cohort analysis\n",
        "- Pre-deployment model validation\n",
        "- Integrated model explainability\n",
        "\n",
        "### Website\n",
        "Visit Us At: https://arize.com/model-monitoring/\n",
        "\n",
        "### Additional Resources\n",
        "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
        "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
        "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
        "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
        "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
        "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
        "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
        "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
        "\n",
        "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "T3Ptaip9JLgY"
      }
    }
  ]
}
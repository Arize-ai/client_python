{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "511HJ-fHWnFv"
      },
      "source": [
        "## Send 1 million inferences with 200 features to Arize in chunks of 100K records at a time\n",
        "\n",
        "Included is sample code of how you can split large dataframes into smaller chunks prior to sending to Arize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1POG6BEfQnMG",
        "outputId": "951dfab9-b511-4962-c134-a4aaa36c6dd3"
      },
      "outputs": [],
      "source": [
        "!pip -q install arize\n",
        "\n",
        "import datetime\n",
        "import random\n",
        "import time\n",
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import Environments, ModelTypes\n",
        "\n",
        "import arize\n",
        "\n",
        "print(f\"Step 1 ✅: Install Arize, you are using sdk version: {arize.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZlF6OiQQsq5"
      },
      "source": [
        "### Set up Arize Client with your API and Space Keys\n",
        "You can find your `API_KEY` and `SPACE_KEY` by navigating to the settings page in your workspace as shown below (only space admins can see the keys). \n",
        "\n",
        "\n",
        "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btoJ-OY5DW5K",
        "outputId": "6a4949f0-84a4-420d-e958-402afa45199b"
      },
      "outputs": [],
      "source": [
        "SPACE_KEY = \"SPACE_KEY\"\n",
        "API_KEY = \"API_KEY\"\n",
        "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
        "\n",
        "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"❌ NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else:\n",
        "    print(\"Step 2 ✅: Import and Setup Arize Client Done! Now we can start using Arize!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uohiUGbQRH6t"
      },
      "source": [
        "### Sample functions to emulate a large dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWSc0hFn-Y4W"
      },
      "outputs": [],
      "source": [
        "def simulate_production_timestamps(X, days=30):\n",
        "    t = datetime.now()\n",
        "    current_ts, earlier_ts = t.timestamp(), (t - timedelta(days=days)).timestamp()\n",
        "    return pd.Series(np.linspace(earlier_ts, current_ts, num=len(X)), index=X.index)\n",
        "\n",
        "\n",
        "def get_feature_columns(num_cols):\n",
        "    cols = []\n",
        "    for i in range(0, num_cols):\n",
        "        cols.append(f\"feat_{i}\")\n",
        "    return cols\n",
        "\n",
        "\n",
        "def get_shap_columns(num_cols):\n",
        "    cols = []\n",
        "    for i in range(0, num_cols):\n",
        "        cols.append(f\"feat_{i}\")\n",
        "    return cols\n",
        "\n",
        "\n",
        "def generate_prediction_ids(X):\n",
        "    return pd.Series((str(uuid.uuid4()) for _ in range(len(X))), index=X.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRnLGH4pRkTS"
      },
      "source": [
        "### Generate random data for a DataFrames which we will chunk on a later step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBfeSnxzUYnP"
      },
      "outputs": [],
      "source": [
        "LABELS = [\"Item 1\", \"Item 2\", \"Item 3\"]\n",
        "\n",
        "NUM_RECORDS = 1_000_000\n",
        "NUM_FEATS = 200\n",
        "\n",
        "feat_names = get_feature_columns(NUM_FEATS)\n",
        "\n",
        "features = pd.DataFrame(\n",
        "    np.random.random(size=(NUM_RECORDS, NUM_FEATS)),\n",
        "    columns=feat_names,\n",
        ")\n",
        "\n",
        "shap_values_column_names_mapping = {f\"{feat}\": f\"{feat}_shap\" for feat in feat_names}\n",
        "\n",
        "shap_columns = [shap_values_column_names_mapping.get(n, n) for n in feat_names]\n",
        "\n",
        "shap_values = pd.DataFrame(\n",
        "    np.random.random(size=(NUM_RECORDS, NUM_FEATS)),\n",
        "    columns=shap_columns,\n",
        ")\n",
        "shap_values.rename(columns=shap_values_column_names_mapping)\n",
        "\n",
        "pLabels = [random.choice(LABELS) for i in range(NUM_RECORDS)]\n",
        "pred_labels = pd.DataFrame(\n",
        "    np.random.random(size=(NUM_RECORDS, 2)),\n",
        "    columns=[\"prediction_label\", \"prediction_score\"],\n",
        ")\n",
        "pred_labels[\"prediction_label\"] = pLabels\n",
        "\n",
        "aLabels = [random.choice(LABELS) for i in range(NUM_RECORDS)]\n",
        "actual_labels = pd.DataFrame(\n",
        "    np.random.random(size=(NUM_RECORDS, 2)), columns=[\"actual_label\", \"actual_score\"]\n",
        ")\n",
        "actual_labels[\"actual_label\"] = aLabels\n",
        "\n",
        "ids = pd.DataFrame(\n",
        "    [str(uuid.uuid4()) for _ in range(NUM_RECORDS)], columns=[\"prediction_id\"]\n",
        ")\n",
        "\n",
        "inferences = pd.concat([features, pred_labels, ids, actual_labels, shap_values], axis=1)\n",
        "\n",
        "inferences[\"prediction_ts\"] = simulate_production_timestamps(inferences, 364)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1bxrUwyR4mU"
      },
      "source": [
        "### Send data to Arize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrLDXNSvLuSo",
        "outputId": "419ce163-5a7e-49e5-cdc8-223ca7819a41"
      },
      "outputs": [],
      "source": [
        "production_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",\n",
        "    timestamp_column_name=\"prediction_ts\",\n",
        "    prediction_label_column_name=\"prediction_label\",\n",
        "    prediction_score_column_name=\"prediction_score\",\n",
        "    actual_label_column_name=\"actual_label\",\n",
        "    actual_score_column_name=\"actual_score\",\n",
        "    feature_column_names=feat_names,\n",
        "    shap_values_column_names=shap_values_column_names_mapping,\n",
        ")\n",
        "\n",
        "### We will chuck the dataframe into 100K records at a time\n",
        "start = 0\n",
        "stop = 100_000\n",
        "step = stop\n",
        "\n",
        "model_id = \"model_to_split\"\n",
        "model_version = \"1.0\"\n",
        "model_type = ModelTypes.SCORE_CATEGORICAL\n",
        "\n",
        "while stop <= len(inferences):\n",
        "    try:\n",
        "        response = arize_client.log(\n",
        "            dataframe=inferences.iloc[start:stop],\n",
        "            schema=production_schema,\n",
        "            model_id=model_id,\n",
        "            model_version=model_version,\n",
        "            model_type=model_type,\n",
        "            environment=Environments.PRODUCTION,\n",
        "        )\n",
        "        # If successful, the server will return a status_code of 200\n",
        "        if response.status_code != 200:\n",
        "            ## In the case a 200 was not received, you'll want to try the chunk again, so we dont increment the start/stop variables\n",
        "            print(\n",
        "                f\"❌ Logging failed with response code {response.status_code}, {response.text}, will try again\"\n",
        "            )\n",
        "        else:\n",
        "            print(\n",
        "                f\"✅ You have successfully logged records from index {start} to {stop} to Arize!\"\n",
        "            )\n",
        "            ## If we got a 200 ACK, we can move on to the next chunk\n",
        "            start = start + step\n",
        "            stop = stop + step\n",
        "    except Exception as err:\n",
        "        print(\n",
        "            f\"An exception occurred when logging index {start} to {stop}, trying again\\n Exception: {err}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check Data Ingestion Information\n",
        "\n",
        "Data will be available in the UI in about 10 minutes after it was received. If data from a new model is sent, the model will be reflected almost immediately in the Arize platform. However, you will not see data yet. To verify data has been sent correctly and is being processed, we recommend that you check our Data Ingestion tab.\n",
        "\n",
        "You will be able to see the predictions, actuals, and feature importances that have been sent in the last week, last day or last 30 minutes.\n",
        "\n",
        "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below.\n",
        "\n",
        "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Overview\n",
        "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
        "- Automated ML monitoring and model monitoring\n",
        "- Workflows to troubleshoot model performance\n",
        "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
        "- Model prediction cohort analysis\n",
        "- Pre-deployment model validation\n",
        "- Integrated model explainability\n",
        "\n",
        "### Website\n",
        "Visit Us At: https://arize.com/model-monitoring/\n",
        "\n",
        "### Additional Resources\n",
        "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
        "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
        "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
        "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
        "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
        "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
        "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
        "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
        "\n",
        "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Chunking Large Datasets.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b72fb6e7218a7ba9b0ea2d899c6447cf37e05630d8cf381a78bf2982129f31d5"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJEgUhyh-k4-"
   },
   "source": [
    "# Arize Tutorial: Logging Predictions Only\n",
    "\n",
    "Let's get started on using Arize! ‚ú®\n",
    "\n",
    "Arize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models.\n",
    "\n",
    "In this tutorial, we will using our Score Categorical model for predicting if someone has breast cancer or not to showcase one of the many ways of using the `arize.pandas.log` to log (i.e. send) data from a Pandas dataframe to the Arize platform.\n",
    "\n",
    "### Why Use Multiple `log` Calls ü§î\n",
    "Sometimes, we want to `log` predictions during production and store our `prediction_id` right away for model tracking, but we don't have ground truth labels avaliable until much later. Othertimes, they become avaliable at the same time. Depending on your situation, you may need to use `log` differently.\n",
    "\n",
    "**In this notebook, we will show how to `log` using `prediction_id` to log only your predictions üöÄ**\n",
    "\n",
    "For more of our usage case tutorials, visit our other [example tutorials](https://arize.gitbook.io/arize/examples).\n",
    "\n",
    "In many use cases, ground truths/actuals may come at a later time and can't be logged with your predictions. Arize provides the functionality of latently logging those delayed actuals by matching them later through the `prediction_id`, which is a required input for all `log` calls. Note that we can also append tags/meta data to these latent actuals.\n",
    "\n",
    "In addition, if you'd like to add new features to your model there is no extra work involved. Arize will automatically detect new features being logged with your predictions and will surface them in the UI.\n",
    "\n",
    "### Running This Notebook\n",
    "1. Save a copy in Google Drive for yourself.\n",
    "2. Step through each section below, pressing play on the code blocks to run the cells.\n",
    "3. In Step 2, use your own Space and API key from your Arize account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUUdm-QfF8xG"
   },
   "source": [
    "## Step 1: Load Data and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWSc0hFn-Y4W"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "###############################################################################\n",
    "# 1 Load data and split data\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# NOTE: We need to set y.astype(str) since BINARY expected non-integer.\n",
    "X, y = X.astype(np.float32), y.astype(str)\n",
    "X, y = pd.DataFrame(X, columns=data[\"feature_names\"]), pd.Series(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "###############################################################################\n",
    "# 2 Fit a simple logistic regression model\n",
    "clf = LogisticRegression(max_iter=3000, verbose=False).fit(X_train, y_train)\n",
    "\n",
    "# 3 Use the model to generate predictions\n",
    "def predict(model, X):\n",
    "    proba = model.predict_proba(X)\n",
    "    pred = pd.Series((str(np.argmax(p)) for p in proba), index=X.index)\n",
    "    score = pd.Series((p[1] for p in proba), index=X.index)\n",
    "    return pred, score\n",
    "\n",
    "\n",
    "y_train_pred, y_train_pred_score = predict(clf, X_train)\n",
    "y_val_pred, y_val_pred_score = predict(clf, X_val)\n",
    "y_test_pred, y_test_pred_score = predict(clf, X_test)\n",
    "\n",
    "print(\"Step 1 ‚úÖ: Load Data & Build Model Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcVdPGFkGF2t"
   },
   "source": [
    "## Step 2: Import and Setup Arize Client\n",
    "You can find your `API_KEY` and `SPACE_KEY` by navigating to the settings page in your workspace as shown below (only space admins can see the keys).\n",
    "\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btoJ-OY5DW5K"
   },
   "outputs": [],
   "source": [
    "!pip install -q arize\n",
    "from arize.pandas.logger import Client, Schema\n",
    "from arize.utils.types import ModelTypes, Environments\n",
    "\n",
    "SPACE_KEY = \"SPACE_KEY\"\n",
    "API_KEY = \"API_KEY\"\n",
    "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
    "\n",
    "model_id = \"logging_tutorial_pred_only\"\n",
    "model_version = \"1.0\"\n",
    "model_type = ModelTypes.SCORE_CATEGORICAL\n",
    "\n",
    "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
    "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
    "else:\n",
    "    print(\"Step 2 ‚úÖ: Import and Setup Arize Client Done! Now we can start using Arize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtuHsrFvg6vf"
   },
   "source": [
    "# Logging Tutorial\n",
    "We'll use the following helper functions to generate prediction IDs and timestamps to simulate a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrasyM6llqW2"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Prediction ID is required for all datasets\n",
    "def generate_prediction_ids(X):\n",
    "    return pd.Series((str(uuid.uuid4()) for _ in range(len(X))), index=X.index)\n",
    "\n",
    "\n",
    "# OPTIONAL: We can directly specify when inferences were made\n",
    "def simulate_production_timestamps(X, days=30):\n",
    "    t = datetime.now()\n",
    "    current_ts, earlier_ts = t.timestamp(), (t - timedelta(days=days)).timestamp()\n",
    "    return pd.Series(np.linspace(earlier_ts, current_ts, num=len(X)), index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDjRIV2ijdbs"
   },
   "source": [
    "## Step 3: Logging Predictions\n",
    "We can log predictions to Arize first, and match various other values such as actuals, explainability (i.e SHAP), or even features later.\n",
    "\n",
    "In this example, we will use `arize.pandas.log()` to only log the `prediction_labels` and `features` directly assuming you had it avaliable. This is to simulate predictions making in production as data become avaliable.\n",
    "\n",
    "You can see our `arize.pandas.log()` documentations by clicking the button below.\n",
    "\n",
    "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E36Ah_8cu9T-"
   },
   "outputs": [],
   "source": [
    "# For this example we need to first assemble our data into a pandas DataFrame\n",
    "production_dataset = X_test.join(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"prediction_id\": generate_prediction_ids(X_test),\n",
    "            \"prediction_ts\": simulate_production_timestamps(X_test),\n",
    "            \"prediction_label\": y_test_pred,\n",
    "            \"prediction_score\": y_test_pred_score,\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA-VuQEIvA4-"
   },
   "source": [
    "Three easy steps to log a `pandas.DataFrame`. See [docs](https://docs.arize.com/arize/api-reference/python-sdk/arize.pandas) for more details.\n",
    "\n",
    "1.   Define `Schema` to designate column names\n",
    "2.   Call `arize.pandas.log()`\n",
    "3.   Check `response.status_code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbgV8q_o6jzH"
   },
   "outputs": [],
   "source": [
    "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
    "production_schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",  # REQUIRED\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"prediction_label\",\n",
    "    prediction_score_column_name=\"prediction_score\",\n",
    "    feature_column_names=data[\"feature_names\"],\n",
    ")\n",
    "\n",
    "# arize_client.log returns a Response object from Python's requests module\n",
    "response = arize_client.log(\n",
    "    dataframe=production_dataset,\n",
    "    schema=production_schema,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    environment=Environments.PRODUCTION,\n",
    ")\n",
    "\n",
    "# If successful, the server will return a status_code of 200\n",
    "if response.status_code != 200:\n",
    "    print(\n",
    "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"Step 3 ‚úÖ: You have successfully logged {len(production_dataset)} data points to Arize!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data Ingestion Information\n",
    "\n",
    "Data will be available in the UI in about 10 minutes after it was received. If data from a new model is sent, the model will be reflected almost immediately in the Arize platform. However, you will not see data yet. To verify data has been sent correctly and is being processed, we recommend that you check our Data Ingestion tab.\n",
    "\n",
    "You will be able to see the predictions, actuals, and feature importances that have been sent in the last week, last day or last 30 minutes.\n",
    "\n",
    "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7ui0hLT6jzI"
   },
   "source": [
    "### Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Arize_Tutorial_Pred_Only.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "b72fb6e7218a7ba9b0ea2d899c6447cf37e05630d8cf381a78bf2982129f31d5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Arize Tutorial: 1-Hot Encoding Decomposition\n",
        "\n",
        "Let's get started on using Arize! ✨\n",
        "\n",
        "Arize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models.\n",
        "\n",
        "This is a simple example on how to decompose 1-hot encoded features and/or shap values into their original multi-class state prior to sending data to Arize.\n",
        "\n",
        "In this case, we have features, predicions, actuals, and their respective SHAP values all in a single dataframe. In the case where your data is not colocated, you can send each peice (prediction, actual, and SHAP values) separatedly as long as the `prediction_id` variable from a SHAP and/or Actual latent call matches a previously sent Prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKFOHukVLFS4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "## Sample data set with features, predictions, actuals and shap values\n",
        "df = pd.read_csv('https://storage.googleapis.com/arize-assets/fixtures/example_shap_data.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Here is an example of data where some features being 1-hot encoded while others are not\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare feature names\n",
        "\n",
        "Since we need the same feature names as the original prediction inputs, we'll need to \"un-encode\" the 1-hot encoded features in this case addr_state and term features were 1-hot encoded, so we create a dictionary where keys are the decomposed names and the values are all the 1-hot encoded names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWSO5kSzOKEC"
      },
      "outputs": [],
      "source": [
        "## This helper function decomposes the 1-hot encoded columns into their original names.\n",
        "## We calculate the sum of the SHAP values for each origial column from each 1-hot column\n",
        "## Reference: https://github.com/slundberg/shap/issues/679#issuecomment-508575567\n",
        "def map_shap(shap_df, one_h_map):\n",
        "  for key, value in one_h_map.items():\n",
        "    shap_df[key] = shap_df[value].sum(axis=1)\n",
        "    shap_df = shap_df.drop(columns=value)\n",
        "  return shap_df\n",
        "\n",
        "encoding_map = {\"term_shap\": ['term_one_h_0_shap', 'term_one_h_1_shap', 'term_one_h_2_shap','term_one_h_3_shap'],\n",
        "              \"addr_state_shap\": ['addr_state_one_h_0_shap', 'addr_state_one_h_1_shap', 'addr_state_one_h_2_shap']}\n",
        "\n",
        "shap_values = map_shap(df, encoding_map)\n",
        "shap_values.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAs7AeGPWoQa"
      },
      "outputs": [],
      "source": [
        "## Features names for your model\n",
        "feature_names = ['installment', 'grade', 'home_ownership', 'annual_income',\n",
        "       'verification_status', 'pymnt_plan', 'purpose', 'inq_last_6mths',\n",
        "       'mths_since_last_delinq', 'mths_since_last_record', 'open_acc',\n",
        "       'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'fico_score',\n",
        "       'fico_range', 'term', 'addr_state']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKiRBGZbcmdh"
      },
      "outputs": [],
      "source": [
        "## Helper function to get name of shap columns\n",
        "def get_shap_column_names(feature_names):\n",
        "  shap_column_names = []\n",
        "  for name in feature_names:\n",
        "    shap_column_names.append(f\"{name}_shap\")\n",
        "  return shap_column_names\n",
        "\n",
        "shap_column_names = get_shap_column_names(feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Arize client\n",
        "You can find your `API_KEY` and `SPACE_KEY` by navigating to the settings page in your workspace as shown below (only space admins can see the keys). \n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3scW8Hs5O4Ac",
        "outputId": "2efe8107-c5bb-4e1f-b455-a6f48ad9a5b9"
      },
      "outputs": [],
      "source": [
        "!pip install -q arize\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import ModelTypes, Environments\n",
        "\n",
        "SPACE_KEY = \"SPACE_KEY\"\n",
        "API_KEY = \"API_KEY\"\n",
        "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
        "\n",
        "model_id=\"Example-SHAP-Decomposition\"\n",
        "model_version=\"1.0\"\n",
        "model_type=ModelTypes.CATEGORICAL\n",
        "\n",
        "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"❌ NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else:\n",
        "    print(\"✅ Import and Setup Arize Client Done! Now we can start using Arize!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA580ZxMYKwH",
        "outputId": "c8a4b392-b917-414c-a5ec-f2ec5c1df25e"
      },
      "outputs": [],
      "source": [
        "response = arize_client.log(\n",
        "    dataframe=shap_values,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=model_type,\n",
        "    environment=Environments.PRODUCTION,\n",
        "    schema = Schema(\n",
        "        prediction_id_column_name=\"ids\",\n",
        "        prediction_label_column_name=\"prediction\",\n",
        "        actual_label_column_name=\"actual\",\n",
        "        feature_column_names=feature_names,\n",
        "        shap_values_column_names=dict(zip(feature_names, shap_column_names)),\n",
        "    )\n",
        ")\n",
        "\n",
        "if response.status_code != 200:\n",
        "    print(f\"❌ logging failed with response code {response.status_code}, {response.text}\")\n",
        "else:\n",
        "    print(f\"✅ logging completed with response code {response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check Data Ingestion Information\n",
        "Data will be available in the UI in about 10 minutes after it was received. If data from a new model is sent, the model will be reflected almost immediately in the Arize platform. However, you will not see data yet. To verify data has been sent correctly and is being processed, we recommend that you check our Data Ingestion tab.\n",
        "\n",
        "You will be able to see the predictions, actuals, and feature importances that have been sent in the last week, last day or last 30 minutes.\n",
        "\n",
        "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below.\n",
        "\n",
        "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Overview\n",
        "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
        "- Automated ML monitoring and model monitoring\n",
        "- Workflows to troubleshoot model performance\n",
        "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
        "- Model prediction cohort analysis\n",
        "- Pre-deployment model validation\n",
        "- Integrated model explainability\n",
        "\n",
        "### Website\n",
        "Visit Us At: https://arize.com/model-monitoring/\n",
        "\n",
        "### Additional Resources\n",
        "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
        "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
        "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
        "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
        "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
        "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
        "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
        "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
        "\n",
        "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Example_One_Hot_Encoding_Shap_Decomposition.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "59f3145cc67fcda0343c2852f1f97113a2e6e98841e887156424448e7071ad54"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}

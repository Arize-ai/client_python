{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJEgUhyh-k4-"
      },
      "source": [
        "# Arize Tutorial: SHAP Value For Every Model\n",
        "\n",
        "Let's get started on using Arize! ‚ú®\n",
        "\n",
        "Arize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models.\n",
        "\n",
        "**SHAP (SHapley Additive exPlanations)** is a game theoretic approach to explain the output of any machine learning model.\n",
        "\n",
        "For more in-depth usage of the `shap` library, visit [SHAP Core Explainers](https://shap-lrjball.readthedocs.io/en/docs_update/generated/shap.Explainer.html) and read more about the math behind each type of explainer. `shap.Explainer` is the default explainer that will match any model type, but you can specify your own type. For example, you can choose to use for example `shap.TreeExplainer`, but it won't work on models such as `sklearn.LinearModel.LogisticRegression`.\n",
        "\n",
        "In this notebook, we will show you which `shap.ExplainerType` to use for some common ML Models üöÄ.\n",
        "\n",
        "### Running This Notebook\n",
        "1. Save a copy in Google Drive for yourself.\n",
        "2. Step through each section below, pressing play on the code blocks to run the cells.\n",
        "3. In Step 2, use your own Space and API key from your Arize account."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4GUtUIvOes-"
      },
      "source": [
        "## Part 0: SHAP API Quick-Start\n",
        "If you are trying to start right away using the `shap` library for logging to Arize, here are some quick codes snippits for you to copy.\n",
        "\n",
        "\n",
        "| Model                     | Explainer                                                | Generating Arguments    |   |   |\n",
        "|:-|:-|:-|---|---|\n",
        "| sklearn.LinearModel       | exp = shap.LinearExplainer(model, X_train)               | exp.shap_values(X_test) |   |   |\n",
        "| sklearn.ensembles         | exp = shap.TreeExplainer(model, X_train)                 | exp.shap_values(X_test) |   |   |\n",
        "| Neural and Model Agnostic | exp = shap.KernelExplainer(model.predict_proba, X_train) | exp.shap_values(X_test) |   |   |\n",
        "\n",
        "First, remember to `pip install shap` and `import shap`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7Ibw6QJx0O-"
      },
      "outputs": [],
      "source": [
        "!pip install -q shap # Run this if you do not have shap installed\n",
        "import shap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUUdm-QfF8xG"
      },
      "source": [
        "##  Part 1: Load Data and Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWSc0hFn-Y4W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1 Load data and split data\n",
        "data = datasets.load_breast_cancer()\n",
        "\n",
        "# NOTE: We need to set y.astype(str) since BINARY expected non-integer.\n",
        "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
        "X, y = X.astype(np.float32), y.astype(str)\n",
        "X, y = pd.DataFrame(X, columns=data[\"feature_names\"]), pd.Series(y)\n",
        "\n",
        "# For SVM/Neural Example - shrink data for faster example runtime\n",
        "X = X.sample(n=100, random_state=1)\n",
        "y = y.sample(n=100, random_state=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)\n",
        "\n",
        "\n",
        "def predict(model, X):\n",
        "    pred_proba = model.predict_proba(X)\n",
        "    pred = pd.Series((str(np.argmax(p)) for p in pred_proba), index=X.index)\n",
        "    pred_score = pd.Series((p[1] for p in pred_proba), index=X.index)\n",
        "    return pred, pred_score\n",
        "\n",
        "\n",
        "print(\"Step 1 ‚úÖ: Load Data Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcVdPGFkGF2t"
      },
      "source": [
        "## Step 2: Import and Setup Arize Client\n",
        "First, copy the Arize `API_KEY` and `SPACE_KEY` from your admin page linked below!\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btoJ-OY5DW5K"
      },
      "outputs": [],
      "source": [
        "!pip install -q arize\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import ModelTypes, Environments\n",
        "\n",
        "SPACE_KEY = \"SPACE_KEY\"\n",
        "API_KEY = \"API_KEY\"\n",
        "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
        "\n",
        "model_id = \"breast_cancer_prediction_SHAP\"\n",
        "model_type = ModelTypes.SCORE_CATEGORICAL\n",
        "\n",
        "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else:\n",
        "    print(\"Step 2 ‚úÖ: Import and Setup Arize Client Done! Now we can start using Arize!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To1Tk3Ozl4TC"
      },
      "source": [
        "# Logging During Production\n",
        "We'll use the following helper functions to generate prediction IDs and timestamps to simulate a production environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrasyM6llqW2"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Prediction ID is required for logging any dataset\n",
        "def generate_prediction_ids(X):\n",
        "    return pd.Series((str(uuid.uuid4()) for _ in range(len(X_test))), index=X.index)\n",
        "\n",
        "\n",
        "# OPTIONAL: We can directly specify when inferences were made\n",
        "def simulate_production_timestamps(X, days=30):\n",
        "    t = datetime.now()\n",
        "    current_t, earlier_t = t.timestamp(), (t - timedelta(days=days)).timestamp()\n",
        "    return pd.Series(np.linspace(earlier_t, current_t, num=len(X)), index=X.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyXDMw5_yGRc"
      },
      "source": [
        "## Part 3: Arize Quick-Start Helper\n",
        "This section of code helps fit your code to the shape Arize needs to `log` onto our platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmjBGKFDx1jc"
      },
      "outputs": [],
      "source": [
        "def get_shap_values(model, X_train, X_test, ExplainerType, show_graph=False):\n",
        "    # Linear Models directly generate in the shape loggable to Arize\n",
        "    if ExplainerType == shap.LinearExplainer:\n",
        "        explainer = shap.LinearExplainer(model, X_train)\n",
        "        shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "    # Tree Model Explainers\n",
        "    elif ExplainerType == shap.TreeExplainer:\n",
        "        explainer = shap.TreeExplainer(model, X_train)\n",
        "        shap_values = np.array(explainer.shap_values(X_test)[1])\n",
        "\n",
        "    # Model Agnostic Explainers\n",
        "    else:\n",
        "        explainer = shap.KernelExplainer(model.predict_proba, X_train)\n",
        "        shap_values = np.array(explainer.shap_values(X_test)[1])\n",
        "\n",
        "    # When not in production, it can be helpful to check graphs for feature explainability\n",
        "    if show_graph:\n",
        "        shap.summary_plot(shap_values, X_test, feature_names=data[\"feature_names\"])\n",
        "\n",
        "    return pd.DataFrame(shap_values, columns=data[\"feature_names\"], index=X_test.index)\n",
        "\n",
        "\n",
        "print(\"Step 3 ‚úÖ: Helper functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQke5G1Lt8zr"
      },
      "source": [
        "## Part 4: Linear Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0qZmaSgU7lp"
      },
      "outputs": [],
      "source": [
        "model_version = f\"{model_id}-linear-model-1.0\"\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
        "y_test_pred, y_test_pred_score = predict(logreg, X_test)\n",
        "shap_values = get_shap_values(logreg, X_train, X_test, shap.LinearExplainer)\n",
        "\n",
        "# For this example we need to first assemble our data into a pandas DataFrame\n",
        "\n",
        "# A mapping is needed to pair up each SHAP value column with its feature name\n",
        "shap_values_column_names_mapping = {\n",
        "    f\"{feat}\": f\"{feat}_shap\" for feat in data[\"feature_names\"]\n",
        "}\n",
        "\n",
        "production_dataset = X_test.join(\n",
        "    [\n",
        "        pd.DataFrame(\n",
        "            {\n",
        "                \"prediction_id\": generate_prediction_ids(X_test),\n",
        "                \"prediction_ts\": simulate_production_timestamps(X_test),\n",
        "                \"prediction_label\": y_test_pred,\n",
        "                \"prediction_score\": y_test_pred_score,\n",
        "                \"actual_label\": y_test,\n",
        "            }\n",
        "        ),\n",
        "        shap_values.rename(columns=shap_values_column_names_mapping),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wFXlqfyQ-81"
      },
      "source": [
        "Three easy steps to log a `pandas.DataFrame`. See [docs](https://docs.arize.com/arize/api-reference/python-sdk/arize.pandas) for more details.\n",
        "\n",
        "1.   Define `Schema` to designate column names\n",
        "2.   Call `arize.pandas.log()`\n",
        "3.   Check `response.status_code`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcX8xIsDQ-82"
      },
      "outputs": [],
      "source": [
        "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
        "production_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",  # REQUIRED\n",
        "    timestamp_column_name=\"prediction_ts\",\n",
        "    prediction_label_column_name=\"prediction_label\",\n",
        "    prediction_score_column_name=\"prediction_score\",\n",
        "    actual_label_column_name=\"actual_label\",\n",
        "    feature_column_names=data[\"feature_names\"],\n",
        "    shap_values_column_names=shap_values_column_names_mapping,\n",
        ")\n",
        "\n",
        "# arize_client.log returns a Response object from Python's requests module\n",
        "response = arize_client.log(\n",
        "    dataframe=production_dataset,\n",
        "    schema=production_schema,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=model_type,\n",
        "    environment=Environments.PRODUCTION,\n",
        ")\n",
        "\n",
        "# If successful, the server will return a status_code of 200\n",
        "if response.status_code != 200:\n",
        "    print(\n",
        "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        f\"Step 4 ‚úÖ: You have successfully logged {len(production_dataset)} data points to Arize!\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EVt41vdt_GU"
      },
      "source": [
        "## Part 5: Tree Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq7oe9xNN_pu"
      },
      "outputs": [],
      "source": [
        "model_version = f\"{model_id}-tree-model-1.0\"\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier().fit(X_train, y_train)\n",
        "y_test_pred, y_test_pred_score = predict(clf, X_test)\n",
        "shap_values = get_shap_values(clf, X_train, X_test, shap.TreeExplainer)\n",
        "\n",
        "# For this example we need to first assemble our data into a pandas DataFrame\n",
        "\n",
        "# A mapping is needed to pair up each SHAP value column with its feature name\n",
        "shap_values_column_names_mapping = {\n",
        "    f\"{feat}\": f\"{feat}_shap\" for feat in data[\"feature_names\"]\n",
        "}\n",
        "\n",
        "production_dataset = X_test.join(\n",
        "    [\n",
        "        pd.DataFrame(\n",
        "            {\n",
        "                \"prediction_id\": generate_prediction_ids(X_test),\n",
        "                \"prediction_ts\": simulate_production_timestamps(X_test),\n",
        "                \"prediction_label\": y_test_pred,\n",
        "                \"prediction_score\": y_test_pred_score,\n",
        "                \"actual_label\": y_test,\n",
        "            }\n",
        "        ),\n",
        "        shap_values.rename(columns=shap_values_column_names_mapping),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xblVajkLQ-82"
      },
      "source": [
        "Three easy steps to log a `pandas.DataFrame`. See [docs](https://docs.arize.com/arize/api-reference/python-sdk/arize.pandas) for more details.\n",
        "\n",
        "1.   Define `Schema` to designate column names\n",
        "2.   Call `arize.pandas.log()`\n",
        "3.   Check `response.status_code`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0F_pBupQ-83"
      },
      "outputs": [],
      "source": [
        "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
        "production_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",  # REQUIRED\n",
        "    timestamp_column_name=\"prediction_ts\",\n",
        "    prediction_label_column_name=\"prediction_label\",\n",
        "    prediction_score_column_name=\"prediction_score\",\n",
        "    actual_label_column_name=\"actual_label\",\n",
        "    feature_column_names=data[\"feature_names\"],\n",
        "    shap_values_column_names=shap_values_column_names_mapping,\n",
        ")\n",
        "\n",
        "# arize_client.log returns a Response object from Python's requests module\n",
        "response = arize_client.log(\n",
        "    dataframe=production_dataset,\n",
        "    schema=production_schema,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=model_type,\n",
        "    environment=Environments.PRODUCTION,\n",
        ")\n",
        "\n",
        "# If successful, the server will return a status_code of 200\n",
        "if response.status_code != 200:\n",
        "    print(\n",
        "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        f\"Step 5 ‚úÖ: You have successfully logged {len(production_dataset)} data points to Arize!\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q78WzmqLuDjM"
      },
      "source": [
        "## Part 6: Neural Models and Model Agnostic\n",
        "In this section, we will use `shap.KernelExplainer`, which works for all models such as deep learning model and SVMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGM1usLzU8wc"
      },
      "outputs": [],
      "source": [
        "model_version = f\"{model_id}-nn-model-1.0\"\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier().fit(X_train, y_train)\n",
        "y_test_pred, y_test_pred_score = predict(clf, X_test)\n",
        "shap_values = get_shap_values(clf, X_train, X_test, shap.KernelExplainer)\n",
        "\n",
        "# For this example we need to first assemble our data into a pandas DataFrame\n",
        "\n",
        "# A mapping is needed to pair up each SHAP value column with its feature name\n",
        "shap_values_column_names_mapping = {\n",
        "    f\"{feat}\": f\"{feat}_shap\" for feat in data[\"feature_names\"]\n",
        "}\n",
        "\n",
        "production_dataset = X_test.join(\n",
        "    [\n",
        "        pd.DataFrame(\n",
        "            {\n",
        "                \"prediction_id\": generate_prediction_ids(X_test),\n",
        "                \"prediction_ts\": simulate_production_timestamps(X_test),\n",
        "                \"prediction_label\": y_test_pred,\n",
        "                \"prediction_score\": y_test_pred_score,\n",
        "                \"actual_label\": y_test,\n",
        "            }\n",
        "        ),\n",
        "        shap_values.rename(columns=shap_values_column_names_mapping),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZNXU5mOQ-84"
      },
      "source": [
        "Three easy steps to log a `pandas.DataFrame`. See [docs](https://docs.arize.com/arize/api-reference/python-sdk/arize.pandas) for more details.\n",
        "\n",
        "1.   Define `Schema` to designate column names\n",
        "2.   Call `arize.pandas.log()`\n",
        "3.   Check `response.status_code`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3b6rdASQ-84"
      },
      "outputs": [],
      "source": [
        "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
        "production_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",  # REQUIRED\n",
        "    timestamp_column_name=\"prediction_ts\",\n",
        "    prediction_label_column_name=\"prediction_label\",\n",
        "    prediction_score_column_name=\"prediction_score\",\n",
        "    actual_label_column_name=\"actual_label\",\n",
        "    feature_column_names=data[\"feature_names\"],\n",
        "    shap_values_column_names=shap_values_column_names_mapping,\n",
        ")\n",
        "\n",
        "# arize_client.log returns a Response object from Python's requests module\n",
        "response = arize_client.log(\n",
        "    dataframe=production_dataset,\n",
        "    schema=production_schema,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=model_type,\n",
        "    environment=Environments.PRODUCTION,\n",
        ")\n",
        "\n",
        "# If successful, the server will return a status_code of 200\n",
        "if response.status_code != 200:\n",
        "    print(\n",
        "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        f\"Step 6 ‚úÖ: You have successfully logged {len(production_dataset)} data points to Arize!\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check Data Ingestion Information\n",
        "You now know how to seamlessly log SHAP values onto the Arize platform. Go to [Arize](https://app.arize.com/) in order to analyze and monitor the logged SHAP values.\n",
        "\n",
        "Data will be available in the UI in about 10 minutes after it was received. If data from a new model is sent, the model will be reflected almost immediately in the Arize platform. However, you will not see data yet. To verify data has been sent correctly and is being processed, we recommend that you check our Data Ingestion tab.\n",
        "\n",
        "You will be able to see the predictions, actuals, and feature importances that have been sent in the last week, last day or last 30 minutes.\n",
        "\n",
        "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below.\n",
        "\n",
        "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03yNR49YZ5Dd"
      },
      "source": [
        "### Overview\n",
        "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
        "- Automated ML monitoring and model monitoring\n",
        "- Workflows to troubleshoot model performance\n",
        "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
        "- Model prediction cohort analysis\n",
        "- Pre-deployment model validation\n",
        "- Integrated model explainability\n",
        "\n",
        "### Website\n",
        "Visit Us At: https://arize.com/model-monitoring/\n",
        "\n",
        "### Additional Resources\n",
        "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
        "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
        "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
        "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
        "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
        "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
        "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
        "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
        "\n",
        "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SHAP_Tutorial_Base_Version.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}

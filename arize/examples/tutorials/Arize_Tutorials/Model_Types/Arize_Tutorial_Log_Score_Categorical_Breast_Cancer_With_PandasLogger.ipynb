{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arize Tutorial: Model Type - Score Categorical\n",
    "\n",
    "Let's get started on using Arize!‚ú®\n",
    "\n",
    "Arize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models.\n",
    "\n",
    "In this tutorial, we will be building a model to predict if someone has breast cancer or not. The model predicts a score (how likely is this person to have breast cancer) and based on a threshold, determines the class (True/False). For this model, we will log the score and the class so this model type is `ModelType.SCORE_CATEGORICAL`. We will load the models‚Äôs training, validation, and test inferences into Arize. üöÄ.\n",
    "\n",
    "Finally, using the `arize.pandas.logger` (available in `arize 2.2.0+`), we will load the model's inference data into Arize. üöÄ\n",
    "\n",
    "### Running This Notebook\n",
    "1. Save a copy in Google Drive for yourself.\n",
    "2. Step through each section below, pressing play on the code blocks to run the cells.\n",
    "3. In Step 2, use your own Space and API key from your Arize account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUUdm-QfF8xG"
   },
   "source": [
    "## Step 1: Load Data and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OWSc0hFn-Y4W"
   },
   "outputs": [],
   "source": [
    "!pip install -q arize shap\n",
    "\n",
    "import datetime\n",
    "import uuid\n",
    "import shap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arize.pandas.logger import Client, Schema\n",
    "from arize.utils.types import ModelTypes, Environments\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxBVOhJ9vlC6",
    "outputId": "94ba808e-91cb-472f-f0f0-6aea4c46e840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 ‚úÖ: Load Data & Build Model Done!\n"
     ]
    }
   ],
   "source": [
    "# 1 Load data and split data\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# NOTE: We need to set y.astype(str) since BINARY expected non-integer.\n",
    "X, y = X.astype(np.float32), y.astype(str)\n",
    "X, y = pd.DataFrame(X, columns=data[\"feature_names\"]), pd.Series(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "# 2 Fit a simple logistic regression model\n",
    "clf = LogisticRegression(max_iter=3000, verbose=False).fit(X_train, y_train)\n",
    "\n",
    "# 3 Use the model to generate predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_train_pred_proba = clf.predict_proba(X_train)\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n",
    "y_val_pred_proba = clf.predict_proba(X_val)\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "# 4 Map the prediction probability to prediction score\n",
    "def map_proba(y_pred, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    y_pred (1-dim) and y_pred_proba (n-dim) from sklearn\n",
    "    Output:\n",
    "    y_pred_scores (1-dim) np.array for the probability of only the predicted class\n",
    "    \"\"\"\n",
    "    y_pred_scores = [y_pred_proba[i][int(y_pred[i])] for i in range(len(y_pred))]\n",
    "    return pd.Series(y_pred_scores)\n",
    "\n",
    "\n",
    "y_train_pred_score = map_proba(y_train_pred, y_train_pred_proba)\n",
    "y_val_pred_score = map_proba(y_val_pred, y_val_pred_proba)\n",
    "y_test_pred_score = map_proba(y_test_pred, y_test_pred_proba)\n",
    "\n",
    "print(\"Step 1 ‚úÖ: Load Data & Build Model Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxFpmijbvyu9"
   },
   "source": [
    "Group and combine all the data (features/predictions/actuals) for each environment (train/validation/test) into one pd.DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wpjsAQj-v1MQ"
   },
   "outputs": [],
   "source": [
    "# df for training env\n",
    "train_df = X_train.reset_index(drop=True)\n",
    "train_df[\"prediction_label\"] = y_train_pred\n",
    "train_df[\"prediction_score\"] = y_train_pred_score\n",
    "train_df[\"actual_label\"] = list(y_train)\n",
    "train_df[\"prediction_id\"] = [str(uuid.uuid4()) for _ in range(len(y_train))]\n",
    "\n",
    "\n",
    "# df for validation env\n",
    "val_df = X_val.reset_index(drop=True)\n",
    "val_df[\"prediction_label\"] = y_val_pred\n",
    "val_df[\"prediction_score\"] = y_val_pred_score\n",
    "val_df[\"actual_label\"] = list(y_val)\n",
    "val_df[\"prediction_id\"] = [str(uuid.uuid4()) for _ in range(len(y_val))]\n",
    "\n",
    "\n",
    "# df for production env\n",
    "test_df = X_test.reset_index(drop=True)\n",
    "test_df[\"prediction_label\"] = y_test_pred\n",
    "test_df[\"prediction_score\"] = y_test_pred_score\n",
    "test_df[\"actual_label\"] = list(y_test)\n",
    "test_df[\"prediction_id\"] = [str(uuid.uuid4()) for _ in range(len(y_test))]\n",
    "\n",
    "# simulate predictions evenly distributed over 30 days by manually specifying prediction time\n",
    "current_time = datetime.datetime.now().timestamp()\n",
    "earlier_time = (datetime.datetime.now() - datetime.timedelta(days=30)).timestamp()\n",
    "optional_prediction_timestamps = np.linspace(\n",
    "    earlier_time, current_time, num=len(y_test)\n",
    ")\n",
    "test_df[\"prediction_ts\"] = pd.Series(optional_prediction_timestamps.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KmlJdhR1Akv"
   },
   "source": [
    "**Optional** - add SHAP value to the simulated production environment data to enable the model explainability feature on Arize platform\n",
    "\n",
    "**SHAP (SHapley Additive exPlanations)** is a game theoretic approach to explain the output of any machine learning model.\n",
    "\n",
    "For more in-depth usage of the `shap` library, visit [SHAP Core Explainers](https://shap-lrjball.readthedocs.io/en/docs_update/generated/shap.Explainer.html) and pick an explainer specific to your machine learning model. `shap.Explainer` is the default explainer that will match model type, but you can specify your own type. For example, you can choose to use for example `shap.TreeExplainer`, but it won't work on models such as `sklearn.LinearModel.LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Vm1s0z4K1C9i"
   },
   "outputs": [],
   "source": [
    "def get_shap_values(model, X_data, ExplainerType=shap.Explainer, show_graph=False):\n",
    "    # NOTE: If there are errors, you  need to manually choose which explainer class\n",
    "    explainer = ExplainerType(model, X_data)\n",
    "    shap_values = explainer.shap_values(X_data)\n",
    "    # When not in production, it can be helpful to check graphs for feature explainability\n",
    "    if show_graph:\n",
    "        shap.summary_plot(shap_values, X_data, feature_names=data[\"feature_names\"])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        shap_values, columns=[f\"{fn}_shap\" for fn in data[\"feature_names\"]]\n",
    "    )\n",
    "\n",
    "\n",
    "test_shap_df = get_shap_values(clf, X_test)\n",
    "test_df = pd.concat([test_df, test_shap_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcVdPGFkGF2t"
   },
   "source": [
    "## Step 2: Import and Setup Arize Client\n",
    "You can find your `API_KEY` and `SPACE_KEY` by navigating to the settings page in your workspace (only space admins can see the keys). Copy those over to the set-up section. We will also be setting up some metadata to use across all logging.\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btoJ-OY5DW5K",
    "outputId": "c903683c-870b-44e6-9e9e-5634ea30560f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 ‚úÖ: Import and Setup Arize Client Done! Now we can start using Arize!\n"
     ]
    }
   ],
   "source": [
    "SPACE_KEY = 'SPACE_KEY'\n",
    "API_KEY = 'API_KEY'\n",
    "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
    "\n",
    "model_id = \"breast_cancer_score_prediction\"\n",
    "model_version = \"1.0\"\n",
    "\n",
    "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
    "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
    "else:\n",
    "    print(\"Step 2 ‚úÖ: Import and Setup Arize Client Done! Now we can start using Arize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAFhPCPOGX4T"
   },
   "source": [
    "## Step 3: Log Inferences to Arize with arize.pandas.logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49WKO4i8wX_q"
   },
   "source": [
    "### 3.1: Log training data to Arize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaiZRNt2EfXs",
    "outputId": "23e7d2fd-0371-464a-ab98-1944666bb461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "future completed with response code 200\n"
     ]
    }
   ],
   "source": [
    "# Define a Schema() for Arize to pick up the data from the correct column for logging\n",
    "train_schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    prediction_label_column_name=\"prediction_label\",\n",
    "    prediction_score_column_name=\"prediction_score\",\n",
    "    actual_label_column_name=\"actual_label\",\n",
    "    feature_column_names=train_df.columns.drop(\n",
    "        [\"prediction_id\", \"prediction_label\", \"prediction_score\", \"actual_label\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "train_res = arize_client.log(\n",
    "    dataframe=train_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
    "    environment=Environments.TRAINING,\n",
    "    schema=train_schema,\n",
    ")\n",
    "if train_res.status_code != 200:\n",
    "    print(f\"‚ùå future failed with response code {train_res.status_code}, {train_res.text}\")\n",
    "else:\n",
    "    print(f\"‚úÖ future completed with response code {train_res.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Luve7h80Gb0L"
   },
   "source": [
    "### 3.2: Log validation data to Arize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx3g8DoQD2me",
    "outputId": "845d2a3c-95b2-4d65-c0e5-796238172337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "future completed with response code 200\n"
     ]
    }
   ],
   "source": [
    "val_schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    prediction_label_column_name=\"prediction_label\",\n",
    "    prediction_score_column_name=\"prediction_score\",\n",
    "    actual_label_column_name=\"actual_label\",\n",
    "    feature_column_names=val_df.columns.drop(\n",
    "        [\"prediction_id\", \"prediction_label\", \"prediction_score\", \"actual_label\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "val_res = arize_client.log(\n",
    "    dataframe=val_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    batch_id=\"validation_test\",  # provide a batch_id to distinguish from other validation data set\n",
    "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
    "    environment=Environments.VALIDATION,\n",
    "    schema=val_schema,\n",
    ")\n",
    "if val_res.status_code != 200:\n",
    "    print(f\"‚ùå future failed with response code {val_res.status_code}, {val_res.text}\")\n",
    "else:\n",
    "    print(f\"‚úÖ future completed with response code {val_res.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0t5YxQWL2ojX"
   },
   "source": [
    "### 3.3: Log production data to Arize\n",
    "Note: We will be sending the test data to emulate sending production data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Blxqc4103Ln9",
    "outputId": "e97f01a7-f878-49da-82e8-fb7cb4464a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "future completed with response code 200\n"
     ]
    }
   ],
   "source": [
    "# Logging production\n",
    "all_cols = test_df.columns\n",
    "shap_cols = test_shap_df.columns\n",
    "feature_cols = all_cols.drop(\n",
    "    list(shap_cols)\n",
    "    + [\n",
    "        \"prediction_id\",\n",
    "        \"prediction_ts\",\n",
    "        \"prediction_label\",\n",
    "        \"prediction_score\",\n",
    "        \"actual_label\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"prediction_label\",\n",
    "    prediction_score_column_name=\"prediction_score\",\n",
    "    actual_label_column_name=\"actual_label\",\n",
    "    feature_column_names=feature_cols,\n",
    "    shap_values_column_names=dict(zip(feature_cols, shap_cols)),\n",
    ")\n",
    "\n",
    "test_res = arize_client.log(\n",
    "    dataframe=test_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
    "    environment=Environments.PRODUCTION,\n",
    "    schema=test_schema,\n",
    ")\n",
    "if test_res.status_code != 200:\n",
    "    print(f\"‚ùå future failed with response code {test_res.status_code}, {test_res.text}\")\n",
    "else:\n",
    "    print(f\"‚úÖ future completed with response code {test_res.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data Ingestion Information\n",
    "\n",
    "Data will be available in the UI in about 10 minutes after it was received. If data from a new model is sent, the model will be reflected almost immediately in the Arize platform. However, you will not see data yet. To verify data has been sent correctly and is being processed, we recommend that you check our Data Ingestion tab.\n",
    "\n",
    "You will be able to see the predictions, actuals, and feature importances that have been sent in the last week, last day or last 30 minutes.\n",
    "\n",
    "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62uTSrlsmxTp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Arize Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Arize_Tutorial_Log_Score_Categorical_Breast_Cancer_With_PandasLogger.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ce17ce0dc65859ec3c02171d2809844f566c6b7317351436dc9cbfc9aeef8583"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJEgUhyh-k4-"
   },
   "source": [
    "# Arize Tutorial: Model Type - Score Categorical\n",
    "\n",
    "Let's get started on using Arize!‚ú®\n",
    "\n",
    "Arize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models.\n",
    "\n",
    "In this tutorial, we will be building a model to predict if someone has breast cancer or not. The model predicts a score (how likely is this person to have breast cancer) and based on a threshold, determines the class (True/False). For this model, we will log the score and the class so this model type is `ModelType.SCORE_CATEGORICAL`. We will load the models‚Äôs training, validation, and test inferences into Arize. üöÄ.\n",
    "\n",
    "### Running This Notebook\n",
    "1. Save a copy in Google Drive for yourself.\n",
    "2. Step through each section below, pressing play on the code blocks to run the cells.\n",
    "3. In Step 2, use your own Space and API key from your Arize account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUUdm-QfF8xG"
   },
   "source": [
    "## Step 1: Load Data and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OWSc0hFn-Y4W",
    "outputId": "e26921d9-464c-4fcb-a917-368613d8cb12"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import concurrent.futures as cf\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def map_proba(y_pred, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    y_pred (1-dim) and y_pred_proba (n-dim) from sklearn\n",
    "    Output:\n",
    "    y_pred_scores (1-dim) np.array for the probability of only the predicted class\n",
    "    \"\"\"\n",
    "    y_pred_scores = [y_pred_proba[i][int(y_pred[i])] for i in range(len(y_pred))]\n",
    "    return pd.Series(y_pred_scores)\n",
    "\n",
    "###############################################################################\n",
    "# 1 Load data and split data\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# NOTE: We need to set y.astype(str) since BINARY expected non-integer.\n",
    "X, y = X.astype(np.float32), y.astype(str)\n",
    "X, y = pd.DataFrame(X, columns=data['feature_names']), pd.Series(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "###############################################################################\n",
    "# 2 Fit a simple logistic regression model\n",
    "clf = LogisticRegression(max_iter=3000, verbose=False).fit(X_train, y_train)\n",
    "\n",
    "# 3 Use the model to generate predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_train_pred_proba = clf.predict_proba(X_train)\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n",
    "y_val_pred_proba = clf.predict_proba(X_val)\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "# 3.5 Change the format for prediction_scores\n",
    "y_train_pred_score = map_proba(y_train_pred, y_train_pred_proba)\n",
    "y_val_pred_score = map_proba(y_val_pred, y_val_pred_proba)\n",
    "y_test_pred_score = map_proba(y_test_pred, y_test_pred_proba)\n",
    "\n",
    "print('Step 1 ‚úÖ: Load Data & Build Model Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcVdPGFkGF2t"
   },
   "source": [
    "## Step 2: Import and Setup Arize Client\n",
    "You can find your `API_KEY` and `SPACE_KEY` by navigating to the settings page in your workspace (only space admins can see the keys). Copy those over to the set-up section. We will also be setting up some metadata to use across all logging.\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btoJ-OY5DW5K",
    "outputId": "d145a45e-f0d5-4a4e-c734-e3203293fbb0"
   },
   "outputs": [],
   "source": [
    "!pip install arize -q\n",
    "from arize.api import Client\n",
    "from arize.utils.types import ModelTypes\n",
    "\n",
    "SPACE_KEY = 'SPACE_KEY'\n",
    "API_KEY = 'API_KEY'\n",
    "arize = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
    "\n",
    "model_id = 'breast_cancer_score_prediction'\n",
    "model_version = '1.0'\n",
    "model_type = ModelTypes.SCORE_CATEGORICAL\n",
    "\n",
    "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
    "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
    "else:\n",
    "    print(\"Step 2 ‚úÖ: Import and Setup Arize Client Done! Now we can start using Arize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAFhPCPOGX4T"
   },
   "source": [
    "## Step 3: Log Training Inferences to Arize\n",
    "First step: Log the training data for your model to Arize!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaiZRNt2EfXs",
    "outputId": "c681c669-4b05-422f-866d-c66abde4428e"
   },
   "outputs": [],
   "source": [
    "# Logging training\n",
    "train_prediction_labels = pd.Series(y_train_pred)\n",
    "train_actual_labels = pd.Series(y_train)\n",
    "train_feature_df = pd.DataFrame(X_train, columns=data['feature_names'])\n",
    "\n",
    "train_responses = arize.log_training_records(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type, # this will change depending on your model type\n",
    "    prediction_labels=train_prediction_labels,\n",
    "    prediction_scores=y_train_pred_score,\n",
    "    actual_labels=train_actual_labels,\n",
    "    features=train_feature_df,\n",
    "    )\n",
    "\n",
    "## Helper to listen to response code to ensure successful delivery\n",
    "def arize_responses_helper(responses):\n",
    "  for response in cf.as_completed(responses):\n",
    "    res = response.result()\n",
    "    if res.status_code != 200:\n",
    "      print(f'‚ùå future failed with response code {res.status_code}, {res.text}')\n",
    "\n",
    "arize_responses_helper(train_responses)\n",
    "\n",
    "print('Step 3 ‚úÖ: If no errors showed up, you have sent Training Inferences!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Luve7h80Gb0L"
   },
   "source": [
    "## Step 4: Log Validation Inferences to Arize\n",
    "Next Step: Log the validation data. You need to include `batch_id` to separate out different validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx3g8DoQD2me",
    "outputId": "118c14dd-540c-4130-b4e4-be191ce35f86"
   },
   "outputs": [],
   "source": [
    "# Logging validation\n",
    "val_prediction_labels = pd.Series(y_val_pred)\n",
    "val_actual_labels = pd.Series(y_val)\n",
    "val_features_df = pd.DataFrame(X_val, columns=data['feature_names'])\n",
    "\n",
    "val_responses = arize.log_validation_records(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    batch_id='batch0',\n",
    "    prediction_labels=val_prediction_labels,\n",
    "    prediction_scores=y_val_pred_score,\n",
    "    actual_labels=val_actual_labels,\n",
    "    features=val_features_df,\n",
    "    )\n",
    "\n",
    "arize_responses_helper(val_responses)\n",
    "print('Step 4 ‚úÖ: If no errors showed up, you have sent Validation Inferences!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtuHsrFvg6vf"
   },
   "source": [
    "# Logging During Production\n",
    "Next steps simulate production environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3tPwyCfz_Ic"
   },
   "source": [
    "## Step 5: Generating and Formatting SHAP Values\n",
    "**SHAP (SHapley Additive exPlanations)** is a game theoretic approach to explain the output of any machine learning model.\n",
    "\n",
    "For more in-depth usage of the `shap` library, visit [SHAP Core Explainers](https://shap-lrjball.readthedocs.io/en/docs_update/generated/shap.Explainer.html) and pick an explainer specific to your machine learning model. `shap.Explainer` is the default explainer that will matches model type, but you can specify your own type. For example, you can choose to use for example `shap.TreeExplainer`, but it won't work on models such as `sklearn.LinearModel.LogisticRegression`.\n",
    "\n",
    "We create this helper function `get_shap_values` to format the data and/or create visualizations for our shap values. We will store our results in a `pd.DataFrame` with matching columns for logging later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "h-dQnToOz83C",
    "outputId": "48b12105-3d60-451f-d31e-259bf5038234"
   },
   "outputs": [],
   "source": [
    "!pip install shap\n",
    "import shap\n",
    "\n",
    "def get_shap_values(model, X_data, ExplainerType=shap.Explainer, show_graph=False):\n",
    "    # NOTE: If there are errors, you  need to manually choose which explainer class\n",
    "    explainer = ExplainerType(model, X_data)\n",
    "    shap_values = explainer.shap_values(X_data)\n",
    "\n",
    "    # When not in production, it can be helpful to check graphs for feature explainability\n",
    "    if show_graph:\n",
    "        shap.summary_plot(shap_values, X_data, feature_names=data['feature_names'])\n",
    "\n",
    "    # NOTE: Arize API expects a DataFrame of the same shape and column name as the model features.\n",
    "    return pd.DataFrame(shap_values, columns=data['feature_names'])\n",
    "\n",
    "shap_values = get_shap_values(clf, X, show_graph=True)\n",
    "print('Part 5 ‚úÖ: If no errors showed up, you have logged predictions and actuals in bulk!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH87Efukh3X4"
   },
   "source": [
    "## Step 6: Production Logging in Bulk to Arize\n",
    "Note: We will be sending our test data to emulate sending production data.\n",
    "\n",
    "1. **prediction_timestamps:** You can directly specify the unix time which the predictions were made by using the optional argument `time_overwrite`. This will set the prediction timestamps. It can be a `pd.Series` or `List` of dtype `int` and the same length as the predictions sent. The timestamp at index 1 will be the prediction timestamp at index 1. You can set the prediction timestamps within the last year.\n",
    "\n",
    "In our example, we used `time_overwrite` to simulate predictions over 30 days so you can see it displayed on arize platform right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OxFrd7qiNCU",
    "outputId": "ddba709a-88f7-4ea0-a055-6a3f0484559b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# bulk_pred_ids_df will be used to uniquely identify these predictions\n",
    "ids_df = pd.DataFrame([str(uuid.uuid4()) for _ in range(len(y_test))])\n",
    "y_pred = pd.Series(clf.predict(X_test))\n",
    "y_score = map_proba(y_pred, clf.predict_proba(X_test))\n",
    "\n",
    "# For Score Categorical, y_pred shape should be (2, N)\n",
    "y_pred = pd.Series(zip(y_pred, y_score))\n",
    "\n",
    "# OPTIONAL: Simulate predictions evenly distributed over 30 days by manually specifying prediction time\n",
    "current_time = datetime.datetime.now().timestamp()\n",
    "earlier_time = (datetime.datetime.now() - datetime.timedelta(days=30)).timestamp()\n",
    "optional_prediction_timestamps = np.linspace(earlier_time, current_time, num=len(y_test_pred))\n",
    "optional_prediction_timestamps = pd.Series(optional_prediction_timestamps.astype(int))\n",
    "\n",
    "# Generate SHAP vales\n",
    "shap_df = get_shap_values(clf, X_test)\n",
    "\n",
    "# First we log the predictions and actuals.\n",
    "log_bulk_responses = arize.bulk_log(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    prediction_ids=ids_df,\n",
    "    prediction_labels=y_pred,\n",
    "    actual_labels=y_test,\n",
    "    prediction_timestamps=optional_prediction_timestamps,\n",
    "    shap_values=shap_df,\n",
    "    features=X_test,\n",
    "    )\n",
    "\n",
    "arize_responses_helper(log_bulk_responses)\n",
    "print('Part 6 ‚úÖ: If no errors showed up, you have logged in bulk just now to Arize!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data Ingestion Information\n",
    "\n",
    "Data will be available in the UI in about 10 minutes after it was received. If data from a new model is sent, the model will be reflected almost immediately in the Arize platform. However, you will not see data yet. To verify data has been sent correctly and is being processed, we recommend that you check our Data Ingestion tab.\n",
    "\n",
    "You will be able to see the predictions, actuals, and feature importances that have been sent in the last week, last day or last 30 minutes.\n",
    "\n",
    "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Arize_Tutorial_Log_Score_Categorical_Breast_Cancer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

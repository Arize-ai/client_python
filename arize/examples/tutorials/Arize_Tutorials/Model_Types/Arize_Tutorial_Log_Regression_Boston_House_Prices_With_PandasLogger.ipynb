{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJEgUhyh-k4-"
   },
   "source": [
    "# Arize Tutorial: Model Type - Numeric\n",
    "\n",
    "Let's get started on using Arize!‚ú®\n",
    "\n",
    "Arize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models.\n",
    "\n",
    "In this tutorial, we will be building a regression model to predict Boston House Prices. The model is predicting a numeric value so the model type will be `ModelTypes.NUMERIC`. We will split the full dataset into three (train-validation-test) separate environments and combine the features/predictions/actuals into one pandas dataframe for each environment.\n",
    "\n",
    "Finally, using the `arize.pandas.logger` (available in `arize 2.2.0+`), we will load the model's inference data into Arize. üöÄ\n",
    "\n",
    "### Running This Notebook\n",
    "1. Save a copy in Google Drive for yourself.\n",
    "2. Step through each section below, pressing play on the code blocks to run the cells.\n",
    "3. In Step 2, use your own Space and API key from your Arize account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUUdm-QfF8xG"
   },
   "source": [
    "## Step 1: Load Data and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IN4qRep8tnFb",
    "outputId": "c7738330-49a4-41c1-a395-84e65520acbe"
   },
   "outputs": [],
   "source": [
    "!pip install -q arize shap\n",
    "\n",
    "import datetime\n",
    "import uuid\n",
    "import shap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arize.pandas.logger import Client, Schema\n",
    "from arize.utils.types import ModelTypes, Environments\n",
    "from sklearn import datasets\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OWSc0hFn-Y4W",
    "outputId": "00309db5-77b2-413d-e221-046bbc9a283f"
   },
   "outputs": [],
   "source": [
    "# 1 Load data and split data\n",
    "data = datasets.load_boston()\n",
    "X, y = datasets.load_boston(return_X_y=True)\n",
    "X, y = pd.DataFrame(X, columns=data[\"feature_names\"]), pd.Series(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "# 2 Fit a regression model\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 0.5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"ls\",\n",
    "}\n",
    "clf = ensemble.GradientBoostingRegressor(**params).fit(X_train, y_train)\n",
    "\n",
    "# 3 Use the model to generate predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_val_pred = clf.predict(X_val)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Step 1 ‚úÖ: Load Data & Build Model Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxnqRbPQtHm9"
   },
   "source": [
    "### Step 1.1: Organize by environments\n",
    "\n",
    "Group and combine all the data (features/predictions/actuals) for each environment (train/validation/test) into one pd.DataFrame object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agpBBRUQs2n2"
   },
   "outputs": [],
   "source": [
    "# df for training env\n",
    "train_df = X_train.reset_index(drop=True)\n",
    "train_df[\"prediction_label\"] = y_train_pred\n",
    "train_df[\"actual_label\"] = list(y_train)\n",
    "train_df[\"prediction_id\"] = [str(uuid.uuid4()) for _ in range(len(y_train))]\n",
    "\n",
    "\n",
    "# df for validation env\n",
    "val_df = X_val.reset_index(drop=True)\n",
    "val_df[\"prediction_label\"] = y_val_pred\n",
    "val_df[\"actual_label\"] = list(y_val)\n",
    "val_df[\"prediction_id\"] = [str(uuid.uuid4()) for _ in range(len(y_val))]\n",
    "\n",
    "\n",
    "# df for production env (simulated using the test data set)\n",
    "test_df = X_test.reset_index(drop=True)\n",
    "test_df[\"prediction_label\"] = y_test_pred\n",
    "test_df[\"actual_label\"] = list(y_test)\n",
    "test_df[\"prediction_id\"] = [str(uuid.uuid4()) for _ in range(len(y_test))]\n",
    "\n",
    "# add timestamp to simulate production environment\n",
    "current_time = datetime.datetime.now().timestamp()\n",
    "earlier_time = (datetime.datetime.now() - datetime.timedelta(days=30)).timestamp()\n",
    "optional_prediction_timestamps = np.linspace(\n",
    "    earlier_time, current_time, num=len(y_test)\n",
    ")\n",
    "test_df[\"prediction_ts\"] = pd.Series(optional_prediction_timestamps.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ0Swk46bynD"
   },
   "source": [
    "### Step 1.2 (optional): Add SHAP values\n",
    "\n",
    "Add SHAP value to the simulated production environment data to enable the model explainability feature on Arize platform\n",
    "\n",
    "**SHAP (SHapley Additive exPlanations)** is a game theoretic approach to explain the output of any machine learning model.\n",
    "\n",
    "For more in-depth usage of the `shap` library, visit [SHAP Core Explainers](https://shap-lrjball.readthedocs.io/en/docs_update/generated/shap.Explainer.html) and pick an explainer specific to your machine learning model. `shap.Explainer` is the default explainer that will match model type, but you can specify your own type. For example, you can choose to use for example `shap.TreeExplainer`, but it won't work on models such as `sklearn.LinearModel.LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOtYltUBcc1T"
   },
   "outputs": [],
   "source": [
    "def get_shap_values(model, X_data, ExplainerType=shap.Explainer, show_graph=False):\n",
    "    # NOTE: If there are errors, you  need to manually choose which explainer class\n",
    "    explainer = ExplainerType(model, X_data)\n",
    "    shap_values = explainer.shap_values(X_data)\n",
    "    # When not in production, it can be helpful to check graphs for feature explainability\n",
    "    if show_graph:\n",
    "        shap.summary_plot(shap_values, X_data, feature_names=data[\"feature_names\"])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        shap_values, columns=[f\"{fn}_shap\" for fn in data[\"feature_names\"]]\n",
    "    )\n",
    "\n",
    "\n",
    "test_shap_df = get_shap_values(clf, X_test)\n",
    "test_df = pd.concat([test_df, test_shap_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcVdPGFkGF2t"
   },
   "source": [
    "## Step 2: Import and Setup Arize Client\n",
    "You can find your `API_KEY` and `SPACE_KEY` by navigating to the settings page in your workspace (only space admins can see the keys). Copy those over to the set-up section. We will also be setting up some metadata to use across all logging.\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btoJ-OY5DW5K",
    "outputId": "296ec45d-9dcf-4957-c80a-65987a7d8a71"
   },
   "outputs": [],
   "source": [
    "SPACE_KEY = 'SPACE_KEY'\n",
    "API_KEY = 'API_KEY'\n",
    "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
    "\n",
    "# Saving model metadata for passing in later\n",
    "model_id = \"boston_house_prices\"\n",
    "model_version = \"1.0\"\n",
    "\n",
    "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
    "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
    "else:\n",
    "    print(\"Step 2 ‚úÖ: Import and Setup Arize Client Done! Now we can start using Arize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAFhPCPOGX4T"
   },
   "source": [
    "## Step 3: Log Inferences to Arize with pandas.logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7ykbAeYKm5v"
   },
   "source": [
    "### 3.1: Log the training data for your model to Arize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaiZRNt2EfXs",
    "outputId": "376fb61e-7f9a-41f9-a20a-abb5e7427b51"
   },
   "outputs": [],
   "source": [
    "# Define a Schema() for Arize to pick up the data from the correct column for logging\n",
    "\n",
    "train_schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    prediction_label_column_name=\"prediction_label\",\n",
    "    actual_label_column_name=\"actual_label\",\n",
    "    feature_column_names=train_df.columns.drop(\n",
    "        [\"prediction_id\", \"prediction_label\", \"actual_label\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "train_res = arize_client.log(\n",
    "    dataframe=train_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=ModelTypes.NUMERIC,\n",
    "    environment=Environments.TRAINING,\n",
    "    schema=train_schema,\n",
    ")\n",
    "if train_res.status_code != 200:\n",
    "    print(f\"‚ùå future failed with response code {train_res.status_code}, {train_res.text}\")\n",
    "else:\n",
    "    print(f\"‚úÖ future completed with response code {train_res.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jo9FSs5R961k"
   },
   "source": [
    "### 3.2: Log the validation data\n",
    "\n",
    "Note: You need to include `batch_id` to separate out different validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4kaxk2x9zXq",
    "outputId": "b1469e48-7867-457a-ce4a-bf3af472f731"
   },
   "outputs": [],
   "source": [
    "# Logging validation\n",
    "\n",
    "val_schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    prediction_label_column_name=\"prediction_label\",\n",
    "    actual_label_column_name=\"actual_label\",\n",
    "    feature_column_names=train_df.columns.drop(\n",
    "        [\"prediction_id\", \"prediction_label\", \"actual_label\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "val_res = arize_client.log(\n",
    "    dataframe=val_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    batch_id=\"validation_test\",  # provide a batch_id to distinguish from other validation data set\n",
    "    model_type=ModelTypes.NUMERIC,\n",
    "    environment=Environments.VALIDATION,\n",
    "    schema=val_schema,\n",
    ")\n",
    "if val_res.status_code != 200:\n",
    "    print(f\"‚ùå future failed with response code {val_res.status_code}, {val_res.text}\")\n",
    "else:\n",
    "    print(f\"‚úÖ future completed with response code {val_res.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Luve7h80Gb0L"
   },
   "source": [
    "### 3.3: Log the production data\n",
    "Note: We will be sending our test data to emulate sending production data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx3g8DoQD2me",
    "outputId": "c1bd8caa-7377-46dd-b12a-005de7f7397f"
   },
   "outputs": [],
   "source": [
    "# Logging production\n",
    "all_cols = test_df.columns\n",
    "shap_cols = test_shap_df.columns\n",
    "feature_cols = all_cols.drop(\n",
    "    list(shap_cols)\n",
    "    + [\"prediction_id\", \"prediction_ts\", \"prediction_label\", \"actual_label\"]\n",
    ")\n",
    "\n",
    "test_schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"prediction_label\",\n",
    "    actual_label_column_name=\"actual_label\",\n",
    "    feature_column_names=feature_cols,\n",
    "    shap_values_column_names=dict(zip(feature_cols, shap_cols)),\n",
    ")\n",
    "\n",
    "test_res = arize_client.log(\n",
    "    dataframe=test_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=ModelTypes.NUMERIC,\n",
    "    environment=Environments.PRODUCTION,\n",
    "    schema=test_schema,\n",
    ")\n",
    "if test_res.status_code != 200:\n",
    "    print(f\"‚ùå future failed with response code {test_res.status_code}, {test_res.text}\")\n",
    "else:\n",
    "    print(f\"‚úÖ future completed with response code {test_res.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data Ingestion Information\n",
    "\n",
    "Data will be available in the UI in about 10 minutes after it was received. If data from a new model is sent, the model will be reflected almost immediately in the Arize platform. However, you will not see data yet. To verify data has been sent correctly and is being processed, we recommend that you check our Data Ingestion tab.\n",
    "\n",
    "You will be able to see the predictions, actuals, and feature importances that have been sent in the last week, last day or last 30 minutes.\n",
    "\n",
    "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXAn6dJnfYgP"
   },
   "source": [
    "# Arize Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " Arize_Tutorial_Log_Regression_Boston_House_Prices_With_PandasLogger.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iixIYFYvUtUL"
   },
   "source": [
    "# Getting Started with the Arize Platform - Comparing Business Impact\n",
    "\n",
    "**In this walkthrough, we are going to look at how to use  Arize to measure business impact in production!**\n",
    "\n",
    "You manage the default/fraud detection model for the widely used [Lending Club](https://www.lendingclub.com/). One of your model is already in production and serving customers, but now you have a newly fitted model that you would like to compare with the production model.\n",
    "\n",
    "Specifically, **you want to see which model has better impact on your business objectives in production**, so you turn to Arize for investigation. We will explain what \"Business Impact\" means when we get to Step 2: Understanding Business Impact\n",
    "\n",
    "\n",
    "\n",
    "## Our steps to resolving this issue will be :\n",
    "\n",
    "1. Get our model onto the Arize platform to investigate\n",
    "2. Enter formula for evaluating business impact\n",
    "3. Compare the model in production and the new model we want to validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jGvz-LwUkYg"
   },
   "source": [
    "# Step 1: Setup and Getting the Data\n",
    "### Step 1.1: Loading data from Arize client\n",
    "We will load in some pre-existing data for the Lending Club model - training data, features, predictions, and class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4BQqsb1h_iS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1 Load data from our model already in production\n",
    "production = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/arize-assets/fixtures/impact-production.csv\"\n",
    ").iloc[:, 1:]\n",
    "\n",
    "# 2 Load validation data for our new model\n",
    "validation = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/arize-assets/fixtures/impact-validation.csv\"\n",
    ").iloc[:, 1:]\n",
    "\n",
    "# 3 Unpack data so we can log them to Arize later!\n",
    "def unpack_data(data):\n",
    "    X, y = data.drop(columns=[\"label\", \"prediction\", \"score\"]), data[\"label\"]\n",
    "    pred, score = data[\"prediction\"], data[\"score\"]\n",
    "    return X, y, pred, score\n",
    "\n",
    "\n",
    "X_val, y_val, y_val_pred, y_val_score = unpack_data(validation)\n",
    "X_prod, y_prod, y_prod_pred, y_prod_score = unpack_data(production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTJgOtGdiAOg"
   },
   "source": [
    "### Step 1.2: Setting up Arize Client:\n",
    "First, copy the Arize `API_KEY` and `SPACE_KEY` from your admin page shown below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFvFOphXfa1I"
   },
   "outputs": [],
   "source": [
    "!pip install -q arize\n",
    "from arize.pandas.logger import Client, Schema\n",
    "from arize.utils.types import ModelTypes, Environments\n",
    "\n",
    "# Step 1: Set-up Arize Client and model meta data\n",
    "SPACE_KEY = \"SPACE_KEY\"\n",
    "API_KEY = \"API_KEY\"\n",
    "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
    "\n",
    "model_id = \"business-impact-comparison\"\n",
    "model_type = ModelTypes.SCORE_CATEGORICAL\n",
    "\n",
    "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
    "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
    "else:\n",
    "    print(\"‚úÖ Arize setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9NsbbI3D69-"
   },
   "source": [
    "We'll use the following helper functions to generate prediction IDs and timestamps to simulate a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgvUDrppD3bQ"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Prediction ID is required for logging any dataset\n",
    "def generate_prediction_ids(X):\n",
    "    return pd.Series((str(uuid.uuid4()) for _ in range(len(X))), index=X.index)\n",
    "\n",
    "\n",
    "# OPTIONAL: We can directly specify when inferences were made\n",
    "def simulate_production_timestamps(X, days=30):\n",
    "    t = datetime.now()\n",
    "    current_t, earlier_t = t.timestamp(), (t - timedelta(days=days)).timestamp()\n",
    "    return pd.Series(np.linspace(earlier_t, current_t, num=len(X)), index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNyrYmrXuCYk"
   },
   "source": [
    "### Step 1.3: Logging Model Version 1 (Production) to Arize\n",
    "First, we take our existing model that's serving in production (Model version 1.0) and use the Arize SDK to log our predictions, actuals, and features. For more details on how **`arize.pandas.log`** works, visit out documentations page below.\n",
    "\n",
    "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bckmZ35Ewcz-"
   },
   "outputs": [],
   "source": [
    "# In the example here we need to first assemble our data into a pandas DataFrame\n",
    "production_dataset = X_prod.join(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"prediction_id\": generate_prediction_ids(X_prod),\n",
    "            \"prediction_ts\": simulate_production_timestamps(X_prod),\n",
    "            \"prediction_labels\": y_prod_pred,\n",
    "            \"prediction_scores\": y_prod_score,\n",
    "            \"actual_labels\": y_prod,\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnIfQmu4wdeH"
   },
   "source": [
    "Three easy steps to log a `pandas.DataFrame`. See [docs](https://docs.arize.com/arize/api-reference/python-sdk/arize.pandas) for more details.\n",
    "\n",
    "1.   Define `Schema` to designate column names\n",
    "2.   Call `arize.pandas.log()`\n",
    "3.   Check `response.status_code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8OAr7VI7H7P"
   },
   "outputs": [],
   "source": [
    "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
    "production_schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",  # REQUIRED\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"prediction_labels\",\n",
    "    prediction_score_column_name=\"prediction_scores\",\n",
    "    actual_label_column_name=\"actual_labels\",\n",
    "    feature_column_names=X_prod.columns,\n",
    ")\n",
    "\n",
    "# arize_client.log returns a Response object from Python's requests module\n",
    "response = arize_client.log(\n",
    "    dataframe=production_dataset,\n",
    "    schema=production_schema,\n",
    "    model_id=model_id,\n",
    "    model_version=\"1.0\",\n",
    "    model_type=model_type,\n",
    "    environment=Environments.PRODUCTION,\n",
    ")\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(\n",
    "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"‚úÖ You have successfully logged {len(production_dataset)} data points to Arize\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_q-jPkADvV88"
   },
   "source": [
    "### Step 1.4: Logging Model Version 2 (Validation) to Arize\n",
    "Next, we log our Model version 2.0 as validation to the Arize platform. With both models logged, we will be able to compare their performance using the business impact page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EnZTFYPwVpU"
   },
   "outputs": [],
   "source": [
    "# In the example here we need to first assemble our data into a pandas DataFrame\n",
    "validation_dataset = X_val.join(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"prediction_id\": generate_prediction_ids(X_val),\n",
    "            \"prediction_labels\": y_val_pred,\n",
    "            \"prediction_scores\": y_val_score,\n",
    "            \"actual_labels\": y_val,\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9f8m4hAwWgh"
   },
   "source": [
    "Three easy steps to log a `pandas.DataFrame`. See [docs](https://docs.arize.com/arize/api-reference/python-sdk/arize.pandas) for more details.\n",
    "\n",
    "1.   Define `Schema` to designate column names\n",
    "2.   Call `arize.pandas.log()`\n",
    "3.   Check `response.status_code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TB4Dffc47IXs"
   },
   "outputs": [],
   "source": [
    "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
    "validation_schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",  # REQUIRED\n",
    "    prediction_label_column_name=\"prediction_labels\",\n",
    "    prediction_score_column_name=\"prediction_scores\",\n",
    "    actual_label_column_name=\"actual_labels\",\n",
    "    feature_column_names=X_val.columns,\n",
    ")\n",
    "\n",
    "# arize_client.log returns a Response object from Python's requests module\n",
    "response = arize_client.log(\n",
    "    dataframe=validation_dataset,\n",
    "    schema=validation_schema,\n",
    "    model_id=model_id,\n",
    "    model_version=\"2.0\",\n",
    "    model_type=model_type,\n",
    "    environment=Environments.VALIDATION,\n",
    "    batch_id=\"validation\",  # distinct batch_id is REQUIRED for logging validation datasets\n",
    ")\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(\n",
    "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"‚úÖ You have successfully logged {len(validation_dataset)} data points to Arize\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Data Ingestion Information\n",
    "\n",
    "Data will be available in the UI in about 10 minutes after it was received. If data from a new model is sent, the model will be reflected almost immediately in the Arize platform. However, you will not see data yet. To verify data has been sent correctly and is being processed, we recommend that you check our Data Ingestion tab. \n",
    "\n",
    "You will be able to see the predictions, actuals, and feature importances that have been sent in the last week, last day or last 30 minutes. \n",
    "\n",
    "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below. \n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkqXm_gEvOZd"
   },
   "source": [
    "## Coffee Time ‚òïÔ∏è\n",
    "Note that the Arize performs takes about 10 minutes to index the data. While the model should appear immediately, the data will not show up till the indexing is done. Feel free to go grab a cup of coffee as Arize works its magic! üîÆ\n",
    "\n",
    "Your Prediction Volume may look slightly different!\n",
    "\n",
    "![image.png](https://storage.googleapis.com/arize-assets/fixtures/waiting-on-data.png)\n",
    "\n",
    "Actual data will show up under **Model Health**. Once the number changes from **0 Actuals** to **Actuals** (with summary statistics listed in the drop-down), your production actuals will have been fully recorded on Arize!\n",
    "\n",
    "![image.png](https://storage.googleapis.com/arize-assets/fixtures/waiting-on-actual-data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x82YyZPUoXF"
   },
   "source": [
    "# Step 2: Understanding Business Impact\n",
    "Sometimes, metrics such as accuracy and recall can't perfectly describe the business objective the model is trying to serve.\n",
    "### **The Fraud Detection Example**\n",
    "\n",
    "In our toy example, we run a default/fraud detection model for the lending club. In this business model, there are financial outcomes that change depending on whether our our model predicted `true` or `false` on a model, in addition to whether those predictions were accurate. **See Business Impact Figure for an example of how this works!**\n",
    "\n",
    "1. When we correct predict default (TP), we save **$10 profit** from admin fees.\n",
    "\n",
    "2. When we incorrectly predict default (FP), we incure a **$500 cost** as a need to re-acquire a new customer\n",
    "\n",
    "3. When we correctly predict no-default (TN), we make **$1000 profit** from customer life-time value.\n",
    "\n",
    "4. When we incorrectly predict no-default (FN), we incure a **$300 cost** from the contract.\n",
    "\n",
    "Thus, since our model's goal is to optimize for a business outcome, evaluating model performance with metrics such as accuracy or recall alone might not be enough! So, we turn to Arize for help!\n",
    "\n",
    "###**Business Impact Figure**\n",
    "\n",
    "![image.png](https://storage.googleapis.com/arize-assets/fixtures/business-impact-final.png)\n",
    "\n",
    "###**For more explaination of how the payoff curve and business impact works, visit our Documentations Page.**\n",
    "\n",
    "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://arize.gitbook.io/arize/platform-features/business-impact-draft)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFzpovENe2Cx"
   },
   "source": [
    "# Step 3: Analyze Payoff Curve on Arize\n",
    "## **The Business Impact Tab**\n",
    "1. Once production data show up, click on **Business Impact** tab. Select **`fraud`** under **`Select Prediction Value`** dropdown.\n",
    "\n",
    "2. Copy the following formula we determined for estimating business impact.\n",
    "\n",
    "```10 * TP_COUNT + 1000 * TN_COUNT - 500 * FP_COUNT -  300 * FN_COUNT```\n",
    "\n",
    "## **Video Demo 1: Customer Business Impact Formula**\n",
    "After entering the formula, you should see a shift in the business impact curve like below.\n",
    "\n",
    "![Button_Open.png](https://storage.googleapis.com/arize-assets/fixtures/business-impact-rec-1-v2.gif)\n",
    "\n",
    "Based on this curve, we could see that the best decision boundary for our business outcome should be between 0.4 - 0.65 $Pr(X = \\texttt{fraud})$ for our score categorical model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK3tQtEad2o0"
   },
   "source": [
    "## **Video Demo 2: Comparing Model Impact**\n",
    "Now, we want to see which one of our model performs better in accordance to our business impact formula. Following the same steps:\n",
    "\n",
    "1. Select **`fraud`** under **`Select Prediction Value`** dropdown.\n",
    "\n",
    "2. Select **`2.0 validation `** under **`Compare against`** dropdown.\n",
    "\n",
    "3. Copy the same formula we determined for estimating business impact.\n",
    "\n",
    "![Button_Open.png](https://storage.googleapis.com/arize-assets/fixtures/business-impact-rec-2-v2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MikOQy8kHx2O"
   },
   "source": [
    "### Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Business_Impact.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

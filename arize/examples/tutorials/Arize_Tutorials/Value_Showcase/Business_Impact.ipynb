{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Business Impact.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iixIYFYvUtUL"
   },
   "source": [
    "# Getting Started with the Arize Platform - Comparing Business Impact\n",
    "\n",
    "**In this walkthrough, we are going to look at how to use  Arize to measure business impact in production!**\n",
    "\n",
    "You manage the default/fraud detection model for the widely used [Lending Club](https://www.lendingclub.com/). One of your model is already in production and serving customers, but now you have a newly fitted model that you would like to compare with the production model.\n",
    "\n",
    "Specifically, **you want to see which model has better impact on your business objectives in production**, so you turn to Arize for investigation. We will explain what \"Business Impact\" means when we get to Step 2: Understanding Business Impact\n",
    "\n",
    "\n",
    "\n",
    "## Our steps to resolving this issue will be :\n",
    "\n",
    "1. Get our model onto the Arize platform to investigate\n",
    "2. Enter formula for evaluating business impact\n",
    "3. Compare the model in production and the new model we want to validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jGvz-LwUkYg"
   },
   "source": [
    "# Step 1: Setup and Getting the Data\n",
    "### Step 1.1: Loading data from Arize client\n",
    "We will load in some pre-existing data for the Lending Club model - training data, features, predictions, and class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f4BQqsb1h_iS"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import datetime\n",
    "\n",
    "# 1 Load data from our model already in production\n",
    "production = pd.read_csv('https://storage.googleapis.com/arize-assets/fixtures/impact-production.csv').iloc[:,1:]\n",
    "\n",
    "# 2 Load validation data for our new model\n",
    "validation = pd.read_csv('https://storage.googleapis.com/arize-assets/fixtures/impact-validation.csv').iloc[:,1:]\n",
    "\n",
    "# 3 Unpack data so we can log them to Arize later!\n",
    "def unpack_data(data):\n",
    "    X, y = data.drop(columns=['label', 'prediction', 'score']), data['label']\n",
    "    pred, score = data['prediction'], data['score']\n",
    "    return X, y, pred, score\n",
    "\n",
    "X_val, y_val, y_val_pred, y_val_score = unpack_data(validation)\n",
    "X_prod, y_prod, y_prod_pred, y_prod_score = unpack_data(production)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTJgOtGdiAOg"
   },
   "source": [
    "### Step 1.2: Setting up Arize Client:\n",
    "First, copy the Arize `API_KEY` and `ORG_KEY` from your admin page linked below!\n",
    "\n",
    "\n",
    "[![Button_Open.png](https://storage.googleapis.com/arize-assets/fixtures/Button_Open.png)](https://app.arize.com/admin)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WFvFOphXfa1I",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bec9dad3-1c80-45d6-cca1-6e09e372759c"
   },
   "source": [
    "!pip install arize -q\n",
    "from arize.api import Client\n",
    "import concurrent.futures as cf\n",
    "from arize.utils.types import ModelTypes\n",
    "\n",
    "# Step 1: Set-up Arize Client and model meta data\n",
    "ORGANIZATION_KEY = 'YOUR_ORGANIZATION_KEY'\n",
    "API_KEY = 'YOUR_API_KEY'\n",
    "arize = Client(organization_key=ORGANIZATION_KEY, api_key=API_KEY)\n",
    "\n",
    "model_id = 'business-impact-demo'\n",
    "model_type = ModelTypes.SCORE_CATEGORICAL\n",
    "\n",
    "if (ORGANIZATION_KEY == 'ORGANIZATION_KEY' or API_KEY == 'API_KEY'):\n",
    "    raise ValueError(\"‚ùå NEED TO CHANGE ORGANIZATION AND/OR API_KEY\")\n",
    "else:\n",
    "    print(\"‚úÖ Arize setup complete!\")\n",
    "\n",
    "# Step 2: Some helpful helper functions for later\n",
    "def arize_responses_helper(responses):\n",
    "    for response in cf.as_completed(responses):\n",
    "        res = response.result()\n",
    "        if res.status_code != 200:\n",
    "            raise ValueError(f'future failed with response code {res.status_code}, {res.text}')\n",
    "\n",
    "def simulate_production_timestamps(num_entries, days=30):\n",
    "    \"\"\"\n",
    "    Takes in: number of entries used for bulk_log, and number of days we want simulate back trace\n",
    "    Returns prediction_timestamps arguement for bulk_log, uniformally distributed over time period\n",
    "    \"\"\"\n",
    "    current_time = datetime.datetime.now().timestamp()\n",
    "    earlier_time = (datetime.datetime.now() - datetime.timedelta(days=days)).timestamp()\n",
    "    optional_prediction_timestamp = np.linspace(earlier_time, current_time, num=num_entries)\n",
    "    optional_prediction_timestamp = pd.Series(optional_prediction_timestamp.astype(int))\n",
    "    return optional_prediction_timestamp"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "‚úÖ Arize setup complete!\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNyrYmrXuCYk"
   },
   "source": [
    "### Step 1.3: Logging Model Version 1 (Production) to Arize\n",
    "First, we take our existing model that's serving in production (Model version 1.0) and use the Arize SDK to log our predictions, actuals, and features. For more details on how **`arize.bulk_log`** or **`arize.log_validation_records`** works, visit out documentations page below.\n",
    "\n",
    "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://arize.gitbook.io/arize/apis/python-sdk-1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A8OAr7VI7H7P"
   },
   "source": [
    "log_bulk_responses = arize.bulk_log(\n",
    "    model_id=model_id,\n",
    "    model_version='1.0',\n",
    "    model_type=model_type,\n",
    "    prediction_ids=pd.Series([str(uuid.uuid4()) for _ in range(len(y_prod))]),\n",
    "    prediction_labels=pd.DataFrame({'prediction_labels': y_prod_pred,\n",
    "                                    'prediction_scores': y_prod_score\n",
    "                                    }),\n",
    "    actual_labels=y_prod,\n",
    "    features=X_prod,\n",
    "    prediction_timestamps=simulate_production_timestamps(len(y_prod), days=30),\n",
    ")\n",
    "\n",
    "arize_responses_helper(log_bulk_responses)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_q-jPkADvV88"
   },
   "source": [
    "### Step 1.4: Logging Model Version 2 (Validation) to Arize\n",
    "Next, we log our Model version 2.0 as validation to the Arize platform. With both models logged, we will be able to compare their performance using the business impact page!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TB4Dffc47IXs"
   },
   "source": [
    "validation_responses = arize.log_validation_records(\n",
    "    batch_id = 'validation',\n",
    "    model_id=model_id,\n",
    "    model_version='2.0',\n",
    "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
    "    prediction_labels=y_val_pred,\n",
    "    prediction_scores=y_val_score,\n",
    "    actual_labels=y_val,\n",
    "    features=X_val,\n",
    "    )\n",
    "\n",
    "arize_responses_helper(validation_responses)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkqXm_gEvOZd"
   },
   "source": [
    "## Coffee Time ‚òïÔ∏è\n",
    "Note that the Arize performs takes about 10 minutes to index the data. While the model should appear immediately, the data will not show up till the indexing is done. Feel free to go grab a cup of coffee as Arize works its magic! üîÆ\n",
    "\n",
    "Your Prediction Volume may look slightly different!\n",
    "\n",
    "![image.png](https://storage.googleapis.com/arize-assets/fixtures/waiting-on-data.png)\n",
    "\n",
    "Actual data will show up under **Model Health**. Once the number changes from **0 Actuals** to **Actuals** (with summary statistics listed in the drop-down), your production actuals will have been fully recorded on Arize!\n",
    "\n",
    "![image.png](https://storage.googleapis.com/arize-assets/fixtures/waiting-on-actual-data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x82YyZPUoXF"
   },
   "source": [
    "# Step 2: Understanding Business Impact\n",
    "Sometimes, metrics such as accuracy and recall can't perfectly describe the business objective the model is trying to serve.\n",
    "### **The Fraud Detection Example**\n",
    "\n",
    "In our toy example, we run a default/fraud detection model for the lending club. In this business model, there are financial outcomes that change depending on whether our our model predicted `true` or `false` on a model, in addition to whether those predictions were accurate. **See Business Impact Figure for an example of how this works!**\n",
    "\n",
    "1. When we correct predict default (TP), we save **$10 profit** from admin fees.\n",
    "\n",
    "2. When we incorrectly predict default (FP), we incure a **$500 cost** as a need to re-acquire a new customer\n",
    "\n",
    "3. When we correctly predict no-default (TN), we make **$1000 profit** from customer life-time value.\n",
    "\n",
    "4. When we incorrectly predict no-default (FN), we incure a **$300 cost** from the contract.\n",
    "\n",
    "Thus, since our model's goal is to optimize for a business outcome, evaluating model performance with metrics such as accuracy or recall alone might not be enough! So, we turn to Arize for help!\n",
    "\n",
    "###**Business Impact Figure**\n",
    "\n",
    "![image.png](https://storage.googleapis.com/arize-assets/fixtures/business-impact-final.png)\n",
    "\n",
    "###**For more explaination of how the payoff curve and business impact works, visit our Documentations Page.**\n",
    "\n",
    "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://arize.gitbook.io/arize/platform-features/business-impact-draft)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFzpovENe2Cx"
   },
   "source": [
    "# Step 3: Analyze Payoff Curve on Arize\n",
    "## **The Business Impact Tab**\n",
    "1. Once production data show up, click on **Business Impact** tab. Select **`fraud`** under **`Select Prediction Value`** dropdown.\n",
    "\n",
    "2. Copy the following formula we determined for estimating business impact.\n",
    "\n",
    "**$f(x) = \\texttt{10 * TP_COUNT + 1000 * TN_COUNT - 500 * FP_COUNT -  300 * FN_COUNT} $**\n",
    "\n",
    "## **Video Demo 1: Customer Business Impact Formula**\n",
    "After entering the formula, you should see a shift in the business impact curve like below.\n",
    "\n",
    "![Button_Open.png](https://storage.googleapis.com/arize-assets/fixtures/business-impact-rec-1.gif)\n",
    "\n",
    "Based on this curve, we could see that the best decision boundary for our business outcome should be between 0.4 - 0.65 $Pr(X = \\texttt{fraud})$ for our score categorical model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK3tQtEad2o0"
   },
   "source": [
    "## **Video Demo 2: Comparing Model Impact**\n",
    "Now, we want to see which one of our model performs better in accordance to our business impact formula. Following the same steps:\n",
    "\n",
    "1. Select **`fraud`** under **`Select Prediction Value`** dropdown.\n",
    "\n",
    "2. Select **`2.0 validation `** under **`Compare against`** dropdown.\n",
    "\n",
    "3. Copy the same formula we determined for estimating business impact.\n",
    "\n",
    "![Button_Open.png](https://storage.googleapis.com/arize-assets/fixtures/business-impact-rec-2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}

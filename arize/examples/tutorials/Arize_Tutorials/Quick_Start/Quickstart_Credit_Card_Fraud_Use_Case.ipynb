{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0TvdSg5HC3Q"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"200\"/>\n",
        "\n",
        "#Quickstart Guide - Credit Card Fraud in the Banking Industry\n",
        "\n",
        "**You are responsible for a credit card fraud model at a large bank or payment processing company. You have been alerted by a spike in credit card chargebacks leading you to suspect that fraudsters are getting away with commiting fraud undetected!** Realizing that this flaw in your model's performance has a heavy cost on your company and customers, you turn to Arize to find out what changed in your credit card fraud detection model and how you can improve it.\n",
        "\n",
        "In this walkthrough, we are going to investigate your production credit card fraud model. We will validate degradation in model performance, troubleshoot the root cause, and furthermore set up proactive monitors to mitigate the impact of future degradations.  \n",
        "\n",
        "Our steps to resolving this issue will be:\n",
        "1. Get our model onto the Arize platform to investigate\n",
        "2. Setup a performance dashboard to look at prediction performance\n",
        "3. Understand where the model is underperforming\n",
        "4. Discover the root cause of why a slice (grouping) of predictions is underperforming\n",
        "5. Set up proactive monitoring to mitigate the impact of such degradations in the future\n",
        "\n",
        "**The production data contains 1 month of data where 2 main issues exist. You will work on identifying these issues over the course of this exercise:**\n",
        "\n",
        "1. An upstream data source has introduced bad (null) values for ENTRY_MODE \n",
        "2. The model is missing fraud for certain merchant types,entry modes and merchant ids especially in certain regions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OHUs0p6HCsX"
      },
      "source": [
        "# Step 0. Setup and Getting the Data\n",
        "\n",
        "The first step is to load our preexisting dataset which includes training and production environments for our credit card fraud model. Using a preexisting dataset illustrates how simple it is to get started with the Arize platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDVA4kK5HHqa"
      },
      "source": [
        "## Install Dependencies and Import Libraries üìö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCKzp837HOHN"
      },
      "outputs": [],
      "source": [
        "!pip install -q arize\n",
        "\n",
        "\n",
        "import datetime\n",
        "import tempfile\n",
        "import uuid\n",
        "from datetime import timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import Environments, ModelTypes\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C8bwEnXHHnx"
      },
      "source": [
        "## **üåê Download the Data**\n",
        "In this walkthrough, we‚Äôll be sending real historical data (with privacy conscious changes to feature names and values). Note, that while feature names and values are made explicit in this dataset, you can achieve the same level of ML Observability using obfuscated features. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJfb08E-HArO"
      },
      "outputs": [],
      "source": [
        "production = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/arize-assets/fixtures/Tags-Demo-Data/credit_card_fraud_production.csv\",\n",
        ")\n",
        "train = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/arize-assets/fixtures/Tags-Demo-Data/credit_card_fraud_training.csv\",\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Data successfully downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG0pz7_AdZWb"
      },
      "source": [
        "## Inspect the Data \n",
        "\n",
        "Take a quick look at the dataset. The data represents a model designed and trained to evaluate the probability of a credit card transaction being fraud based on various features such as merchant_type, mean_amount, transaction amount, entry_mode, etc. The dataset contains one month of data and the performance will be evaluated by comparing:\n",
        "\n",
        "*   **PREDICTION**: The probability of a fraud transaction predicted by the model \n",
        "*   **ACTUAL**: Fraud or not fraud based on ground truth collected by credit card users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nAO3wHFHsuF"
      },
      "outputs": [],
      "source": [
        "production.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiKjDrTG_2sN"
      },
      "outputs": [],
      "source": [
        "feature_column_names = [\n",
        "    \"MERCHANT_TYPE\",\n",
        "    \"MERCHANT_ID\",\n",
        "    \"ENTRY_MODE\",\n",
        "    \"STATE\",\n",
        "    \"MEAN_AMOUNT\",\n",
        "    \"STD_AMOUNT\",\n",
        "    \"TX_AMOUNT\",\n",
        "    \"VISA_RISK_SCORE\",\n",
        "    \"MASTERCARD_RISK_SCORE\",\n",
        "    \"AMEX_RISK_SCORE\",\n",
        "]\n",
        "shap_column_names = [f\"{x}_shap\" for x in feature_column_names]\n",
        "tag_column_names = ['Dependents', 'Partner', 'EmploymentStatus', 'LocationCode', 'Education', 'Gender', 'Age']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgJKldiSH6OL"
      },
      "source": [
        "# Step 1. Sending Data into Arize üí´\n",
        "\n",
        "Now that we have our dataset imported, we are ready to integrate into Arize. We do this by logging (sending) important data we want to analyze to the platform. There, the data will be easily visualized and troubleshooting workflows will help us find the source of our problem.\n",
        "\n",
        "For our model, we are going to log:\n",
        "*   feature data\n",
        "*   predictions\n",
        "*   actuals\n",
        "\n",
        "## Import and Setup Arize Client\n",
        "\n",
        "The first step is to setup our Arize client. After that we will log the data for our model.\n",
        "\n",
        "First, copy the Arize `API_KEY` and `SPACE_KEY` from your **Demo Model** page under **Quickstart** shown below! Copy those over to the set-up section in the code snippet. We will also be setting up some metadata to use across all logging.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnOIGeFsKDYs"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/quickstart-keys.gif\" width=\"700\">\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/quickstart-keys2.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XJANcnXH6kT"
      },
      "outputs": [],
      "source": [
        "# Connect to your Arize client\n",
        "SPACE_KEY = \"SPACE_KEY\"\n",
        "API_KEY = \"API_KEY\"\n",
        "\n",
        "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
        "\n",
        "model_id = (\n",
        "    \"creditcard-fraud-demo-model\"  # This is the model name that will show up in Arize\n",
        ")\n",
        "model_version = \"v1.0\"  # Version of model - can be any string\n",
        "\n",
        "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else:\n",
        "    print(\"‚úÖ Arize setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVIZgl2oIHGt"
      },
      "source": [
        "## Log Training & Production Data to Arize \n",
        "\n",
        "Now that our Arize client is setup, let's go ahead and log all of our data to the platform. For more details on how **`arize.pandas.logger`** works, visit out documentation page below.\n",
        "\n",
        "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)\n",
        "\n",
        "Key parameters:\n",
        "\n",
        "*   **prediction_label_column_name**: tells Arize which column contains the predictions\n",
        "*   **actual_label_column_name**: tells Arize which column contains the actual results from field data\n",
        "*   **preidction_score_column_name**: tells Arize which column contains the prediction score from field data\n",
        "*   **actual_label_column_name**: tells Arize which column contains the actual results from field data\n",
        "*   **actual_score_column_name**: tells Arize which column contains the actual score from field data\n",
        "\n",
        "Given that our model is predicting between categories, the model type we will use will be [ModelTypes.SCORE_CATEGORICAL](https://docs.arize.com/arize/product-guides-1/models/model-types) to perform this analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbFoahq4IMfd"
      },
      "source": [
        "## Log Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLJMK3UeIJMk"
      },
      "outputs": [],
      "source": [
        "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
        "training_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",\n",
        "    prediction_label_column_name=\"PREDICTION\",\n",
        "    prediction_score_column_name=\"PREDICTION_SCORE\",\n",
        "    actual_label_column_name=\"ACTUAL\",\n",
        "    actual_score_column_name=\"ACTUAL_SCORE\",\n",
        "    feature_column_names=feature_column_names,\n",
        "    tag_column_names = tag_column_names,\n",
        ")\n",
        "\n",
        "# Logging Training DataFrame\n",
        "training_response = arize_client.log(\n",
        "    dataframe=train,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
        "    environment=Environments.TRAINING,\n",
        "    schema=training_schema,\n",
        ")\n",
        "\n",
        "# If successful, the server will return a status_code of 200\n",
        "if training_response.status_code != 200:\n",
        "    print(\n",
        "        f\"logging failed with response code {training_response.status_code}, {training_response.text}\"\n",
        "    )\n",
        "else:\n",
        "    print(f\"‚úÖ You have successfully logged training set to Arize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRQdEXZDIvMo"
      },
      "source": [
        "## Log Production Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoWpauUWIsmm"
      },
      "outputs": [],
      "source": [
        "# Changing dates for ease of visualization / to mimic recent production dataset\n",
        "END_DATE = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
        "START_DATE = (datetime.date.today() - timedelta(31)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "\n",
        "def setPredictionIDandTime(df, start, end):\n",
        "    out_df = pd.DataFrame()\n",
        "    dts = pd.date_range(start, end).to_pydatetime().tolist()\n",
        "    for dt in dts:\n",
        "        day_df = df.loc[df[\"day\"] == dt.day].copy()\n",
        "        day_df[\"prediction_ts\"] = int(dt.strftime(\"%s\"))\n",
        "        out_df = pd.concat([out_df, day_df], ignore_index=True)\n",
        "    out_df[\"prediction_id\"] = [str(uuid.uuid4()) for _ in range(out_df.shape[0])]\n",
        "    return out_df.drop(columns=\"day\")\n",
        "\n",
        "\n",
        "production = setPredictionIDandTime(production, START_DATE, END_DATE)\n",
        "\n",
        "production_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",\n",
        "    timestamp_column_name=\"prediction_ts\",\n",
        "    prediction_label_column_name=\"PREDICTION\",\n",
        "    prediction_score_column_name=\"PREDICTION_SCORE\",\n",
        "    actual_label_column_name=\"ACTUAL\",\n",
        "    actual_score_column_name=\"ACTUAL_SCORE\",\n",
        "    feature_column_names=feature_column_names,\n",
        "    shap_values_column_names=dict(zip(feature_column_names, shap_column_names)),\n",
        "    tag_column_names = tag_column_names,\n",
        ")\n",
        "\n",
        "production_response = arize_client.log(\n",
        "    dataframe=production,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
        "    environment=Environments.PRODUCTION,\n",
        "    schema=production_schema,\n",
        ")\n",
        "\n",
        "if production_response.status_code != 200:\n",
        "    print(\n",
        "        f\"logging failed with response code {production_response.status_code}, {production_response.text}\"\n",
        "    )\n",
        "else:\n",
        "    print(f\"‚úÖ You have successfully logged production set to Arize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GRDmDYmJWFt"
      },
      "source": [
        "# Step 2. Confirm Data in Arize ‚úÖ\n",
        "\n",
        "Note that the Arize takes about 10 minutes to index the data. While the model should appear immediately, the data will not show up until the indexing is complete. Feel free to head over to the **Data Ingestion** tab for your model to watch Arize works its magic!üîÆ\n",
        "\n",
        "**‚ö†Ô∏è DON'T SKIP:**\n",
        "In order to move on to the next step, make sure your actuals and training/production sets are loaded into the platform. To check:\n",
        "1. Navigate to the **Models** page from the left bar, locate and click on model **arize-demo-creditcard-fraud**\n",
        "2. On the **Overview Tab**, make sure you can see Predictions and Actuals under the **Model Health** section. Once production actuals have been fully recorded on Arize, the row title will change from **0 Actuals** to **Actuals** with summary statistics such as cardinality listed in the tables.\n",
        "3. Verify the list of **Features** below **Actuals**.\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/fraud_overview.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkgBBB0IMHmv"
      },
      "source": [
        "# Step 3. Set up Model Baseline\n",
        "\n",
        "Now that our data has been logged into the [Arize platform](https://app.arize.com/) we can begin our investigation into our poorly performing fraud detection model. \n",
        "\n",
        "Arize will guide you through setting up a **Baseline** (reference environment for comparison) and automatically create **Monitors** for your model in just a few clicks ‚Äîjust follow the blue banner at the top of the page titled \"Finish setting up your model\". \n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/Click-Through%20Rate%20Use-Case/images/initial_setup_banner.png)\n",
        "\n",
        "Arize can automatically configure monitors that are best suited to your data. From the banner at the top of the screen, select the following configurations after clicking the 'Set up Model' button: \n",
        "\n",
        "1. Datasets: `Training Version 1.0`\n",
        "2. Default Metric: `False Negative Rate`, Trigger Alert When: `False Negative Rate is above .2`, Positive Class: `FRAUD`\n",
        "3. Turn On Monitoring: Drift ‚úÖ, Data Quality ‚úÖ, Performance ‚úÖ \n",
        "\n",
        "You will now see that the baseline has been set and **Drift**, **Data Quality**, and **Performance** monitors have been created!!! \n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/fraud_setupbaseline.gif)\n",
        "\n",
        " \n",
        "To prevent expensive chargebacks from getting by our models undetected Arize automatically sets up monitors to ensure our model is flagged if Performance, Data Quality, or Drift spikes above a certain threshold/before it becomes a major issue. You can filter monitors by category, edit evaluation windows, thresholds, etc. and create custom monitors by visiting the **Monitors** tab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA-2w3x9UG7b"
      },
      "source": [
        "# Step 4. Performance Analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IhJexvtUEQW"
      },
      "source": [
        "Once a performance monitor is triggered, navigate to the **Performance** tab to start troubleshooting your model issues and gain an understanding of what caused the degradation. The false negative rate (our default performance metric) is plotted over the last 30 days and it is overlaid on top of bars which measure the volume of predictions. Our model is doing pretty well but there have been a few spikes in false negative rate down to ~0.2 so let's look into what could be driving performance down.\n",
        "\n",
        "If you scroll down, the **Output Segmentation** section includes a confusion matrix which is useful for our model as it is assigning a class to the prediction.\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/perftab_fraud_overview.png)\n",
        "\n",
        "Let's scroll down even further to the **Performance Breakdown by Feature**, this section is very useful to uncover low performing cohorts within a feature. SHAP (Shapley Additive exPlanations) is a technique that breaks down individual predictions of a complex model to assign feature importance scores. Since this model is producing SHAP values for every prediction, Arize is able to use those SHAP values and Drift (PSI) to weight performance within each feature to create a **Performance Impact Score**. By sorting by this score instead of just feature importance or min/max performance, Arize is able to surface to the top, the top features that are attributing to decreased performance.\n",
        "\n",
        "At the top of the **Performance Breakdown by Feature** list is `STATE` so let's expand this feature. Now we see a list of the inputs to this feature which are a couple of categorical values. By hovering over bar, Arize displays the volume that this input was utilized in predictions and the performance metric for that cohort. \n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/cc_fraud_state_perf.png)\n",
        "\n",
        "**We can start by comparing the production to training dataset.** This can help answer questions such as \"Were we seeing this problem in training?\" or \"Does my new / previous model version perform better?\". It can also be helpful to compare to other windows of production.\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/perf_tab_fraud.gif)\n",
        "\n",
        "\n",
        "\n",
        "Here, we can identify low performing segments. By looking at performance breakdown by feature, you can dig even deeper to see which segment within each feature of the model is underperforming. In this case, we are filtering on `STATE`=`CA`, we observe `ENTRY_MODE`, which has the highest performance impact, comes to the top.\n",
        "\n",
        "Some of the immediate insights surfaced from the **Feature Performance Tab** are detailed below. \n",
        "1. Worst performing `ENTRY_MODE` includes `credentials_on_file`, followed by `manual`, and `_NULL`\n",
        "2. Worst performing `MERCHANT_TYPE` includes `Religious Organizations`,`Online Food Delivery`, and `Tax Payments`\n",
        "3. Worst performing `MERCHANT_ID` includes `FL`, `CA`, and `NY`\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/cc_fraud_perf_tab_entry_mode_filteron_ca.png)\n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/cc_fraud_perf_tab_merchant_type_filteron_Ca.png)\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/cc_fraud_perf_tab_merchant_id_filteron_ca.png)\n",
        "\n",
        "Moreover, we can compare the overall production dataset to other windows of production. Here, we can investigate what the production dataset looks like in a low performing segment. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/fraud_perftabx2.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5. Exploring Drift\n"
      ],
      "metadata": {
        "id": "zyyyavziATfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction Drift Impact** can surface when drift has impacted your model. **Drift** (PSI) is a measurement of how much your distribution has drifted. Lastly, Feature Importance helps you explain why even small **Drift** (PSI) can have significant Drift Impact.\n",
        "\n",
        "Selecting the **Drift** tab we notice a discernible model prediction drift in production compared to our training dataset (baseline) for a period of 4 days. By taking a look at the **Distribution Comparison** beneath the **Prediction Drift over Time** widget we notice that in our training dataset (Baseline Distribution) we expect to see around 1% FRAUD whereas in our production dataset (Current Distribution) we see highs of almost 25% FRAUD!\n",
        " \n",
        " \n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/prediction_drift_fraud.gif)\n"
      ],
      "metadata": {
        "id": "tqWHKyLeAZ6z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX7enXEbYR79"
      },
      "source": [
        "# Step 6. Feature Performance Insights and Data Quality Checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ObKzcnvYR5c"
      },
      "source": [
        "Using the insights gathered from the **Feature Performance Tab**, we can take action to 1) prevent this type of fraud abuse from going undetected in the future and 2) use our findings to improve our model. As noted previously, the slice (feature/value combination) `ENTRY_MODE: credentials_on_file` was one of the worst performing segments for our model. Navigate back to the **Drift** tab and click into the `ENTRY_MODE` feature under the **Feature Drift** section. \n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/entry_mode.gif)\n",
        "\n",
        "Upon first glance, we see that `ENTRY_MODE` is starting to drift around 19th December. By clicking on the high drift region, we noice that our training dataset (Baseline distribution) did not have any `_NULL` values. Clicking on the **Data Quality** tab, we can confirm the cardinality of the feature increased on the 19th and started falling back down 6 days later. \n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/entry_mode_drift.png)\n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/data_quality_check.gif)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jZ9lFAebcpX"
      },
      "source": [
        "# üìö Conclusion \n",
        "In this walkthrough we've shown how Arize can be used to log prediction data for a model, pinpoint model performance degradations, and set up monitors to proactively catch future issues. \n",
        "\n",
        "We completed the following tasks: \n",
        "1. Uploaded data from a credit card transaction fraud model \n",
        "2. Set up a model baseline (Training V1.0) and managed Performance, Data Quality, and Drift monitors\n",
        "3. Created a Feature Performance Heatmap to surface low performing cohorts impacting our model which helped narrow down our undetected fraudulent transactions to certain `ENTRY_MODE`s and `MERCHANT_TYPE`s coming from a few specific `STATE`s.\n",
        "4. Identified correlations between our model's degrading performance with individual feature drift and distribution variance.\n",
        "\n",
        "We identified the following areas of concern: \n",
        "1. `_NULL` values for the feature `ENTRY_MODE`. This leads us to believe that we need to upsample this type of feature/value combination or fix an upstream datasource to omit this undetermined value. \n",
        "2. Suspicious activity coming from `MERCHANT_TYPE`: `Online Food Delivery`, `Religious Organizations`, `Pawn Shops and Salvage Yards`, `Automotive Tire Sotres`, and  `Tax Payments`, `ENTRY_MODE` : `credential_on_file` and `manual`. Specifically we noticed drift of these categories fluctuating on certain dates and coming from a small subset of `STATES`, namely `CA`, and `NY`. We must look into the POS systems across these states to understand what type of organized fraud is happening from these regions while retraining our model to detect anomalous food delivery and erroneous tax payment transactions. \n",
        "3. We also noticed that our model performs poorly on certain `MERCHANT_ID`s when filtered on `STATES`, namely `CA`, and `NY`. Perhaps a new model strategy is needed to form stronger inferences. \n",
        "\n",
        "Though we covered a lot of ground, this is just scratching the surface of what the Arize platform can do. We urge you to explore more of Arize, either on your own or through one of our many other tutorials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es52tD8lbceL"
      },
      "source": [
        "# About Arize\n",
        "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
        "- Automated ML monitoring and model monitoring\n",
        "- Workflows to troubleshoot model performance\n",
        "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
        "- Model prediction cohort analysis\n",
        "- Pre-deployment model validation\n",
        "- Integrated model explainability\n",
        "\n",
        "### Website\n",
        "Visit Us At: https://arize.com/model-monitoring/\n",
        "\n",
        "### Additional Resources\n",
        "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
        "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
        "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
        "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
        "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
        "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
        "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
        "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
        "\n",
        "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Quickstart Credit Card Fraud Use Case.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "ec6620dbdb1ae7ae605320a7ce7472136ac4f41aa18fe452eefaab7683971943"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit (conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Arize AI Quick Start: Training and Serving Models with Microsoft Azure ML\n",
    "\n",
    "##### NOTE: We do not recommend using *Run All* because it takes several minutes to deploy and update models; models cannot be queried until they are active.\n",
    "\n",
    "This part of the guide consists of the following sections:\n",
    "\n",
    "#### Setup\n",
    "* Launch an Azure Databricks cluster\n",
    "* Install Arize SDK\n",
    "* Install MLflow\n",
    "* Install the Azure ML SDK\n",
    "* Create or load an Azure ML Workspace\n",
    "\n",
    "\n",
    "#### Training a Model\n",
    "* Use MLflow Tracking to track experiment\n",
    "\n",
    "#### Building an Azure Container Image for model deployment\n",
    "* Use MLflow to build a Container Image for the trained model\n",
    "\n",
    "#### Deploy the model to expose a consumable API using Azure Container Instances (ACI)\n",
    "* Create an ACI webservice deployment using the model's Container Image\n",
    "\n",
    "#### Querying the deployed model in ACI\n",
    "* Load a sample input vector from the diabetes dataset\n",
    "* Evaluate the sample input vector by sending an HTTP request\n",
    "\n",
    "#### Publishing prediction results to Arize\n",
    "* Log resulting prediction output along with input vector using Arize's SDK\n",
    "\n",
    "#### Alternatively, if using Kubernetes: Deploy the model using Azure Kubernetes Service (AKS)\n",
    "* Option 1: Create a new AKS cluster\n",
    "* Option 2: Connect to an existing AKS cluster\n",
    "* Deploy to the model's image to the specified AKS cluster\n",
    "\n",
    "#### Querying the deployed model in AKS\n",
    "* Load a sample input vector from the wine dataset\n",
    "* Evaluate the sample input vector by sending an HTTP request\n",
    "\n",
    "#### Updating the AKS deployment\n",
    "* Build an Azure Container Image for another model\n",
    "* Deploy the new model's image to the AKS cluster\n",
    "* Query the updated model\n",
    "\n",
    "#### Cleaning up the deployments\n",
    "* Terminate the ACI webservice\n",
    "* Terminate the AKS webservice\n",
    "* Remove the AKS cluster from the Azure ML Workspace\n",
    "\n",
    "This notebook uses the `diabetes` dataset in scikit-learn and predicts the progression metric (a quantitative measure of disease progression after one year after) based on BMI, blood pressure, etc. It uses the scikit-learn ElasticNet linear regression model, where we vary the `alpha` and `l1_ratio` parameters for tuning. For more information on ElasticNet, refer to:\n",
    "  * [Elastic net regularization](https://en.wikipedia.org/wiki/Elastic_net_regularization)\n",
    "  * [Regularization and Variable Selection via the Elastic Net](https://web.stanford.edu/~hastie/TALKS/enet_talk.pdf)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note:** This notebook expects that you use a Databricks hosted MLflow tracking server. If you would like to preview the Databricks MLflow tracking server, contact your Databricks sales representative to request access. To set up your own tracking server, see the instructions in [MLflow Tracking Servers](https://www.mlflow.org/docs/latest/tracking.html#mlflow-tracking-servers) and configure your connection to your tracking server by running [mlflow.set_tracking_uri](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_tracking_uri)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Ensure you are using or create a cluster specifying\n",
    "  * **Databricks Runtime Version:** Databricks Runtime 5.0 or above\n",
    "  * **Python Version:** Python > 3.5.3\n",
    "1. Install required libraries or if using Databricks Runtime 5.1 or above, run Cmd 5.\n",
    "   1. Create required libraries.\n",
    "    * Source **PyPI** and enter `arize`.\n",
    "    * Source **PyPI** and enter `mlflow[extras]`. This installs mlflow and all its dependencies.\n",
    "    * Source **PyPI** and enter `azureml-sdk[databricks]`.\n",
    "   1. Install the libraries into the cluster.\n",
    "1. Attach this notebook to the cluster."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install arize mlflow[extras] azureml-sdk[databricks]"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Write Your ML Code Based on the`train_diabetes.py` Code\n",
    "This tutorial is based on the MLflow's [train_diabetes.py](https://github.com/mlflow/mlflow/blob/master/examples/sklearn_elasticnet_diabetes/train_diabetes.py) example, which uses the `sklearn.diabetes` built-in dataset to predict disease progression based on various factors."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Import various libraries including matplotlib, sklearn, mlflow\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import lasso_path, enet_path\n",
    "from sklearn import datasets\n",
    "\n",
    "# Import mlflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Load Diabetes datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# Create pandas DataFrame for sklearn ElasticNet linear_model\n",
    "Y = np.array([y]).transpose()\n",
    "d = np.concatenate((X, Y), axis=1)\n",
    "cols = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'progression']\n",
    "data = pd.DataFrame(d, columns=cols)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train the Diabetes Model\n",
    "The next function trains ElasticNet linear regression based on the input parameters of `alpha (in_alpha)` and `l1_ratio (in_l1_ratio)`.\n",
    "\n",
    "In addition, this function uses MLflow Tracking to record its\n",
    "* parameters\n",
    "* metrics\n",
    "* model\n",
    "\n",
    "**Tip:** Use `with mlflow.start_run:` in the Python code to create a new MLflow run. This is the recommended way to use MLflow in notebook cells. Whether your code completes or exits with an error, the `with` context will make sure to close the MLflow run, so you don't have to call `mlflow.end_run`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# train_diabetes\n",
    "#   Uses the sklearn Diabetes dataset to predict diabetes progression using ElasticNet\n",
    "#       The predicted \"progression\" column is a quantitative measure of disease progression one year after baseline\n",
    "#       http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "def train_diabetes(data, in_alpha, in_l1_ratio):\n",
    "  # Evaluate metrics\n",
    "  def eval_metrics(actual, pred):\n",
    "      rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "      mae = mean_absolute_error(actual, pred)\n",
    "      r2 = r2_score(actual, pred)\n",
    "      return rmse, mae, r2\n",
    "\n",
    "  warnings.filterwarnings('ignore')\n",
    "  np.random.seed(40)\n",
    "\n",
    "  # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "  train, test = train_test_split(data)\n",
    "\n",
    "  # The predicted column is \"progression\" which is a quantitative measure of disease progression one year after baseline\n",
    "  train_x = train.drop(['progression'], axis=1)\n",
    "  test_x = test.drop(['progression'], axis=1)\n",
    "  train_y = train[['progression']]\n",
    "  test_y = test[['progression']]\n",
    "\n",
    "  if float(in_alpha) is None:\n",
    "    alpha = 0.05\n",
    "  else:\n",
    "    alpha = float(in_alpha)\n",
    "\n",
    "  if float(in_l1_ratio) is None:\n",
    "    l1_ratio = 0.05\n",
    "  else:\n",
    "    l1_ratio = float(in_l1_ratio)\n",
    "\n",
    "  # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "  with mlflow.start_run():\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "    # Print out ElasticNet model metrics\n",
    "    print('Elasticnet model (alpha=%f, l1_ratio=%f):' % (alpha, l1_ratio))\n",
    "    print('  RMSE: %s' % rmse)\n",
    "    print('  MAE: %s' % mae)\n",
    "    print('  R2: %s' % r2)\n",
    "\n",
    "    # Set tracking_URI first and then reset it back to not specifying port\n",
    "    # Note, we had specified this in an earlier cell\n",
    "    #mlflow.set_tracking_uri(mlflow_tracking_URI)\n",
    "\n",
    "    # Log mlflow attributes for mlflow UI\n",
    "    mlflow.log_param('alpha', alpha)\n",
    "    mlflow.log_param('l1_ratio', l1_ratio)\n",
    "    mlflow.log_metric('rmse', rmse)\n",
    "    mlflow.log_metric('r2', r2)\n",
    "    mlflow.log_metric('mae', mae)\n",
    "    mlflow.sklearn.log_model(lr, \"model\")\n",
    "    modelpath = \"/dbfs/mlflow/test_diabetes/model-%f-%f\" % (alpha, l1_ratio)\n",
    "    mlflow.sklearn.save_model(lr, modelpath)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Experiment with Different Parameters\n",
    "\n",
    "Call `train_diabetes` with different parameters. Later, you'll be able to visualize all these runs in the MLflow experiment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "%fs rm -r dbfs:/mlflow/test_diabetes"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# alpha and l1_ratio values of 0.01, 0.01\n",
    "train_diabetes(data, 0.01, 0.01)\n",
    "\n",
    "# alpha and l1_ratio values of 0.01, 0.75\n",
    "train_diabetes(data, 0.01, 0.75)\n",
    "\n",
    "# alpha and l1_ratio values of 0.01, .5\n",
    "train_diabetes(data, 0.01, .5)\n",
    "\n",
    "# alpha and l1_ratio values of 0.01, 1\n",
    "train_diabetes(data, 0.01, 1)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View the run, experiment, run details, and notebook revision\n",
    "\n",
    "1. Click the **Runs** icon in the notebook context bar to display the Runs sidebar. In the sidebar, you can view the run parameters and metrics. For example: <img src=\"https://docs.databricks.com/_static/images/mlflow/mlflow-notebook-experiments.gif\"/>\n",
    "\n",
    "1. Click the External Link icon <img src=\"https://docs.databricks.com/_static/images/external-link.png\"/> in the Runs context bar to view the notebook experiment. For example: <img src=\"https://docs.databricks.com/_static/images/mlflow/quick-start-nb-experiment.png\"/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create or load an Azure ML Workspace"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before models can be deployed to Azure ML, you must create or obtain an Azure ML Workspace. The `azureml.core.Workspace.create()` function will load a workspace of a specified name or create one if it does not already exist. For more information about creating an Azure ML Workspace, see the [Azure ML Workspace management documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-workspace)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "\n",
    "workspace_name = 'YOUR WORKSPACE NAME'\n",
    "workspace_location = 'YOUR WORKSPACE LOCATION'\n",
    "resource_group = 'YOUR RESOURCE GROUP'\n",
    "subscription_id = 'YOUR SUBSCRIPTION ID'\n",
    "\n",
    "workspace = Workspace.create(name = workspace_name,\n",
    "                             location = workspace_location,\n",
    "                             resource_group = resource_group,\n",
    "                             subscription_id = subscription_id,\n",
    "                             exist_ok=True)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build an Azure Container Image for model deployment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use MLflow to build a Container Image for the trained model\n",
    "\n",
    "Use the `mlflow.azuereml.build_image` function to build an Azure Container Image for the trained MLflow model. This function also registers the MLflow model with a specified Azure ML workspace. The resulting image can be deployed to Azure Container Instances (ACI) or Azure Kubernetes Service (AKS) for real-time serving."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Specify the run ID associated with an ElasticNet training run from. You can find a run ID and model path from the experiment run, which can be found on the run details page:\n",
    "\n",
    "![image](https://docs.azuredatabricks.net/_static/images/mlflow/mlflow-deployment-example-run-info.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "run_id = 'YOU RUN ID OF CHOICE'\n",
    "model_uri = 'runs:/' + run_id + '/model'"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "import mlflow.azureml\n",
    "\n",
    "model_image, azure_model = mlflow.azureml.build_image(model_uri=model_uri,\n",
    "                                                      workspace=workspace,\n",
    "                                                      model_name='model',\n",
    "                                                      image_name='model',\n",
    "                                                      description='Sklearn ElasticNet image for predicting diabetes progression',\n",
    "                                                      synchronous=False)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "model_image.wait_for_creation(show_output=True)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deploy the model to expose a consumable API using [Azure Container Instances (ACI)](https://docs.microsoft.com/en-us/azure/container-instances/)\n",
    "\n",
    "Using the Azure ML SDK, deploy the Container Image for the trained MLflow model to ACI."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "dev_webservice_name = 'diabetes-model'\n",
    "dev_webservice_deployment_config = AciWebservice.deploy_configuration()\n",
    "dev_webservice = Webservice.deploy_from_image(name=dev_webservice_name, image=model_image, deployment_config=dev_webservice_deployment_config, workspace=workspace)\n",
    "\n",
    "dev_webservice.wait_for_deployment()"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query the deployed model in AzureML"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "#### Load diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "#### Create sample input vector\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "Y = np.array([y]).transpose()\n",
    "d = np.concatenate((X, Y), axis=1)\n",
    "cols = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'progression']\n",
    "data = pd.DataFrame(d, columns=cols)\n",
    "sample = data.drop([\"progression\"], axis=1).iloc[[0]]\n",
    "\n",
    "query_input = sample.to_json(orient='split')\n",
    "query_input = eval(query_input)\n",
    "query_input.pop('index', None)\n",
    "\n",
    "#print(query_input)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate the sample input vector by sending an HTTP request\n",
    "Query the ACI webservice's scoring endpoint by sending an HTTP POST request that contains the input vector."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "def query_endpoint_example(scoring_uri, inputs, service_key=None):\n",
    "  headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "  }\n",
    "  if service_key is not None:\n",
    "    headers['Authorization'] = 'Bearer {service_key}'.format(service_key=service_key)\n",
    "\n",
    "  print('Sending batch prediction request with inputs: {}'.format(inputs))\n",
    "  response = requests.post(scoring_uri, data=json.dumps(inputs), headers=headers)\n",
    "  preds = json.loads(response.text)\n",
    "  print('Received response: {}'.format(preds))\n",
    "  return preds"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "dev_webservice.scoring_uri\n",
    "model_id='diabetes-model'\n",
    "model_version='2cdc865cd53a420cb12036ea08c62083'"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "### Arize Helper Utility\n",
    "def construct_feature_map(inputs):\n",
    "  keys = inputs['columns']\n",
    "  values = inputs['data'][0]\n",
    "  print(f'keys: {keys}')\n",
    "  print(f'values: {values}')\n",
    "  features = {}\n",
    "  for i, key in enumerate(keys):\n",
    "    features[key] = str(values[i])\n",
    "  return features\n"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "from arize.api import Client as client\n",
    "from arize.utils.types import ModelTypes\n",
    "\n",
    "## Instantiate arize client\n",
    "SPACE_KEY = 'YOUR ARIZE SPACE KEY'\n",
    "API_KEY = 'YOUR ARIZE API KEY'\n",
    "arize = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
    "\n",
    "dev_prediction = query_endpoint_example(scoring_uri=dev_webservice.scoring_uri, inputs=query_input)\n",
    "\n",
    "prediction_id=str(uuid.uuid4())\n",
    "\n",
    "print('Logging prediction to arize: {}'.format(prediction_id))\n",
    "arize.log_prediction(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=ModelTypes.NUMERIC,\n",
    "    prediction_id=prediction_id,\n",
    "    prediction_label=dev_prediction[0],\n",
    "    features=construct_feature_map(query_input))"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Alternatively, if using Kubernetes: Deploy the model using [Azure Kubernetes Service (AKS)](https://azure.microsoft.com/en-us/services/kubernetes-service/). (Do Option 1 or Option 2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Option 1: Create a new AKS cluster\n",
    "\n",
    "If you do not have an active AKS cluster for model deployment, create one using the Azure ML SDK."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "# Use the default configuration (you can also provide parameters to customize this)\n",
    "prov_config = AksCompute.provisioning_configuration(vm_size='Standard_D16_v3')\n",
    "\n",
    "aks_cluster_name = 'diabetes-cluster'\n",
    "# Create the cluster\n",
    "aks_target = ComputeTarget.create(workspace = workspace,\n",
    "                                  name = aks_cluster_name,\n",
    "                                  provisioning_configuration = prov_config)\n",
    "\n",
    "# Wait for the create process to complete\n",
    "aks_target.wait_for_completion(show_output = True)\n",
    "print(aks_target.provisioning_state)\n",
    "print(aks_target.provisioning_errors)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Option 2: Connect to an existing AKS cluster\n",
    "\n",
    "If you already have an active AKS cluster running, you can add it to your Workspace using the Azure ML SDK."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "# Get the resource group from https://porta..azure.com -> Find your resource group\n",
    "resource_group = '<resource-group>'\n",
    "\n",
    "# Give the cluster a local name\n",
    "aks_cluster_name = 'diabetes-cluster'\n",
    "\n",
    "# Attatch the cluster to your workgroup\n",
    "attach_config = AksCompute.attach_configuration(resource_group=resource_group, cluster_name=aks_cluster_name)\n",
    "aks_target = ComputeTarget.attach(workspace, name='diabetes-compute', attach_config)\n",
    "\n",
    "# Wait for the operation to complete\n",
    "aks_target.wait_for_completion(True)\n",
    "print(aks_target.provisioning_state)\n",
    "print(aks_target.provisioning_errors)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deploy to the model's image to the specified AKS cluster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "\n",
    "# Set configuration and service name\n",
    "prod_webservice_name = 'diabetes-model-prod'\n",
    "prod_webservice_deployment_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "# Deploy from image\n",
    "prod_webservice = Webservice.deploy_from_image(workspace = workspace,\n",
    "                                               name = prod_webservice_name,\n",
    "                                               image = model_image,\n",
    "                                               deployment_config = prod_webservice_deployment_config,\n",
    "                                               deployment_target = aks_target)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": [
    "# Wait for the deployment to complete\n",
    "prod_webservice.wait_for_deployment(show_output = True)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query the deployed model in production"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate the sample input vector by sending an HTTP request\n",
    "Query the AKS webservice's scoring endpoint by sending an HTTP POST request that includes the input vector. The production AKS deployment may require an authorization token (service key) for queries. Include this key in the HTTP request header."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def query_endpoint_example(scoring_uri, inputs, service_key=None):\n",
    "  headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "  }\n",
    "  if service_key is not None:\n",
    "    headers['Authorization'] = 'Bearer {service_key}'.format(service_key=service_key)\n",
    "\n",
    "  print('Sending batch prediction request with inputs: {}'.format(inputs))\n",
    "  response = requests.post(scoring_uri, data=json.dumps(inputs), headers=headers)\n",
    "  preds = json.loads(response.text)\n",
    "  print('Received response: {}'.format(preds))\n",
    "  return preds"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "source": [
    "prod_scoring_uri = prod_webservice.scoring_uri\n",
    "prod_service_key = prod_webservice.get_keys()[0] if len(prod_webservice.get_keys()) > 0 else None"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "source": [
    "prod_prediction1 = query_endpoint_example(scoring_uri=prod_scoring_uri, service_key=prod_service_key, inputs=query_input)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Update the production deployment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build an Azure Container Image for the new model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "run_id2 = '<run-id2>'\n",
    "model_uri = 'runs:/' + run_id2 + '/model'"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "import mlflow.azureml\n",
    "\n",
    "model_image_updated, azure_model_updated = mlflow.azureml.build_image(\n",
    "    model_uri=model_uri,\n",
    "    workspace=workspace,\n",
    "    model_name='model-updated',\n",
    "    image_name='model-updated',\n",
    "    description='Sklearn ElasticNet image for predicting diabetes progression',\n",
    "    synchronous=False)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "source": [
    "model_image_updated.wait_for_creation(show_output=True)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deploy the new model's image to the AKS cluster\n",
    "\n",
    "Using the [`azureml.core.webservice.AksWebservice.update()`](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.akswebservice?view=azure-ml-py#update) function, replace the deployment's existing model image with the new model image."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "prod_webservice.update(image=model_image_updated)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": [
    "prod_webservice.wait_for_deployment(show_output = True)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query the updated model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "prod_prediction2 = query_endpoint_example(scoring_uri=prod_scoring_uri, service_key=prod_service_key, inputs=query_input)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare the predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print('Run ID: {} Prediction: {}'.format(run_id1, prod_prediction1))\n",
    "print('Run ID: {} Prediction: {}'.format(run_id2, prod_prediction2))"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean up the deployments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Terminate the ACI webservice\n",
    "\n",
    "Because ACI manages compute resources on your behalf, deleting the \"dev\" ACI webservice will remove all resources associated with the \"dev\" model deployment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "dev_webservice.delete()"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Terminate the AKS webservice\n",
    "\n",
    "This terminates the real-time serving webservice running on the specified AKS cluster. It **does not** terminate the AKS cluster."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "prod_webservice.delete()"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove the AKS cluster from the Azure ML Workspace\n",
    "\n",
    "If the cluster was created using the Azure ML SDK (see **Option 1: Create a new AKS cluster**), remove it from the Azure ML Workspace will terminate the cluster, including all of its compute resources and deployments.\n",
    "\n",
    "If the cluster was created independently (see **Option 2: Connect to an existing AKS cluster**), it will remain active after removal from the Azure ML Workspace."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "aks_target.delete()"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "name": "MLflow Quick Start Part 1: Training and Logging",
  "notebookId": 2062321517797926
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4chH_jBYCfI"
      },
      "source": [
        "# üöÄ **Arize and Neptune Walkthrough**\n",
        "\n",
        "Let's get started on using Arize with Neptune! ‚ú®\n",
        "\n",
        "Arize and Neptune are MLOps tools that aim to improve connected, but different parts of your ML pipeline and ML workflow. Arize helps you visualize your production model performance, understand drift & data quality issues. Neptune logs, stores, displays, and compares all your MLOps metadata for better experiment tracking and model registry.\n",
        "\n",
        "With Arize and Neptune, you will be able to train the best model, and pre-launch validate your model, and compare production performances of those models.\n",
        "\n",
        "\n",
        "## ‚úîÔ∏è Steps for this Walkthrough\n",
        "1. Initialize Neptune and set-up Arize client\n",
        "2. Logging training callbacks to Neptune\n",
        "3. Logging training and validation records to Arize\n",
        "4. Storing and versioning model weights with Neptune\n",
        "5. Logging and versioning model in production with Arize\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT5dYnFRcix2"
      },
      "source": [
        "# Step 1: Initialize Neptune and set-up Arize client\n",
        "\n",
        "## Step 1.2 Set-up Neptune Project\n",
        "First you will need to create a Neptune account and follow these steps\n",
        "1. Sign up for an account and replace `YOUR_USER_NAME` with your client name\n",
        "2. Copy your `API_TOKEN`  from top right of the neptune nav bar\n",
        "3. Create a new `Project` and name it `ArizeIntegration`. Here is how to [create project](https://docs.neptune.ai/administration/projects#create-project)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW5tR9FvumLK"
      },
      "outputs": [],
      "source": [
        "!pip install neptune-client -q\n",
        "!pip install neptune-tensorflow-keras -q\n",
        "\n",
        "import neptune.new as neptune\n",
        "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
        "\n",
        "NEPTUNE_USER_NAME = 'NEPTUNE_USER_NAME'\n",
        "NEPTUNE_API_TOKEN = 'NEPTUNE_API_TOKEN'\n",
        "\n",
        "if NEPTUNE_USER_NAME == 'NEPTUNE_USER_NAME' or NEPTUNE_API_TOKEN == 'NEPTUNE_API_TOKEN': \n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE USERNAME AND/OR API TOKEN\")\n",
        "\n",
        "# set parameters for initializing Neptune\n",
        "PROJECT_NAME = f\"{NEPTUNE_USER_NAME}/ArizeIntegration\"\n",
        "run = neptune.init(api_token=NEPTUNE_API_TOKEN, project=PROJECT_NAME)\n",
        "\n",
        "print('Step 1.1 ‚úÖ: Initialize Neptune run and project complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSIND2ZK1cHT"
      },
      "source": [
        "You can find more info about the NeptuneCallback in the [TensorFlow / Keras integration](https://docs.neptune.ai/integrations-and-supported-tools/model-training/tensorflow-keras) docs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JGR8yPjiq6w"
      },
      "source": [
        "## Step 1.2: Set-up Arize Client\n",
        "To set up Arize, copy the Arize `API_KEY` and `SPACE_KEY` from your admin page linked below!\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDrwK5eOcm-5"
      },
      "outputs": [],
      "source": [
        "!pip install arize -q\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import ModelTypes, Environments\n",
        "\n",
        "SPACE_KEY = 'SPACE_KEY'\n",
        "API_KEY = 'API_KEY'\n",
        "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
        "\n",
        "model_id = 'neptune_cancer_prediction_model'\n",
        "model_version = 'v1'\n",
        "model_type = ModelTypes.BINARY\n",
        "\n",
        "if SPACE_KEY == 'SPACE_KEY' or API_KEY == 'API_KEY': \n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else: \n",
        "    print(\"Step 1.2 ‚úÖ: Initialize Arize client complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZHA77eccOyG"
      },
      "source": [
        "# Step 2: Logging training callbacks to Neptune\n",
        "\n",
        "Neptune tracks your model training callbacks, allowing training loss curves to be logged and visualized for each different training iterations. In this example, we will be working with a `tensorflow.keras` model to build a model for classifying whether an individual has breast cancer or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kofGZ331zxi"
      },
      "source": [
        "## Step 2.1: Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh9yOvSbYB8Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import os\n",
        "import concurrent.futures as cf\n",
        "from sklearn import datasets, preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import datetime\n",
        "\n",
        "def process_data(X, y):\n",
        "    scaler = preprocessing.MinMaxScaler()\n",
        "    X = np.array(X).reshape((len(X), 30))\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "\n",
        "# 1 Load data and split data\n",
        "data = datasets.load_breast_cancer()\n",
        "\n",
        "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
        "X, y = X.astype(np.float32), y\n",
        "\n",
        "X, y = pd.DataFrame(X, columns=data['feature_names']), pd.Series(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)\n",
        "\n",
        "print('Step 2.1 ‚úÖ: Load Data Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGoLR6Vuj79l"
      },
      "source": [
        "## Step 2.2 Logging Training Callbacks\n",
        "By passing `run` instance, a live training curve should show up on Neptune under the **Charts** tab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEOI5zJT6Odw"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "import tensorflow as tf\n",
        "\n",
        "# Step 1: Define and compile model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='sigmoid', input_shape=((30,))))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=keras.optimizers.Adam(), \n",
        "              loss=keras.losses.mean_squared_logarithmic_error)\n",
        "\n",
        "# Step 2: Fit model and log callbacks\n",
        "\n",
        "params = {'batch_size': 30,\n",
        "          'epochs': 50,\n",
        "          'verbose': 0,\n",
        "         }\n",
        "\n",
        "callbacked = model.fit(X_train, y_train, \n",
        "                batch_size=params['batch_size'], \n",
        "                epochs=params['epochs'], \n",
        "                verbose=params['verbose'], \n",
        "                validation_data=(X_test, y_test),\n",
        "                # log to Neptune using NeptuneCallback\n",
        "                callbacks=[NeptuneCallback(run=run)]\n",
        "                )\n",
        "\n",
        "print('Step 2.2 ‚úÖ: Training callbacks successfully logged!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4RnD6yeT-mS"
      },
      "source": [
        "# Step 3: Logging training and validation records to Arize\n",
        "Arize allows you to log training and validation records to an **Evaluation Store** for model pre-launch validation, such as visualizing performance across different feature slices (i.e, model accuracy for lower income individuals v.s higher). \n",
        "\n",
        "The records you send in can also serve as your model baseline, which can be compared against the features your models predict on in production to inform you when the distributions of the features have shifted. You can click here to access the documentation for our Python SDK. This section uses `arize.pandas.log()`. You can check the documentations by clicking the button below.\n",
        "\n",
        "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hpG2bUNpTMu"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: A quick helper function to validate Arize responses\n",
        "def arize_responses_helper(responses):\n",
        "    for response in cf.as_completed(responses):\n",
        "        res = response.result()\n",
        "        if res.status_code != 200:\n",
        "            raise ValueError(f'future failed with response code {res.status_code}, {res.text}')\n",
        "\n",
        "def generate_prediction_ids(X):\n",
        "    return pd.Series((str(uuid.uuid4()) for _ in range(len(X))), index=X.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChxMp0eRr7dB"
      },
      "source": [
        "## Step 3.1: Logging Training Records to Arize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F5WrFvrkYm6"
      },
      "outputs": [],
      "source": [
        "# Use the model to generate predictions\n",
        "y_train_pred = model.predict(X_train).T[0]\n",
        "y_val_pred = model.predict(X_val).T[0]\n",
        "y_test_pred = model.predict(X_test).T[0]\n",
        "\n",
        "# Defining a Schema() for training environment\n",
        "train_data = X_train.copy()\n",
        "feature_column_names = train_data.columns\n",
        "train_data['prediction_ids'] = generate_prediction_ids(train_data)\n",
        "train_data['predictions'] = y_train_pred\n",
        "train_data['actuals'] = y_train\n",
        "\n",
        "train_schema = Schema(\n",
        "    feature_column_names=feature_column_names,\n",
        "    prediction_id_column_name=\"prediction_ids\",\n",
        "    prediction_label_column_name=\"predictions\",\n",
        "    actual_label_column_name=\"actuals\",\n",
        ")\n",
        "\n",
        "# Logging to Arize platform using arize_client.log\n",
        "train_response = arize_client.log(\n",
        "    dataframe=train_data,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    batch_id=\"training\",\n",
        "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
        "    environment=Environments.TRAINING,\n",
        "    schema=train_schema,\n",
        ")\n",
        "\n",
        "arize_responses_helper(train_response)\n",
        "print('Step 3.1 ‚úÖ: If no errors showed up, you have sent Training Inferences!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70W2iJjasE9o"
      },
      "source": [
        "## Step 3.2 Logging Validation to Arize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGqNKuVBsHi-"
      },
      "outputs": [],
      "source": [
        "# Defining a Schema() for training environment\n",
        "val_data = X_val.copy()\n",
        "val_data['prediction_ids'] = generate_prediction_ids(val_data)\n",
        "val_data['predictions'] = y_val_pred\n",
        "val_data['actuals'] = y_val\n",
        "\n",
        "val_schema = Schema(\n",
        "    feature_column_names=feature_column_names,\n",
        "    prediction_id_column_name=\"prediction_ids\",\n",
        "    prediction_label_column_name=\"predictions\",\n",
        "    actual_label_column_name=\"actuals\",\n",
        ")\n",
        "\n",
        "# Logging to Arize platform using arize_client.log\n",
        "val_response = arize_client.log(\n",
        "    dataframe=val_data,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    batch_id=\"baseline\",\n",
        "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
        "    environment=Environments.VALIDATION,\n",
        "    schema=val_schema,\n",
        ")\n",
        "\n",
        "arize_responses_helper(val_response)\n",
        "print('Step 3.2 ‚úÖ: If no errors showed up, you have sent Validation Inferences!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ9fINHCnF_R"
      },
      "source": [
        "# Step 4: Storing and Versioning Model Weights with Neptune\n",
        "Neptune allows you to organize your models in a folder like structure through the `run` instance of each project. For each run, you can log model weights or checkpoints. You can organize different trained iterations using tag `model_version` you used to log training records to Arize for better integration.\n",
        "\n",
        "You can also easily log `model_id` for better reference information.\n",
        "\n",
        "**Note: Code for model storing is different for different frameworks. The following is only applicable for tf.keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3GtycCCnGh2"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Storing model version 1\n",
        "directory_name = f'keras_model_{model_version}'\n",
        "model.save(directory_name)\n",
        "\n",
        "run[f'{directory_name}/saved_model.pb'].upload(f'{directory_name}/saved_model.pb')\n",
        "for name in glob.glob(f'{directory_name}/variables/*'):\n",
        "    run[name].upload(name)\n",
        "\n",
        "# Log 'model_id', for better reference\n",
        "run['model_id'] = model_id\n",
        "\n",
        "print('Step 4 ‚úÖ: If no errors showed up, can should now see the folders in your Neptune Project')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYsgoRmmnI_E"
      },
      "source": [
        "# Step 5: Logging and versioning model in production with Arize\n",
        "During production, you can use `arize.bulk_log` or `arize.log` in the Python SDK to log any data in your model serving endpoint. In this example, we send in our test data simulating production setting. But in production, you would deploy the models saved by Neptune prior to logging to Arize!\n",
        "\n",
        "You can find more about `arize.bulk_log` here.\n",
        "\n",
        "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://arize.gitbook.io/arize/apis/python-sdk-1/arize.bulk_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4InfresqnJtA"
      },
      "outputs": [],
      "source": [
        "# Defining a Schema() for training environment\n",
        "prod_data = X_test.copy()\n",
        "prod_data['prediction_ids'] = generate_prediction_ids(prod_data)\n",
        "prod_data['predictions'] = y_test_pred\n",
        "prod_data['actuals'] = y_test\n",
        "\n",
        "prod_schema = Schema(\n",
        "    feature_column_names=feature_column_names,\n",
        "    prediction_id_column_name=\"prediction_ids\",\n",
        "    prediction_label_column_name=\"predictions\",\n",
        "    actual_label_column_name=\"actuals\",\n",
        ")\n",
        "\n",
        "# Logging to Arize platform using arize_client.log\n",
        "prod_response = arize_client.log(\n",
        "    dataframe=prod_data,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
        "    environment=Environments.PRODUCTION,\n",
        "    schema=prod_schema,\n",
        ")\n",
        "\n",
        "arize_responses_helper(prod_response)\n",
        "print('Step 5 ‚úÖ: If no errors appear, you just logged predictions, features, and actuals to Arize!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "[V2] Arize_Tutorial_Neptune-updates.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

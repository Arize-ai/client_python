{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feast_Arize_Tutorial_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC0YquU02WPk"
      },
      "source": [
        "# üöÄ **Arize and Feast Walkthrough**\n",
        "\n",
        "Arize and Feast are two platforms aimed at different, but connected, parts of the ML pipeline. Arize helps you visualize your model performance, understand drift & data quality issues, and share insights as your **Evaluation Store**. Feast (i.e, **Feature Store**) is an operational data system for managing and serving machine learning features to models in production.\n",
        "\n",
        "# ‚ú® Prologue: The Data Consistency Story\n",
        "You are building a transaction fraud model that predicts whether a payment by a customer succeed. Two of your most important features are `current_24_hr_cancels` and `avg_cancels` referring to the most up-to-date information about cancellations occurring across transactions. \n",
        "\n",
        "In this example, we will show how data inconsistency can occur based on arrival of new information. The **online features** are features served in production, usually \"materialized\" live in production for low latency. The **offline features** are features used retraining models, often retrieved later after thos features are already served in production.\n",
        "\n",
        "However, there is typically a delay between getting the online features and when the data sources from which those features are updated. For example, there could be a delay in parquet data source registering a cancellation for our transactions.\n",
        "\n",
        "This delay causes discrepancies between online and offline environments for `current_24_hr_cancels` and `avg_cancels`, since these features are computed assuming the logs from our parquet file is up-to-date.\n",
        "\n",
        "\n",
        "In this tutorial, we will show how to catch this using **Feast with Arize:** surfacing up and when they are inconsistent, how are they inconsistent, and what can do the troubleshoot once we understand the problem. \n",
        "\n",
        "## ‚úîÔ∏è Steps for this Walkthrough\n",
        "\n",
        "1. Install Dependencies & Set-up Feast + Arize Repo/Credentials\n",
        "2. Online: `store.get_online_features` from feast and `arize.log` Integration \n",
        "3. Offline: `store.get_historical_features` from feast and `arize.log_validation_records` Integration\n",
        "4. On Arize: Measuring Data Inconsistency\n",
        "5. On Arize: Troubleshooting data consistency and why this matters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4H1uViFcYD6"
      },
      "source": [
        "# **Step 1: Install Dependencies & Set-up Feast + Arize Repo/Credentials**\n",
        "In this section, we will set-up the Colab environment so that Feast works properly in under 1 minute!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OpBn5hhhYc4"
      },
      "source": [
        "## **Step 1.1: Installing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p78T3Sp2ePM0",
        "outputId": "89f0de0a-83ec-4484-fcff-eccef8d64a7e"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import os\n",
        "\n",
        "!pip install feast -q\n",
        "!pip install arize -q\n",
        "\n",
        "clear_output(wait=True)\n",
        "print(\"‚úÖ Packages has been installed. ‚ö†Ô∏è Restart run-time before running next cell!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚úÖ Packages has been installed. ‚ö†Ô∏è Restart run-time before running next cell!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDQRpXP7f4yh"
      },
      "source": [
        "##**Step 1.2: ‚ö†Ô∏è Restart Run-time** ‚ö†Ô∏è\n",
        "Since Colab comes with pre-installed environments, you will need to reset some dependencies following these steps:\n",
        "\n",
        "1. Click on `Runtime`\n",
        "2. Click on `Re-start Runtime` (Don't click the other options!)\n",
        "\n",
        "Then you can continue the tutorial from the cell below (no need to run pip install again). \n",
        "\n",
        "If you ever need to reset the tutorial, you can run this cell again.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yguFQfqOfpRz",
        "outputId": "b7f52f7e-819d-425b-ae2d-82f981f47645"
      },
      "source": [
        "try:\n",
        "    import feast\n",
        "except:\n",
        "    raise ValueError(\"‚ö†Ô∏è You need to restart run-time to reset Colab dependencies\")\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "\n",
        "# setting up the repo\n",
        "if 'sample_data' in os.listdir():\n",
        "    !git clone https://github.com/alanschen/feast_example.git\n",
        "    %cd feast_example\n",
        "\n",
        "!python reset_environment.py # this resets your feast environment\n",
        "clear_output(wait=True)\n",
        "\n",
        "if 'feature_store.yaml' in os.listdir():\n",
        "    print(\"‚úÖ Environment has been re-set properly\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚úÖ Environment has been re-set properly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzjSF94shfoC"
      },
      "source": [
        "## **Step 1.3: Set-up Feature Store & Materialize Feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "WU5wc317djdi",
        "outputId": "6722fbf4-b01b-41ca-9844-fe44276f718f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# 1 Defining a FeatureStore\n",
        "from feast import FeatureStore\n",
        "store = feast.FeatureStore(repo_path=\".\")\n",
        "\n",
        "# 2 Applying feast definitions to the online registry : registry.db\n",
        "print(\"‚úÖ Applying feast definition to registry.db\")\n",
        "!feast apply\n",
        "\n",
        "# 3 materializing features into our online sqlite feature store\n",
        "target_time = datetime(2021, 6, 1, 22, 59, 59)\n",
        "TARGET_TIME = target_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
        "print(\"‚úÖ Materializing one feature into online_store.db\")\n",
        "!feast materialize '2021-06-01T22:50:00' $TARGET_TIME\n",
        "\n",
        "# 2 Defining our feature references:\n",
        "print(\"\\n‚úÖ Showing an example entries in our `data_source.parquet`\")\n",
        "cancel = pd.read_parquet('data/cancel_stats.parquet')\n",
        "cancel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚úÖ Applying feast definition to registry.db\n",
            "Registered entity \u001b[1m\u001b[32muser_id\u001b[0m\n",
            "Registered feature view \u001b[1m\u001b[32muser_cancel_stats\u001b[0m\n",
            "Deploying infrastructure for \u001b[1m\u001b[32muser_cancel_stats\u001b[0m\n",
            "‚úÖ Materializing one feature into online_store.db\n",
            "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views from \u001b[1m\u001b[32m2021-06-01 22:50:00+00:00\u001b[0m to \u001b[1m\u001b[32m2021-06-01 22:59:59+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
            "\n",
            "\u001b[1m\u001b[32muser_cancel_stats\u001b[0m:\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.24it/s]\n",
            "\n",
            "‚úÖ Showing an example entries in our `data_source.parquet`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>user_id</th>\n",
              "      <th>current_24_hr_cancels</th>\n",
              "      <th>avg_cancels</th>\n",
              "      <th>created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-01 22:45:12</td>\n",
              "      <td>501</td>\n",
              "      <td>5</td>\n",
              "      <td>5.742</td>\n",
              "      <td>2021-06-01 22:45:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-01 22:47:23</td>\n",
              "      <td>501</td>\n",
              "      <td>5</td>\n",
              "      <td>5.742</td>\n",
              "      <td>2021-06-01 22:47:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-01 22:49:24</td>\n",
              "      <td>501</td>\n",
              "      <td>5</td>\n",
              "      <td>5.742</td>\n",
              "      <td>2021-06-01 22:49:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-01 22:51:45</td>\n",
              "      <td>501</td>\n",
              "      <td>6</td>\n",
              "      <td>5.742</td>\n",
              "      <td>2021-06-01 22:51:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-01 22:52:03</td>\n",
              "      <td>501</td>\n",
              "      <td>6</td>\n",
              "      <td>6.323</td>\n",
              "      <td>2021-06-01 22:52:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-06-01 22:55:50</td>\n",
              "      <td>501</td>\n",
              "      <td>7</td>\n",
              "      <td>6.323</td>\n",
              "      <td>2021-06-01 22:55:50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             datetime  user_id  ...  avg_cancels             created\n",
              "0 2021-06-01 22:45:12      501  ...        5.742 2021-06-01 22:45:12\n",
              "1 2021-06-01 22:47:23      501  ...        5.742 2021-06-01 22:47:23\n",
              "2 2021-06-01 22:49:24      501  ...        5.742 2021-06-01 22:49:24\n",
              "3 2021-06-01 22:51:45      501  ...        5.742 2021-06-01 22:51:45\n",
              "4 2021-06-01 22:52:03      501  ...        6.323 2021-06-01 22:52:03\n",
              "5 2021-06-01 22:55:50      501  ...        6.323 2021-06-01 22:55:50\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxoKOp8Zm5tt"
      },
      "source": [
        "## **Step 1.4: Set-up Arize Client**\n",
        "First, copy the Arize `API_KEY` and `SPACE_KEY` from your admin page linked below!\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evAiyO0ovEa8",
        "outputId": "a8f402c6-1c17-40b1-c0b6-5255cbaed867"
      },
      "source": [
        "from arize.api import Client\n",
        "from arize.types import ModelTypes\n",
        "import concurrent.futures as cf\n",
        "\n",
        "\n",
        "# Step 1.2: Set-up Arize Client and model meta data\n",
        "SPACE_KEY = 'SPACE_KEY'\n",
        "API_KEY = 'API_KEY'\n",
        "arize = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
        "\n",
        "model_id = 'arize-feast-tutorial'\n",
        "model_version = '1.0'\n",
        "model_type = ModelTypes.SCORE_CATEGORICAL\n",
        "\n",
        "if SPACE_KEY == 'SPACE_KEY' or API_KEY == 'API_KEY': \n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else: \n",
        "    print(\"‚úÖ Arize setup complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚úÖ Arize setup complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS90n6N4ncYq"
      },
      "source": [
        "#**Step 2: Online Environment Integration**\n",
        "After running `feast materialize` in the previous step, the most recent feature for `user_id: 501` has been stored to `online_store.db`. Then, by running `store.get_online_feature`, we can fetch the feature, predict outcomes with our best model, and use `arize.log` to record evaluations to the Arize as your Evaluation Store.\n",
        "\n",
        "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://arize.gitbook.io/arize/apis/python-sdk-1/arize.log)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "W2KUYL8jmqgp",
        "outputId": "0601ad30-cdfd-41dd-8d83-e28860f6305a"
      },
      "source": [
        "import uuid\n",
        "\n",
        "# define online feature\n",
        "feature_refs = [\"user_cancel_stats:current_24_hr_cancels\", \"user_cancel_stats:avg_cancels\"]\n",
        "online_data = store.get_online_features(\n",
        "    feature_refs=feature_refs, # as defined above\n",
        "    entity_rows=[{\"user_id\": 501}],\n",
        ")\n",
        "\n",
        "feature_labels = ['user_cancel_stats__current_24_hr_cancels', 'user_cancel_stats__avg_cancels']\n",
        "\n",
        "# formatting the feature into a dataframe\n",
        "print(\"\\n‚úÖ Feast online feature materialized and retrieved\")\n",
        "display(online_data.to_df()[feature_labels])\n",
        "\n",
        "# logging to arize\n",
        "prediction_id = '1a43c711-f407-4a5c-aa54-c22344a9879c' # we will need this to join the records\n",
        "prediction_label = 'fraud'\n",
        "actual_label = 'fraud'\n",
        "prediction_timestamp = int(target_time.timestamp()) # this will be used to create match environment on Arize\n",
        "\n",
        "log_result = arize.log(model_id=model_id,\n",
        "          model_version=model_version,\n",
        "          prediction_id=prediction_id,\n",
        "          prediction_label=prediction_label,\n",
        "          prediction_timestamp=prediction_timestamp,\n",
        "          features=online_data.to_dict()\n",
        "          )\n",
        "assert log_result.result().status_code == 200, \"Logging should be successful\"\n",
        "\n",
        "print(\"\\n‚úÖ Arize online feature logging complete\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Feast online feature materialized and retrieved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_cancel_stats__current_24_hr_cancels</th>\n",
              "      <th>user_cancel_stats__avg_cancels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>6.323</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_cancel_stats__current_24_hr_cancels  user_cancel_stats__avg_cancels\n",
              "0                                         7                           6.323"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Arize online feature logging complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9OXM6tleBAH"
      },
      "source": [
        "# **Step 3: Offline Environment Integration**\n",
        "**Important**: Notice for `event_timestamp` we used the `target_time` again, so we are using the **exact same timestamp** as when we called `get_online_feature` when calling `get_historical_features`.\n",
        "\n",
        "Next, we can then log the offline data to Arize as validation using `arize.log_validation_records` when we are re-training our model using the historical/offline features. Click below for the documentations.\n",
        "\n",
        "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://arize.gitbook.io/arize/apis/python-sdk-1/arize.log_validation_records)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "xSD7nffXLH9u",
        "outputId": "45b5afbe-91cb-4f2e-f9ed-07dbdf559d39"
      },
      "source": [
        "# In even the most performant real time systems, the most up to date information about the world\n",
        "# takes time to fully propagate throughout the stack. In this case, we simulate a scenario where \n",
        "# the most recent information about user 501's cancel behavor rolls up to the feature store \n",
        "# AFTER the prediction has been made with the stale information.\n",
        "latest_arrival_time = datetime(2021, 6, 1, 22, 56, 30)\n",
        "\n",
        "# Add an entry to our data source to simulate new entry in data source\n",
        "cancel.loc[6] = [latest_arrival_time, 501, 8, 7.127, latest_arrival_time]\n",
        "cancel.to_parquet(\"data/cancel_stats.parquet\")\n",
        "\n",
        "print(\"‚ö†Ô∏è A new data entry logged into the data source parquet:\")\n",
        "display(cancel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è A new data entry logged into the data source parquet:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>user_id</th>\n",
              "      <th>current_24_hr_cancels</th>\n",
              "      <th>avg_cancels</th>\n",
              "      <th>created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-01 22:45:12</td>\n",
              "      <td>501</td>\n",
              "      <td>5</td>\n",
              "      <td>5.742</td>\n",
              "      <td>2021-06-01 22:45:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-01 22:47:23</td>\n",
              "      <td>501</td>\n",
              "      <td>5</td>\n",
              "      <td>5.742</td>\n",
              "      <td>2021-06-01 22:47:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-01 22:49:24</td>\n",
              "      <td>501</td>\n",
              "      <td>5</td>\n",
              "      <td>5.742</td>\n",
              "      <td>2021-06-01 22:49:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-01 22:51:45</td>\n",
              "      <td>501</td>\n",
              "      <td>6</td>\n",
              "      <td>5.742</td>\n",
              "      <td>2021-06-01 22:51:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-01 22:52:03</td>\n",
              "      <td>501</td>\n",
              "      <td>6</td>\n",
              "      <td>6.323</td>\n",
              "      <td>2021-06-01 22:52:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-06-01 22:55:50</td>\n",
              "      <td>501</td>\n",
              "      <td>7</td>\n",
              "      <td>6.323</td>\n",
              "      <td>2021-06-01 22:55:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2021-06-01 22:56:30</td>\n",
              "      <td>501</td>\n",
              "      <td>8</td>\n",
              "      <td>7.127</td>\n",
              "      <td>2021-06-01 22:56:30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             datetime  user_id  ...  avg_cancels             created\n",
              "0 2021-06-01 22:45:12      501  ...        5.742 2021-06-01 22:45:12\n",
              "1 2021-06-01 22:47:23      501  ...        5.742 2021-06-01 22:47:23\n",
              "2 2021-06-01 22:49:24      501  ...        5.742 2021-06-01 22:49:24\n",
              "3 2021-06-01 22:51:45      501  ...        5.742 2021-06-01 22:51:45\n",
              "4 2021-06-01 22:52:03      501  ...        6.323 2021-06-01 22:52:03\n",
              "5 2021-06-01 22:55:50      501  ...        6.323 2021-06-01 22:55:50\n",
              "6 2021-06-01 22:56:30      501  ...        7.127 2021-06-01 22:56:30\n",
              "\n",
              "[7 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "2j26SC7ceAZh",
        "outputId": "987fe646-be4c-45c4-9c9c-f4bfbf272a48"
      },
      "source": [
        "# Retrieving offline data to Arize\n",
        "entity_df = pd.DataFrame.from_dict({\"user_id\": [501], \"event_timestamp\": [target_time]})\n",
        "offline_data = store.get_historical_features(\n",
        "    entity_df=entity_df,\n",
        "    feature_refs=feature_refs,\n",
        ").to_df().sort_values('user_id')\n",
        "\n",
        "print(\"\\n‚úÖ Feast offline (historical) feature retrieved\")\n",
        "# logging validation data to Arize\n",
        "arize.log_validation_records(\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    batch_id='offline',\n",
        "    prediction_labels=pd.Series([prediction_label]), # we need to pass in the same prediction_labels\n",
        "    actual_labels=pd.Series([actual_label]),\n",
        "    prediction_ids=pd.Series([prediction_id]),\n",
        "    prediction_timestamps=pd.Series([prediction_timestamp]) # and the same timest\n",
        ")\n",
        "print(\"\\n‚úÖ Arize offline (validation) features logging complete\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è Notice a mismatch between online environment\")\n",
        "display(online_data.to_df()[feature_labels])\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è ... and offline environment!\")\n",
        "display(offline_data[feature_labels])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Feast offline (historical) feature retrieved\n",
            "\n",
            "‚úÖ Arize offline (validation) features logging complete\n",
            "\n",
            "‚ö†Ô∏è Notice a mismatch between online environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_cancel_stats__current_24_hr_cancels</th>\n",
              "      <th>user_cancel_stats__avg_cancels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>6.323</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_cancel_stats__current_24_hr_cancels  user_cancel_stats__avg_cancels\n",
              "0                                         7                           6.323"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "‚ö†Ô∏è ... and offline environment!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_cancel_stats__current_24_hr_cancels</th>\n",
              "      <th>user_cancel_stats__avg_cancels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>7.127</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_cancel_stats__current_24_hr_cancels  user_cancel_stats__avg_cancels\n",
              "0                                         8                           7.127"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43Ec4jREnio4"
      },
      "source": [
        "# **Step 4: Arize Platform - Measuring Data Inconsistency**\n",
        "\n",
        "Now, suppose we have the above problem of online/offline mismatch in a live model in production serving tens of thousands of predictions. Arize will help you surface up when such mismatch occurs, and provides you with tool to troubleshoot how inconsistency may have occured.\n",
        "\n",
        "\n",
        "## Step 4.1 Setting up Project on Arize\n",
        "**Data Consistency** is an Arize feature that's availiable under the **Projects** tab. To use it, you have to **create a new project** containing your models with the same match environments. For example, all models with same feature schema (such as one instance of a model deployed for a stores/cities/state) can use the same **Projects** page.\n",
        "\n",
        "\n",
        "![Create Project.png](https://storage.googleapis.com/arize-assets/fixtures/create_project.gif)\n",
        "\n",
        "## Step 4.2 Setting up Match Environment\n",
        "\n",
        "Since there may be many validation datasets logged for a model, we will need to select the validation data identifiable by `batch_id`, which in our example above, we labelled `batch_id = 'offline'`.\n",
        "\n",
        "We want to then set up a match environment. then enter `offline` as our match environment under `validation` as our match environment for `production`. Then, we want to select our model name as show below. \n",
        "\n",
        "### üîÅ You can click on the gif to view it again.\n",
        "[![Set_up_match_config.png](https://storage.googleapis.com/arize-assets/fixtures/data_consistency_environment.gif)](https://storage.googleapis.com/arize-assets/fixtures/data_consistency_environment.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3l1BjorCxTR"
      },
      "source": [
        "# **Step 5: Arize Platform - Troubleshooting Inconsistency and Why This Matters**\n",
        "\n",
        "**Note:** The following demo is an expanded example, where the same delayed arrival of information to data source before offline fetching is repeated for tens of thousands of data.\n",
        "\n",
        "## **Step 5.1: Checking Data Consistency by Feature**\n",
        "We first want to see the overall data consistency within all of our features. We can see the distribution of any mismatches by clicking into each feature. By toggling on **Show Unmatched Only**, we can see the overall distribution shape and residual of the mismatch.\n",
        "\n",
        "\n",
        "### üîÅ You can click on the gif to view it again.\n",
        "[![Feature_view.png](https://storage.googleapis.com/arize-assets/fixtures/data_consistency_feature_view_2.gif)](https://storage.googleapis.com/arize-assets/fixtures/data_consistency_feature_view_2.gif)\n",
        "\n",
        "\n",
        "## **Step 5.2: Troubleshooting with Heatmap**\n",
        "Base on the **Distribution Comparisons** and **Residual Error** card, we can already see that there is a online feature distribution mismatch that is one-sided (i.e. all data from get_historical_feature higher than they are on the online environment). We can see that there is a delay, but let's take a deeper dive.\n",
        "\n",
        "### üîÅ You can click on the gif to view it again.\n",
        "[![Heatmap_view.png](https://storage.googleapis.com/arize-assets/fixtures/data_consistency_heatmap_view.gif)](https://storage.googleapis.com/arize-assets/fixtures/data_consistency_heatmap_view.gif)\n",
        "\n",
        "From investigating the heatmap and adjusting the max intensity, we can validate that the mismatch is one sided, suggesting a delay in data rolling up to the feature store.\n",
        "\n",
        "# **Step 5.3: Why does this matter**\n",
        "We always want our models to have the best performance possible. In this case, the offline example seems to be skewed due to the delayed arrival of data in our system. This will have a negative impact on model performance due to training/production distribution difference, which we will want to eliminate as much as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKrkh6_PKYGb"
      },
      "source": [
        "# **Overview**\n",
        "\n",
        null,
        "\n",
        "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
        "- Automated ML monitoring and model monitoring\n",
        "- Workflows to troubleshoot model performance\n",
        "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
        "- Model prediction cohort analysis\n",
        "- Pre-deployment model validation\n",
        "- Integrated model explainability\n",
        "\n",
        "### Website\n",
        "Visit Us At: https://arize.com/model-monitoring/\n",
        "\n",
        "### Additional Resources\n",
        "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
        "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
        "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
        "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
        "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
        "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
        "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
        "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
        "\n",
        "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring."
      ]
    }
  ]
}

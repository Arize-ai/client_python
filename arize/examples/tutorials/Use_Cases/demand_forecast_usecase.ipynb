{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdMI8iNub6Ye"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"200\"/>\n",
        "\n",
        "# Getting Started with the Arize Platform- Demand Forecasting for a Retail Company\n",
        "\n",
        "\n",
        "**In this example, you are part of a team for a retail company that maintains and monitors a demand forecasting regression model that predicts the one week unit quantity demanded for items in your stores.** The business objective of your ML model is so that your store fronts can supply them exactly the number of items demanded on time, as predicted by your model. \n",
        "\n",
        "**You have been alerted their are calls about stores overshelfing and unhappy customers in the last month due to mispredictions by your demand forecasting model, so you turn to Arize to gain insight as to why**.\n",
        "\n",
        "\n",
        "In this walkthrough, we are going to investigate your production demand forecasting model model. We will first set-up monitors and dashboard to provide better insights to into when these events happened and what happened on the days we had unhappy customers. Then, we will go into a deep dive to investigate the root causes of those mispredictions, and what kind of insights ML Engineer can gain from using Arize features. \n",
        "\n",
        "**The steps to this tutorial will be:**\n",
        "\n",
        "1. Tracking your model to the Arize platform\n",
        "2. Set-up Performance Monitor and Dashboard to better understand our model performance\n",
        "3. Understand when underprediction and overprediction events happen, and what they represent\n",
        "4. Discover feature drifts corresponding to time periods of performance degredation, and takeaways for ML Engineers to fix\n",
        "\n",
        "The goal of this is to see how the Arize platform can help your team quickly dive into issues critical to your operations through:\n",
        "- (1) Model observability & business insights \n",
        "- (2) Model performance troubleshooting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ilv3i0Qqbfu"
      },
      "source": [
        "# Part 0: Setup and Getting the Data\n",
        "The first step is to load our pre-existing dataset which includes training and production environments for our demand forecast example. Using a pre-existing dataset illustrates how simple it is to get started with the Arize platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies and Import Libraries üìö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKTMZgVLqm1a",
        "outputId": "9371de4a-b8b1-4667-c72b-3ccba533bf24"
      },
      "outputs": [],
      "source": [
        "!pip install -q arize\n",
        "\n",
        "import pandas as pd\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import Environments, ModelTypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUrO-FG8q2e7"
      },
      "source": [
        "## **üåê Download the Data**\n",
        "In this walkthrough, we‚Äôll be sending real historical data (with privacy conscious changes to feature names and values). Note, that while feature names and values are made explicit in this dataset, you can achieve the same level of ML Observability using obfuscated features. \n",
        "\n",
        "| Feature | Type | Description |||\n",
        "|:-|:-|:-|---|---|\n",
        "| `item_size`| `int`| shelf item physical size |||\n",
        "| `supplier_id`| `int`| unique identifier of item supplier |||\n",
        "| `avg_historical_sales`| `float`| average sales of item in the last 6 month |||\n",
        "| `cur_projected_sales`| `float`| sales projected based on seasonality from another times series model |||\n",
        "| `item_new_release_flag`| `int (0 or 1)`| flag indicating if item was released in the last 2 month |||\n",
        "| `item_stickyness_factor`| `float`| a number that represents whether an item will likely be purchased by the same customer again |||\n",
        "| `item_release_year`| `int`| the year which item has been released |||\n",
        "| `shelf_life_weeks`| `int`| how long the item is intended to be on sale for |||\n",
        "\n",
        "\n",
        "## Inspect the Data \n",
        "\n",
        "The data represents a regression model trained to forecast demand for an item one week in advance. The dataset contains one month of data and the performance will be evaluated by comparing:\n",
        "\n",
        "*   **`prediction`**: Predicted number of items to demanded by customers this week (also the number of items we will shelf in operations)\n",
        "*   **`actual`**: Actual number of items recorded as demanded within a week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EkJTxfbKrDhV",
        "outputId": "010a204a-a194-4dc2-d003-afc2aedd8ff3"
      },
      "outputs": [],
      "source": [
        "# import dataset into two dataframes for logging\n",
        "val_data = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/arize-assets/fixtures/demand_forecast_val.csv\"\n",
        ")\n",
        "prod_data = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/arize-assets/fixtures/demand_forecast_prod.csv\"\n",
        ")\n",
        "feature_column_names = val_data[\n",
        "    [\n",
        "        \"item_size\",\n",
        "        \"supplier_id\",\n",
        "        \"avg_historical_sales\",\n",
        "        \"cur_projected_sales\",\n",
        "        \"item_new_release_flag\",\n",
        "        \"item_stickyness_factor\",\n",
        "        \"item_release_year\",\n",
        "        \"shelf_life_weeks\",\n",
        "    ]\n",
        "].columns\n",
        "\n",
        "print(\"‚úÖ Dependencies installed and data successfully downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# select features, prediction, and actual columns only\n",
        "prod_data[list(feature_column_names) + [\"predictions\", \"actuals\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIM5Q70nb8vy"
      },
      "source": [
        "# Step 1. Sending Data into Arize üí´\n",
        "First, copy the Arize `API_KEY` and `SPACE_KEY` from your admin page shown below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCiFPCYi64R-",
        "outputId": "9a4f6eb7-6055-4c14-acc1-9ed319a6d510"
      },
      "outputs": [],
      "source": [
        "SPACE_KEY = \"SPACE_KEY\"\n",
        "API_KEY = \"API_KEY\"\n",
        "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
        "\n",
        "model_id = (\n",
        "    \"demand-forecast-demo-model\"  # This is the model name that will show up in Arize\n",
        ")\n",
        "model_version = \"v1.0\"  # Version of model - can be any string\n",
        "\n",
        "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else:\n",
        "    print(\"‚úÖ Arize setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f812QnU9ynm-"
      },
      "source": [
        "### Using the Python SDK\n",
        "For our dataset, we have pre-formatted the feature names and dataframes for logging to Arize using our Python SDK through `arize.pandas.logger`. The `Schema` of your model specifies a mapping from column names for your logging DataFrame. \n",
        "\n",
        "Here's a summary below:\n",
        "\n",
        "| Schema Argument Name | Description |||\n",
        "|:- |:-|---|---|\n",
        "| `feature_column_names`| names of the columns representing features |||\n",
        "| `prediction_id_column_name`| list of unique ids you can use to use to match each record |||\n",
        "| `prediction_label_column_name`| predictions column name |||\n",
        "| `actual_label_column_name`| actuals column name |||\n",
        "| `timestamp_column_name`| timestamps for when predictions were made |||\n",
        "\n",
        "For more details on how to send data in production to Arize, check out some of our other logging tutorials and SDK documentations in Gitbook.\n",
        "\n",
        "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Log Validation & Production Data to Arize "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7j94jt8cBlx",
        "outputId": "609c8818-9e55-4258-df15-923f4b36f9f0"
      },
      "outputs": [],
      "source": [
        "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
        "validation_schema = Schema(\n",
        "    feature_column_names=feature_column_names,\n",
        "    prediction_id_column_name=\"prediction_ids\",\n",
        "    prediction_label_column_name=\"predictions\",\n",
        "    actual_label_column_name=\"actuals\",\n",
        ")\n",
        "\n",
        "# Logging to Arize platform using arize_client.log\n",
        "val_response = arize_client.log(\n",
        "    dataframe=val_data,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    batch_id=\"baseline\",\n",
        "    model_type=ModelTypes.NUMERIC,\n",
        "    environment=Environments.VALIDATION,\n",
        "    schema=validation_schema,\n",
        ")\n",
        "\n",
        "production_schema = Schema(\n",
        "    feature_column_names=feature_column_names,\n",
        "    prediction_id_column_name=\"prediction_ids\",\n",
        "    timestamp_column_name=\"prediction_ts\",\n",
        "    prediction_label_column_name=\"predictions\",\n",
        "    actual_label_column_name=\"actuals\",\n",
        ")\n",
        "\n",
        "prod_response = arize_client.log(\n",
        "    dataframe=prod_data,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=ModelTypes.NUMERIC,\n",
        "    environment=Environments.PRODUCTION,\n",
        "    schema=production_schema,\n",
        ")\n",
        "\n",
        "# Checking responses to make sure our data was successfully ingested\n",
        "if val_response.status_code != 200 or prod_response.status_code != 200:\n",
        "    print(f\"logging failed with response code {response.status_code}, {response.text}\")\n",
        "else:\n",
        "    print(f\"‚úÖ You have successfully logged data to Arize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tmeTIX1aSfC"
      },
      "source": [
        "# Step 2. Confirm Data in Arize ‚úÖ\n",
        "Note that the Arize performs takes about 10 minutes to index the data. While the model should appear immediately, the data will not show up untill the indexing is done. Feel free to go grab a cup of coffee as Arize works its magic! üîÆ\n",
        "\n",
        "**The next sections (Part 2 and Part 3) are screen captures for tutorials to setting-up the model we just sent in.**\n",
        "\n",
        "Feel free to follow and mirror our instructions to set-up the dashboards yourself, or simply read the guide below to see how Arize can quickly generate value for demand forecasting models.\n",
        "\n",
        "**‚ö†Ô∏è DON'T SKIP:**\n",
        "In order to move on to the next step, make sure your actuals and training/production sets are loaded into the platform. To check:\n",
        "1. Navigate to models from the left bar, locate and click on model **demand-forecast-tutorial**\n",
        "2. On the **Overview Tab**, make sure you can see Predictions and Actuals under the **Model Health** section. Once production actuals have been fully recorded on Arize, the row title will change from **0 Actuals** to **Actuals** with summary statistics such as cardinality listed in the tables.\n",
        "3. Verify the list of **Features** below **Actuals**.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-waiting-actuals.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT6lV0qJNlmW"
      },
      "source": [
        "# Step 3. Improving Model Observability & Business Insight\n",
        "Now that our data has been logged to the Arize platform, let's investigate the low performances events we have been hearing about!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL6RgKSpNpLN"
      },
      "source": [
        "## **Baseline Configurations**\n",
        "We will first need to set-up a baseline distribution by clicking on the **Config** button. This will serve as the reference distribution and benchmark for our production data. We will use a validation set we sent in, but you can choose a production window or training set as our reference distribution. \n",
        "\n",
        "\n",
        "Here are the steps to follow:\n",
        "1.   Click on **Config** button on top right\n",
        "2.   Click on **Configure Baseline** button to select a reference distribution\n",
        "3. Select **Validation** for **Version v1.0**\n",
        "\n",
        "\n",
        "\n",
        "‚ö†Ô∏è We recommend doing this first for all of models you track to Arize.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-baseline-configgif.gif\" width=\"1200\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixkj8771aYoO"
      },
      "source": [
        "## **Understanding Error Biases**\n",
        "Each prediction of our model in production translates to an operational decision by our retail company. In this case, **demand forecasting** is only important in so far as it can allow better **supply management**.\n",
        "\n",
        "In our example retail demand forecasting company, **under-forecasting** is much more problematic since customers aren‚Äôt delivered on what they wanted, we could lose out on customer lifetime value. Thus, we want to monitor our **Mean Error** in addition to **Mean Absolute Error**.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/forecasting-bias-problem.png\" width=\"600\">\n",
        "\n",
        "## **Monitoring Biases with Performance Monitors**\n",
        "\n",
        "Even if our model is only trained on loss functions of **Mean Squared Error** or **Mean Absolute Error**, we sometimes still care about the **Mean Error** because it often tells us about the biases in our predictions, and these biases has a tangibly different impact on our business.\n",
        "\n",
        "Let‚Äôs set-up an Arize **Performance Monitor** to visualize and monitor our performance following these steps...\n",
        "\n",
        "\n",
        "1.   Navigate to the **Monitors** tab\n",
        "2.   Click on **Create Model Performance Monitor**\n",
        "3.   Select **`Mean Error`** as your **Evaluation Metric**\n",
        "4.   Select to trigger alert when **metrics is below -7.5** \n",
        "\n",
        "\n",
        "\n",
        "**You can click on the gifs to replay it**\n",
        "[<img src=\"https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-perf-monitor.gif\" width=\"1200\">](https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-perf-monitor.gif)\n",
        "\n",
        "### **Summary**\n",
        "Performance Dashboards can help you monitor production using the metric important to your business function, such as Mean Error in this case. You can access them under performance tab and set-up alerts for when metric dips below or above a certain number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjSOk64uNuse"
      },
      "source": [
        "## **Arize Dashboard Configurations**\n",
        "Now that we understand the importance of **Mean Error** as a measure of prediction bias, we also want to monitor and visualize it along with **Mean Absolute Error** side by side. Many Data Scientists reading this section will immediately understand that Mean Error alone isn't the informative, because there are often **coinciding event** of **both** over and under prediction, resulting in a zero-sum Mean Error.\n",
        "\n",
        "We can avoid this with a side-by-side time series chart in our custom times series widget on our Dashboard.\n",
        "\n",
        "### **1. Performance Dashboard**\n",
        "Performance Dashboard is a customizable feature where you can monitor time series data, feature/prediction distribution, and model metrics all in one place. You can even monitor only a slice or subset of your production data based on your model performance metric.\n",
        "\n",
        "Following these steps\n",
        "1.  Click on **Create Dashboard** and select **Regression Performance Dashboard**\n",
        "\n",
        "This will create a dashboard with many useful default widget already created for your regression model.\n",
        "\n",
        "2. Under the card **Model Evaluation Metric By Day**, we delete **MAPE** curve and change **RMSE** to **Mean Error**.\n",
        "3. Save the widget, and publish changes to our dashboard.\n",
        "\n",
        "### **2. Setting-up initial dashboard**\n",
        "[<img src=\"https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-dashboard.gif\" width=\"1200\">](https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-dashboard.gif)\n",
        "\n",
        "### **3. Creating Data Metric Times Series Widget**\n",
        "Let's also create a data metric time series widget to visualize the average values of our predictions vs actuals. In this way, we can **visualize errors along with actuals** to validate the magnitude of our prediction error.\n",
        "\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-data-metrics-create.png\" width=\"1200\">\n",
        "\n",
        "We want create a new card right under our `Model Evaluation Metrics by Day` card by doing the following:\n",
        "\n",
        "1.   Select **Times Series** Widges\n",
        "2.   Select **Data Metrics**\n",
        "3.   Choose `Prediction/Actual` and `Average` for curves\n",
        "\n",
        "### **4. Interpreting Our Dashboard**\n",
        "Here's the final product of what our dashboard would look like, and when those error biases happen.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-visualize-bias.png\" width=\"1200\">\n",
        "\n",
        "\n",
        "Now we can clearly visualize prediction biases and overall model accuracy with two charts.\n",
        "\n",
        "1.   The top chart compares the errors using MAE and ME, showing us the magnitude and direction of our error biases\n",
        "2.   The second shows us the averages of our predictions and actuals, giving us additional information to identify validate the over or under estimation event.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eST3BeIjOOut"
      },
      "source": [
        "## **Observability & Business Insight Summary**\n",
        "[The Arize platform](https://app.arize.com/) provides the tools for engineers, product teams, and even data scientists to quickly gain business insight for better strategical decision making.\n",
        "\n",
        "In this section we...\n",
        "1.   Set-up a **Baseline** from our validation set to continiously compare it our production data.\n",
        "2.   Created a **Mean Error Performance Monitor** so that we will be alerted whenever we detects a negative bias (i.e turned away customers)\n",
        "3. Customized a times series widget on **Dashboard** to visualize **Mean Error** side by side with **Mean Absolute Error** to understand both the magnitude and direction of our prediction biases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1K_1zp8dFS3"
      },
      "source": [
        "# Step 4. Empowering ML Engineers to Troubleshoot\n",
        "Now that we have identified when our underprediction and overprediction event happened, lets go into a deep dive to understand why they happened.\n",
        "\n",
        "Arize can also be used to triage your ML model performance. The model performance troubleshooting tools are designed by ML engineers for engineers to help you understand and solve your model performance issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmoN5A8NdJDF"
      },
      "source": [
        "## **Investigating production windows with low performance**\n",
        "In our **Drift Tab** overview, we clearly see two time periods where the distribution has changed. You can click on the dates to see the feature distribution and drift of that particular day. You might have noticed that the the first drift corresponds to when we observed an over-estimating event in Part 2, and the second corresponds to an under-estimating event.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-whats-drift-tab.png\" width=\"800\">\n",
        "\n",
        "Let's sort by **Drift(PSI)** and investigate several of these features and click on one of the days of the second prediction drift, we can see that a number of features have drifted in these days. \n",
        "\n",
        "[<img src=\"https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-drift.gif\" width=\"1200\">](https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-drift.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ5I14nh0Oa7"
      },
      "source": [
        "## **Deep Dive into Root Cause**\n",
        "Two features `item_new_release_flag` and `item_size` seem to have high drift\n",
        "1.   Click on one of the days during the second drift period (underpredicting period)\n",
        "2.   Click into either feature through the red alert button\n",
        "3.   Observe that their feature drift timeline coincided with prediction drift\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-new-release-drift.png\" width=\"800\">\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/demand-forecast-item-size-drift.png\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leCWCB8TdN2B"
      },
      "source": [
        "## **Turning Insight into Action**\n",
        "\n",
        "We used the **Drift Tab** to investigate dates of feature drifts and prediction drifts. Not all feature drifts are inherently maligant and impact our model performances -- only some do. With the insights provided on Arize, you can deep dive into root causes and quickly gain intuitions, allowing for ML teams to quickly iterate, experiment, and ship new models in production.\n",
        "\n",
        "In this case, by visualizing the feature drift and understanding the features responsible, our ML Engineers now have additional information to work with when improving our models when troubleshooting model performance issues with the drift tab.\n",
        "\n",
        "Some possible conclusions and action items our engineers could make might be...\n",
        "\n",
        "1.  Examining possible concept drifts relating to the two features in question\n",
        "2.  Retraining our model to fit new distributions specific to this drift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoHhu8awNdxG"
      },
      "source": [
        "# üìö Conclusion \n",
        "In this tutorial, we first logged 30 days of production data to Arize using our **Python SDK** and developed an understanding that Mean Error is an important metric to monitor under-prediction and therefore customer satisfaction. \n",
        "\n",
        "We then set-up a **Performance Monitor** to monitor Mean Error, and set-up a **Performance Dashboard** to ensure we can gain greater performance observability and insight into both MAE and ME side-by-side for our business objective.\n",
        "\n",
        "Lastly, we used **Drift Tab** to investigate potential reasons for our model under-prediction event. One feature drift in `item_new_release_flag` and `item_size` coincided with only the under-prediction event, so we came up with several conclusions that our ML Engineers could have drawn from this observation to improve and troubleshoot our model in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbXv-W3JgatG"
      },
      "source": [
        "# About Arize\n",
        "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
        "- Automated ML monitoring and model monitoring\n",
        "- Workflows to troubleshoot model performance\n",
        "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
        "- Model prediction cohort analysis\n",
        "- Pre-deployment model validation\n",
        "- Integrated model explainability\n",
        "\n",
        "### Website\n",
        "Visit Us At: https://arize.com/model-monitoring/\n",
        "\n",
        "### Additional Resources\n",
        "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
        "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
        "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
        "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
        "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
        "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
        "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
        "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
        "\n",
        "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "demand-forecast-usage-caseipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

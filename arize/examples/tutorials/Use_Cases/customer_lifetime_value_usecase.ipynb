{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS9SS3oURkFw"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"200\"/>\n",
        "\n",
        "# Getting Started with the Arize Platform - Customer Lifetime Value in Telecommunication Industry\n",
        "\n",
        "**You are part of a team in a telecommunication company that monitors and maintains a customer lifetime value (LTV) regression model, which predicts the LTV for each customer.** The business objective of this regression model is to accurately predict customer lifetime value in order to improve customer segmentation and profiling to customize offers and target customers based on their potential value and recognize best customers.\n",
        "\n",
        "You understand that flaws in your model performance will have a huge negative impact on your company and with your LTV model in production you don't have any effective tool at your disposal to monitor the performance of your models, identify any issues and troubleshoot costly model degradations. Therefore, you turn to Arize to help you understand what went wrong in your model and how you can improve it. \n",
        "\n",
        "\n",
        "**In this walkthrough, we are going to investigate your production LTV model. We will validate degradation in model performance, take a deep dive to investigate the root causes of those inaccurate predictions, and set up proactive monitors to mitigate the impact of future degradations.**\n",
        "\n",
        "\n",
        "You will learn how to:\n",
        "\n",
        "1.   Get training and production data into the Arize platform\n",
        "2.   Setup performance dashboards and monitors to look at prediction performance\n",
        "3.   Understand where the model is underperforming\n",
        "4.   Discover the root cause of issues\n",
        "5. Set up pro-active monitoring to mitigate the impact of such degradations in the future\n",
        "\n",
        "\n",
        "The production data contains 1 month of data where 2 main issues exist. You will work on identifying these issues over the course of this exercise.\n",
        "\n",
        "1.   A data source has introduced changes in the distribution of particular features\n",
        "2.   The model is inacurate during some time period due to particular features "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd0U7-RuRh2A"
      },
      "source": [
        "\n",
        "\n",
        "# Step 0. Setup and Getting the Data\n",
        "\n",
        "The first step is to load our preexisting dataset which includes training and production environments for our LTV model. Using a preexisting dataset illustrates how simple it is to get started with the Arize platform.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krle3DI8uNoy"
      },
      "source": [
        "## Install Dependencies and Import Libraries üìö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdKYTc3ORalw",
        "outputId": "c44112b5-450a-458c-e17c-8a675694a13b"
      },
      "outputs": [],
      "source": [
        "!pip install -q arize\n",
        "\n",
        "import datetime\n",
        "import uuid\n",
        "from datetime import timedelta\n",
        "\n",
        "import pandas as pd\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import Environments, ModelTypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XOQE2A9uelK"
      },
      "source": [
        "## **üåê Download the Data**\n",
        "In this walkthrough, we‚Äôll be sending real historical data. Note, that while feature names and values are made explicit in this dataset, you can achieve the same level of ML Observability using obfuscated features. \n",
        "\n",
        "| Feature | Type | Description |||\n",
        "|:-|:-|:-|---|---|\n",
        "| `City`| `str`| city in California where the customer resides |||\n",
        "| `Gender`| `str`| customer's gender |||\n",
        "| `Partner`| `str`| flag indicating if the customer has a partner |||\n",
        "| `Dependents`| `str`| flag indicating if the customer has dependents |||\n",
        "| `Phone Service`| `str `| flag indicating if the customer has phone service |||\n",
        "| `Internet Service`| `str`| flag indicating if the customer has internet service |||\n",
        "| `Streaming TV`| `str`| flag indicating if the customer streams TV |||\n",
        "| `Streaming Movies`| `str`| flag indicating if the customer streams movies |||\n",
        "| `Churn Value`| `int (0 or 1)`| flag indicating if the customer churned |||\n",
        "\n",
        "## Inspect the Data \n",
        "\n",
        "The data represents a regression model trained to predict LTV for a customer. The dataset contains one month of data and the performance will be evaluated by comparing:\n",
        "\n",
        "*   **`Predicted LTV`**: Predicted value of LTV for each customer\n",
        "*   **`Actual LTV`**: Actual value of LTV for each customer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jf3rAuAmGHa",
        "outputId": "0811f986-c7ed-4115-ea9a-dcc0752286fc"
      },
      "outputs": [],
      "source": [
        "# Preparing dataset for this tutorial\n",
        "train_df = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/LTV_train.csv\"\n",
        ")\n",
        "test_df = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/LTV_test.csv\"\n",
        ")\n",
        "\n",
        "\n",
        "print(\"‚úÖ Dependencies installed and data successfully downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zevjJmzI6M0T"
      },
      "source": [
        "## Inspect and Prepare the Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "PUsrZN_IYQVN",
        "outputId": "5a354d43-e399-45f1-adba-0292cbc56bc1"
      },
      "outputs": [],
      "source": [
        "# Preparing Training Data\n",
        "train_df[\"prediction_id\"] = [str(uuid.uuid4()) for _ in range(len(train_df))]\n",
        "train_df = train_df.drop(columns=[\"Unnamed: 0\"])\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "7jcbvIgxYa_K",
        "outputId": "f6ce9c34-a4d2-42ab-c057-f48e7116a0a0"
      },
      "outputs": [],
      "source": [
        "# Preparing production data\n",
        "def prod_ID_time(df, start, end):\n",
        "    max_d = df[\"day\"].max()\n",
        "    out_df = pd.DataFrame()\n",
        "    dts = pd.date_range(start, end).to_pydatetime().tolist()\n",
        "    for dt in dts:\n",
        "        day_df = df.loc[df[\"day\"] == (dt.day % max_d)].copy()\n",
        "        day_df[\"prediction_ts\"] = int(dt.strftime(\"%s\"))\n",
        "        out_df = pd.concat([out_df, day_df], ignore_index=True)\n",
        "    out_df[\"prediction_id\"] = [str(uuid.uuid4()) for _ in range(out_df.shape[0])]\n",
        "    return out_df.drop(columns=\"day\")\n",
        "\n",
        "\n",
        "today = datetime.date.today()\n",
        "END_DATE = (today).strftime(\"%Y-%m-%d\")\n",
        "START_DATE = (today - timedelta(31)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "test_df = prod_ID_time(test_df, START_DATE, END_DATE)\n",
        "test_df = test_df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liVb6DFTwSBo"
      },
      "source": [
        "# Step 1. Sending Data into Arize üí´\n",
        "\n",
        "Now that we have our dataset imported, we are ready to integrate into Arize. We do this by logging (sending) important data we want to analyze to the platform. There, the data will be easily visualized and troubleshooting workflows will help us find the source of our problem.\n",
        "\n",
        "For our model, we are going to log:\n",
        "*   feature data\n",
        "*   predictions\n",
        "*   actuals\n",
        "\n",
        "## Import and Setup Arize Client\n",
        "\n",
        "The first step is to setup our Arize client. After that we will log the data.\n",
        "\n",
        "First, copy the Arize `API_KEY` and `SPACE_KEY` from your admin page shown below! Copy those over to the set-up section. We will also be setting up some metadata to use across all logging.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXAPWHo_WmfY",
        "outputId": "d917ddbd-0b32-4694-b918-d86726c3412f"
      },
      "outputs": [],
      "source": [
        "SPACE_KEY = \"SPACE_KEY\"\n",
        "API_KEY = \"API_KEY\"\n",
        "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
        "\n",
        "# Saving model metadata for passing in later\n",
        "model_id = \"customer-lifetime-value-demo-model\"  # This is the model name that will show up in Arize\n",
        "model_version = \"v1.0\"  # Version of model - can be any string\n",
        "\n",
        "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else:\n",
        "    print(\"‚úÖ Arize setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy3V7oUAWmo5"
      },
      "source": [
        "## Log Training & Production Data to Arize \n",
        "\n",
        "Now that our Arize client is setup, let's go ahead and log all of our data to the platform. For more details on how **`arize.pandas.logger`** works, visit out documentations page below.\n",
        "\n",
        "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)\n",
        "\n",
        "Key parameters:\n",
        "\n",
        "*   **prediction_label_column_name**: tells Arize which column contains the predictions\n",
        "*   **actual_label_column_name**: tells Arize which column contains the actual results from field data\n",
        "\n",
        "\n",
        "We will use [ModelTypes.NUMERIC](https://docs.arize.com/arize/concepts-and-terminology/model-types) to perform this analysis.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIgUnns_K-NQ"
      },
      "source": [
        "### Log the training data for your model to Arize!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUuPYMkVXGzx",
        "outputId": "b84676f9-dc85-4297-e488-90c31722ca55"
      },
      "outputs": [],
      "source": [
        "# Define a Schema() for Arize to pick up the data from the correct column for logging\n",
        "\n",
        "train_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",\n",
        "    prediction_label_column_name=\"Predicted LTV\",\n",
        "    actual_label_column_name=\"Actual LTV\",\n",
        "    feature_column_names=train_df.columns.drop(\n",
        "        [\"prediction_id\", \"Predicted LTV\", \"Actual LTV\"]\n",
        "    ),\n",
        ")\n",
        "\n",
        "train_res = arize_client.log(\n",
        "    dataframe=train_df,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=ModelTypes.NUMERIC,\n",
        "    environment=Environments.TRAINING,\n",
        "    schema=train_schema,\n",
        ")\n",
        "if train_res.status_code != 200:\n",
        "    print(f\"future failed with response code {train_res.status_code}, {train_res.text}\")\n",
        "else:\n",
        "    print(f\"future completed with response code {train_res.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVg0YSwxLIeO"
      },
      "source": [
        "### Log the production data\n",
        "Note: We will be sending our test data to emulate sending production data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di9OXa0MLQWY",
        "outputId": "a8e86635-e13d-49d5-9720-b371e1051d72"
      },
      "outputs": [],
      "source": [
        "# Logging production\n",
        "all_cols = test_df.columns\n",
        "feature_cols = all_cols.drop(\n",
        "    [\"prediction_id\", \"prediction_ts\", \"Predicted LTV\", \"Actual LTV\"]\n",
        ")\n",
        "\n",
        "test_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",\n",
        "    timestamp_column_name=\"prediction_ts\",\n",
        "    prediction_label_column_name=\"Predicted LTV\",\n",
        "    actual_label_column_name=\"Actual LTV\",\n",
        "    feature_column_names=feature_cols,\n",
        ")\n",
        "\n",
        "test_res = arize_client.log(\n",
        "    dataframe=test_df,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=ModelTypes.NUMERIC,\n",
        "    environment=Environments.PRODUCTION,\n",
        "    schema=test_schema,\n",
        ")\n",
        "if test_res.status_code != 200:\n",
        "    print(f\"future failed with response code {test_res.status_code}, {test_res.text}\")\n",
        "else:\n",
        "    print(f\"future completed with response code {test_res.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rJ6vMVKxQVf"
      },
      "source": [
        "# Step 2. Confirm Data in Arize ‚úÖ\n",
        "\n",
        "Note that the Arize performs takes about 10 minutes to index the data. While the model should appear immediately, the data will not show up until the indexing is complete. Feel free to go grab a cup of coffee as Arize works its magic! ‚òïüîÆ\n",
        "\n",
        "**‚ö†Ô∏è DON'T SKIP:**\n",
        "In order to move on to the next step, make sure your actuals and training/production sets are loaded into the platform. To check:\n",
        "1. Navigate to models from the left bar, locate and click on model **LTV-use-case-tutorial**\n",
        "2. On the **Overview Tab**, make sure you can see Predictions and Actuals under the **Model Health** section. Once production actuals have been fully recorded on Arize, the row title will change from **0 Actuals** to **Actuals** with summary statistics such as cardinality listed in the tables.\n",
        "3. Verify the list of **Features** below **Actuals**.\n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/newmodel.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFivwR9rxfxw"
      },
      "source": [
        "# Step 3. Set up Model Baseline & Managed Monitors\n",
        "\n",
        "Now that our data has been logged into the [Arize platform](https://app.arize.com/) we can begin our investigation into our poorly performing LTV regression model. \n",
        "\n",
        "Arize will guide you through setting up a **Baseline** (reference environment for comparison) and automatically create **Monitors** for your model in just a few clicks ‚Äîjust follow the blue banner at the top of the page titled \"Finish setting up your model\". \n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/Click-Through%20Rate%20Use-Case/images/initial_setup_banner.png)\n",
        "\n",
        "Arize can automatically configure monitors that are best suited to your data. From the banner at the top of the screen, select the following configurations after clicking the 'Set up Model' button: \n",
        "\n",
        "1. Datasets: `Training Version 1.0`\n",
        "2. Default Metric: `RMSE`, Trigger Alert When: `RMSE is above 80`\n",
        "3. Turn On Monitoring: Drift ‚úÖ, Data Quality ‚úÖ, Performance ‚úÖ \n",
        "\n",
        "You will now see that the baseline has been set and **Drift**, **Data Quality**, and **Performance** monitors have been created!!! \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/modelsetup.gif)\n",
        "\n",
        "Arize automatically sets up monitors to ensure our model is flagged if the Performance, Data Quality, or Drift spikes above a certain threshold/before it becomes a major issue. You can see filter monitors by category, edit evaluation windows, thresholds, etc. and create custom monitors by visiting the **Monitors** tab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyVgx8DFyfle"
      },
      "source": [
        "# Step 4. Exploring Drift \n",
        "\n",
        "Selecting the **Drift** tab we notice that we do not see any noticeable model prediction drift in production compared to our training dataset (baseline).  \n",
        "It's important to note that while we do not see any prediction drift, we do notice an increase in RMSE between day 22 and day 3.\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-18%20at%2011.48.45%20PM.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dk3OVgnjk9k"
      },
      "source": [
        "# Step 5. Analyzing feature drift\n",
        "During intial model setup, Arize automatically created a set drift monitors and dashboards for each feature available in the dataset. Drift is represented as the Population Stability Index (PSI) over an given period. We will use these graphs to monitor overall trends. From the model overview page, select the **Internet Service** feature and you should notice the change in Internet Service distribution. Use the PSI graph to select a period of interest. Notice that the default threshold set by Arize was crossed for the same period that the RMSE spiked.\n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-18%20at%2011.57.16%20PM.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2tD6aJ3jzsA"
      },
      "source": [
        "# Step 6. Setting up a proactive custom monitor \n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-19%20at%2011.37.06%20AM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gusY1VW0j64v"
      },
      "source": [
        "# Step 7. Analyzing Root Cause \n",
        "\n",
        "Arize facilitates troubleshooting which features and more specifically slices (feature/value combinations) could be the culprit of our model's performance degradation. Arize provides a number of flexible dashboard templates for users to get started in creating custom layouts for surfacing model insights. Let's see how in just a few clicks we can quickly identify which features could be causing our model to perform so badly. Navigate to the **Templates** section on the left sidebar and scroll down to click on the **Feature Performance Heatmap**. From there select your model, select the features you care to investigate, metric `RMSE`. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/heatmap.gif)\n",
        "\n",
        "Arize automatically discovers and surfaces model performance issues across all features and various feature/value combinations. Visual indicators facilitate drill down analysis of the most problematic slices affecting your overall model performance. \n",
        "\n",
        "Some of the immediate insights surfaced from our **Feature Performance Heatmap** are detailed below. \n",
        "1. Worst performing `Internet Service` is `Fiber Optic`\n",
        "2. Worst performing `Streaming TV` is `Yes`\n",
        "3. Worst performing `Streaming Movies` is `Yes`\n",
        "4. Worst performing `City` includes `Moreno Valley`, `Roseville`, and `Novato.`\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-18%20at%2010.00.49%20PM.png)\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-18%20at%209.59.58%20PM.png)\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-18%20at%2010.00.16%20PM.png)\n",
        "\n",
        "\n",
        "\n",
        "We can further dive into a performance analysis of our model by filtering on various low performing feature/value slices. This will help determine the data needed to upsample and retrain our model to improve performance on these segments. For example, by adding a filter in our **Feature Performance Heatmap** we can narrow down where the model degradation is originating from and through which features it is most prominent. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-19%20at%2011.22.55%20AM.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihInstFsA3vx"
      },
      "source": [
        "# Step 8. Feature Performance Insights --> Actions \n",
        "\n",
        "Using the insights gathered from our **Feature Performance Heatmap**, we can take action to use our findings to improve our model. As noted previously, the slice (feature/value combination) `Streaming TV: Yes`, along with `Internet Service` and `Streaming Movies`, was one of the worst performing segments for our model. Navigate back to the model **Overview** page and click into the `Streaming TV` feature under the **Features** section. \n",
        "\n",
        "Upon first glance, we see that `Streaming TV` is starting to drift around day 21 where the model experienced more data from the `Yes` variable, which was also accompanied by an increase in RMSE during the same time frame.\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-19%20at%2012.02.18%20AM.png)\n",
        "\n",
        "\n",
        "Similarly, by navigating to `City` we notice significant drift across training and production distributions across various regions like `Novato` and `Roseville`. Furthermore, we notice that our training dataset (Baseline distribution) had little to no values for these cities. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-19%20at%2012.10.23%20AM.png)\n",
        "\n",
        "This troubleshooting flow has lead us to understand that retraining the model on these slices of feature/value combinations (namely `City`:`Novato, Roseville`, `Streaming TV`: `Yes` and  `Internet Service`: `Yes`) could significantly improve our model's RMSE performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRgz8oGe-iuh"
      },
      "source": [
        "# Step 9. Model Performance Overview\n",
        "\n",
        "We can get a quick performance overview by clicking on the performace tab under your specific model. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-19%20at%2011.42.50%20AM.png)\n",
        "\n",
        "\n",
        "As we continue to check in and improve our model's performance, we want to be able to efficiently view all our important model metrics in a single pane. In the same way we set up a **Feature Performance Heatmap** we will create a **Model Performance Dashboard** to view our model's most important metrics in a single configurable layout. \n",
        "\n",
        "Navigate to the **Templates** section on the left sidebar and scroll down to click on the **Regression Model**. From there select your model, features you care to investigate. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/regmodel.gif)\n",
        "\n",
        "In addition to the default widgets Arize sets up for your dashboard, you can configure custom metrics your team cares about. In only a few clicks I added a few widgets to give me a single glance view of my model's **RMSE**, **MAPE**, and **MAE** as standalone statistics widgets. To visualize these metrics over time I also created a timeseries widget and overlayed three plots showcase the fluctuation of my metrics over time. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/LTV%20Use-Case/Screen%20Shot%202021-10-19%20at%2011.17.11%20AM.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìö Conclusion \n",
        "\n",
        "Customer lifetime value is an important metric to consider in every business. Use Arize to identify segments where your LTV model is underperforming, troubleshoot root cause analysis, and proactively monitor for future degradations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_4UPugXyf7k"
      },
      "source": [
        "# About Arize\n",
        "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
        "- Automated ML monitoring and model monitoring\n",
        "- Workflows to troubleshoot model performance\n",
        "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
        "- Model prediction cohort analysis\n",
        "- Pre-deployment model validation\n",
        "- Integrated model explainability\n",
        "\n",
        "### Website\n",
        "Visit Us At: https://arize.com/model-monitoring/\n",
        "\n",
        "### Additional Resources\n",
        "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
        "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
        "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
        "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
        "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
        "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
        "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
        "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
        "\n",
        "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LTV Use-case.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

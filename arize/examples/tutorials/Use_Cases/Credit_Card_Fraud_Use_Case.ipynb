{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0TvdSg5HC3Q"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"200\"/>\n",
        "\n",
        "# Getting Started with the Arize Platform - Credit Card Fraud in the Banking Industry\n",
        "\n",
        "**You are responsible for a credit card fraud model at a large bank or payment processing company. You have been alerted by a spike in credit card chargebacks leading you to suspect that fraudsters are getting away with commiting fraud undetected!** Realizing that this flaw in your model's performance has a heavy cost on your company and customers, you understand the need for a powerful toolset to troubleshoot (and prevent) costly model degradations. You turn to Arize to find out what changed in your credit card fraud detection model and how you can improve it.\n",
        "\n",
        "In this walkthrough, we are going to investigate your production credit card fraud model. We will validate degradation in model performance, troubleshoot the root cause, and furthermore set up proactive monitors to mitigate the impact of future degradations.  \n",
        "\n",
        "We will set up monitors to proactively identify when our fraud model is not perfoming as expected, troubleshoot why we're seeing this deviation in production, and come up with actionable steps to improve the model.\n",
        "\n",
        "Our steps to resolving this issue will be:\n",
        "1. Get our model onto the Arize platform to investigate\n",
        "2. Setup a performance dashboard to look at prediction performance\n",
        "3. Understand where the model is underperforming\n",
        "4. Discover the root cause of why a slice (grouping) of predictions is underperforming\n",
        "5. Set up pro-active monitoring to mitigate the impact of such degradations in the future\n",
        "\n",
        "The production data contains 1 month of data where 2 main issues exist. You will work on identifying these issues over the course of this exercise.\n",
        "\n",
        "1. An upstream data source has introduced bad (null) values for ENTRY_MODE \n",
        "2. The model is missing fraud for certain merchant types,entry modes and merchant ids especially in certain regions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OHUs0p6HCsX"
      },
      "source": [
        "# Step 0. Setup and Getting the Data\n",
        "\n",
        "The first step is to load our preexisting dataset which includes training and production environments for our creditcard fraud model. Using a preexisting dataset illustrates how simple it is to get started with the Arize platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDVA4kK5HHqa"
      },
      "source": [
        "## Install Dependencies and Import Libraries üìö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCKzp837HOHN",
        "outputId": "d31d7439-306c-4b7f-db91-a4f105766dd6"
      },
      "outputs": [],
      "source": [
        "!pip install -q arize\n",
        "\n",
        "\n",
        "import datetime\n",
        "import tempfile\n",
        "import uuid\n",
        "from datetime import timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import Environments, ModelTypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C8bwEnXHHnx"
      },
      "source": [
        "## **üåê Download the Data**\n",
        "In this walkthrough, we‚Äôll be sending real historical data (with privacy conscious changes to feature names and values). Note, that while feature names and values are made explicit in this dataset, you can achieve the same level of ML Observability using obfuscated features. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJfb08E-HArO",
        "outputId": "5c1cc5b8-1809-48aa-cb3b-9cc654c63d06"
      },
      "outputs": [],
      "source": [
        "production = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/arize-assets/fixtures/Tags-Demo-Data/credit_card_fraud_production.csv\",\n",
        ")\n",
        "train = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/arize-assets/fixtures/Tags-Demo-Data/credit_card_fraud_training.csv\",\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Dependencies installed and data successfully downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG0pz7_AdZWb"
      },
      "source": [
        "## Inspect the Data \n",
        "\n",
        "Take a quick look at the dataset. The data represents a model designed and trained to evaluate the probability of a credit card transaction being fraud based on various features such as merchant_type, mean_amount, transaction amount, entry_mode, etc. The dataset contains one month of data and the performance will be evaluated by comparing:\n",
        "\n",
        "*   **PREDICTION**: The probability of a fraud transaction predicted by the model \n",
        "*   **ACTUAL**: Fraud or not fraud based on ground truth collected by credit card users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "7nAO3wHFHsuF",
        "outputId": "df091f1b-08a8-4c51-84d2-daf53a194268"
      },
      "outputs": [],
      "source": [
        "production.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiKjDrTG_2sN"
      },
      "outputs": [],
      "source": [
        "feature_column_names = [\n",
        "    \"MERCHANT_TYPE\",\n",
        "    \"MERCHANT_ID\",\n",
        "    \"ENTRY_MODE\",\n",
        "    \"STATE\",\n",
        "    \"MEAN_AMOUNT\",\n",
        "    \"STD_AMOUNT\",\n",
        "    \"TX_AMOUNT\",\n",
        "    \"VISA_RISK_SCORE\",\n",
        "    \"MASTERCARD_RISK_SCORE\",\n",
        "    \"AMEX_RISK_SCORE\",\n",
        "]\n",
        "shap_column_names = [f\"{x}_shap\" for x in feature_column_names]\n",
        "tag_column_names = ['Dependents', 'Partner', 'EmploymentStatus', 'LocationCode', 'Education', 'Gender', 'Age']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgJKldiSH6OL"
      },
      "source": [
        "# Step 1. Sending Data into Arize üí´\n",
        "\n",
        "Now that we have our dataset imported, we are ready to integrate into Arize. We do this by logging (sending) important data we want to analyze to the platform. There, the data will be easily visualized and troubleshooting workflows will help us find the source of our problem.\n",
        "\n",
        "For our model, we are going to log:\n",
        "*   feature data\n",
        "*   predictions\n",
        "*   actuals\n",
        "\n",
        "## Import and Setup Arize Client\n",
        "\n",
        "The first step is to setup our Arize client. After that we will log the data.\n",
        "\n",
        "First, copy the Arize `API_KEY` and `SPACE_KEY` from your admin page shown below! Copy those over to the set-up section. We will also be setting up some metadata to use across all logging.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XJANcnXH6kT"
      },
      "outputs": [],
      "source": [
        "SPACE_KEY = \"SPACE_KEY\"\n",
        "API_KEY = \"API_KEY\"\n",
        "\n",
        "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
        "\n",
        "model_id = (\n",
        "    \"creditcard-fraud-demo-model\"  # This is the model name that will show up in Arize\n",
        ")\n",
        "model_version = \"v1.0\"  # Version of model - can be any string\n",
        "\n",
        "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else:\n",
        "    print(\"‚úÖ Arize setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVIZgl2oIHGt"
      },
      "source": [
        "## Log Training & Production Data to Arize \n",
        "\n",
        "Now that our Arize client is setup, let's go ahead and log all of our data to the platform. For more details on how **`arize.pandas.logger`** works, visit out documentations page below.\n",
        "\n",
        "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)\n",
        "\n",
        "Key parameters:\n",
        "\n",
        "*   **prediction_label_column_name**: tells Arize which column contains the predictions\n",
        "*   **actual_label_column_name**: tells Arize which column contains the actual results from field data\n",
        "*   **preidction_score_column_name**: tells Arize which column contains the prediction score from field data\n",
        "*   **actual_label_column_name**: tells Arize which column contains the actual results from field data\n",
        "*   **actual_score_column_name**: tells Arize which column contains the actual score from field data\n",
        "\n",
        "Given that our model is predicting between categories, we will use [ModelTypes.SCORE_CATEGORICAL](https://docs.arize.com/arize/product-guides-1/models/model-types) to perform this analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbFoahq4IMfd"
      },
      "source": [
        "## Log Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLJMK3UeIJMk"
      },
      "outputs": [],
      "source": [
        "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
        "training_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",\n",
        "    prediction_label_column_name=\"PREDICTION\",\n",
        "    prediction_score_column_name=\"PREDICTION_SCORE\",\n",
        "    actual_label_column_name=\"ACTUAL\",\n",
        "    actual_score_column_name=\"ACTUAL_SCORE\",\n",
        "    feature_column_names=feature_column_names,\n",
        "    tag_column_names = tag_column_names,\n",
        ")\n",
        "\n",
        "# Logging Training DataFrame\n",
        "training_response = arize_client.log(\n",
        "    dataframe=train,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
        "    environment=Environments.TRAINING,\n",
        "    schema=training_schema,\n",
        ")\n",
        "\n",
        "# If successful, the server will return a status_code of 200\n",
        "if training_response.status_code != 200:\n",
        "    print(\n",
        "        f\"logging failed with response code {training_response.status_code}, {training_response.text}\"\n",
        "    )\n",
        "else:\n",
        "    print(f\"‚úÖ You have successfully logged training set to Arize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRQdEXZDIvMo"
      },
      "source": [
        "## Log Production Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoWpauUWIsmm"
      },
      "outputs": [],
      "source": [
        "# changing dates for ease of visualization / to mimic recent produciton dataset\n",
        "END_DATE = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
        "START_DATE = (datetime.date.today() - timedelta(31)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "\n",
        "def setPredictionIDandTime(df, start, end):\n",
        "    out_df = pd.DataFrame()\n",
        "    dts = pd.date_range(start, end).to_pydatetime().tolist()\n",
        "    for dt in dts:\n",
        "        day_df = df.loc[df[\"day\"] == dt.day].copy()\n",
        "        day_df[\"prediction_ts\"] = int(dt.strftime(\"%s\"))\n",
        "        out_df = pd.concat([out_df, day_df], ignore_index=True)\n",
        "    out_df[\"prediction_id\"] = [str(uuid.uuid4()) for _ in range(out_df.shape[0])]\n",
        "    return out_df.drop(columns=\"day\")\n",
        "\n",
        "\n",
        "production = setPredictionIDandTime(production, START_DATE, END_DATE)\n",
        "\n",
        "production_schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",\n",
        "    timestamp_column_name=\"prediction_ts\",\n",
        "    prediction_label_column_name=\"PREDICTION\",\n",
        "    prediction_score_column_name=\"PREDICTION_SCORE\",\n",
        "    actual_label_column_name=\"ACTUAL\",\n",
        "    actual_score_column_name=\"ACTUAL_SCORE\",\n",
        "    feature_column_names=feature_column_names,\n",
        "    shap_values_column_names=dict(zip(feature_column_names, shap_column_names)),\n",
        "    tag_column_names = tag_column_names,\n",
        ")\n",
        "\n",
        "production_response = arize_client.log(\n",
        "    dataframe=production,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
        "    environment=Environments.PRODUCTION,\n",
        "    schema=production_schema,\n",
        ")\n",
        "\n",
        "if production_response.status_code != 200:\n",
        "    print(\n",
        "        f\"logging failed with response code {production_response.status_code}, {production_response.text}\"\n",
        "    )\n",
        "else:\n",
        "    print(f\"‚úÖ You have successfully logged production set to Arize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GRDmDYmJWFt"
      },
      "source": [
        "# Step 2. Confirm Data in Arize ‚úÖ\n",
        "\n",
        "Note that the Arize performs takes about 10 minutes to index the data. While the model should appear immediately, the data will not show up until the indexing is complete. Feel free to head over to the **Data Ingestion** tab for your model to watch Arize works its magic!üîÆ\n",
        "\n",
        "**‚ö†Ô∏è DON'T SKIP:**\n",
        "In order to move on to the next step, make sure your actuals and training/production sets are loaded into the platform. To check:\n",
        "1. Navigate to models from the left bar, locate and click on model **arize-demo-creditcard-fraud**\n",
        "2. On the **Overview Tab**, make sure you can see Predictions and Actuals under the **Model Health** section. Once production actuals have been fully recorded on Arize, the row title will change from **0 Actuals** to **Actuals** with summary statistics such as cardinality listed in the tables.\n",
        "3. Verify the list of **Features** below **Actuals**.\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/fraud_overview.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkgBBB0IMHmv"
      },
      "source": [
        "# Step 3. Set up Model Baseline & Managed Monitors\n",
        "\n",
        "Now that our data has been logged into the [Arize platform](https://app.arize.com/) we can begin our investigation into our poorly performing fraud detection model. \n",
        "\n",
        "Arize will guide you through setting up a **Baseline** (reference environment for comparison) and automatically create **Monitors** for your model in just a few clicks ‚Äîjust follow the blue banner at the top of the page titled \"Finish setting up your model\". \n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/Click-Through%20Rate%20Use-Case/images/initial_setup_banner.png)\n",
        "\n",
        "Arize can automatically configure monitors that are best suited to your data. From the banner at the top of the screen, select the following configurations after clicking the 'Set up Model' button: \n",
        "\n",
        "1. Datasets: `Training Version 1.0`\n",
        "2. Default Metric: `False Negative Rate`, Trigger Alert When: `False Negative Rate is above .2`, Positive Class: `FRAUD`\n",
        "3. Turn On Monitoring: Drift ‚úÖ, Data Quality ‚úÖ, Performance ‚úÖ \n",
        "\n",
        "You will now see that the baseline has been set and **Drift**, **Data Quality**, and **Performance** monitors have been created!!! \n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/fraud_setupbaseline.gif)\n",
        "\n",
        " \n",
        "To prevent expensive chargebacks from getting by our models undetected Arize automatically sets up monitors to ensure our model is flagged if Performance, Data Quality, or Drift spikes above a certain threshold/before it becomes a major issue. You can see filter monitors by category, edit evaluation windows, thresholds, etc. and create custom monitors by visiting the **Monitors** tab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmlvQgN2N13z"
      },
      "source": [
        "# Step 4. Setting up proactive custom monitors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K6n4rLpN11b"
      },
      "source": [
        "**Arize sets up monitors across all features, predictions, and actual values.** In fraud detection it's important to monitor your model's: \n",
        "\n",
        "\n",
        "1.   False Negative Rate ‚Äî¬†Chargeback % (fraud transactions that were identified by the model as non fraud leading to a chargeback/immediate financial loss for the company).\n",
        "2.   False Positive Rate ‚Äî Upset Customer % (non fraud transactions that were classified as fraud leading to an awkward moment at the register and an upset customer). \n",
        "3.  Accuracy ‚Äî¬†of all my predictions, what percent did the model predict correctly? We need to be careful with this metric as it can be potentially misleading, especially if there is a small amount of fraud transactions. If a model has 1% fraud, misclassifying all transactions can still result in 99% accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L4Vizc5SaS8"
      },
      "source": [
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/monitor_FNR.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0o72uxwN1y6"
      },
      "source": [
        "# Step 5. Exploring Drift\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV_swqQDN1wC"
      },
      "source": [
        "Selecting the **Drift** tab we notice a noticeable model prediction drift in production compared to our training dataset (baseline) for a period of 4 days. By taking a look at the **Distribution Comparison** beneath the **Prediction Drift over Time** widget we notice that in our training dataset (Baseline Distribution) we expect to see around 1% FRAUD whereas in our production dataset (Current Distribution) we see highs of almost 25% FRAUD!\n",
        " \n",
        " \n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/prediction_drift_fraud.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA-2w3x9UG7b"
      },
      "source": [
        "# Step 6. Performance Analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IhJexvtUEQW"
      },
      "source": [
        "Once a performance monitor is triggered, navigate to the **Performance** tab to start troubleshooting your model issues and gain an understanding of what caused the degradation. The false negative rate (our default performance metric) is plotted over the last 30 days and it is overlaid on top of bars which measure the volume of predictions. Our model is doing pretty well but there have been a few spikes in false negative rate down to ~0.2 so let's look into what could be driving performance down.\n",
        "\n",
        "If you scroll down, the **Output Segmentation** section includes a confusion matrix which is useful for our model as it is assigning a class to the prediction.\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/perftab_fraud_overview.png)\n",
        "\n",
        "Let's scroll down even further to the **Performance Breakdown by Feature**, this section is very useful to uncover low performing cohorts within a feature. Since this model is producing SHAP values for every prediction, Arize is able to use those SHAP values to weight performance within each feature to create a **Performance Impact Score**. By sorting by this score instead of just feature importance or min/max performance, Arize is able to surface to the top, the top features that are attributing to decreased performance.\n",
        "\n",
        "At the top of the **Performance Breakdown by Feature** list is `STATE` so let's expand this feature. Now we see a list of the inputs to this feature which are a couple of categorical values. By hovering over bar, Arize displays the volume that this input was utilized in predictions and the performance metric for that cohort. \n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/fraud_state_perf.png)\n",
        "\n",
        "**We can start by comparing the production to training dataset.** This can help answer questions such as \"Were we seeing this problem in training?\" or \"Does my new / previous model version perform better?\". It can also be helpful to compare to other windows of production.\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/perf_tab_fraud.gif)\n",
        "\n",
        "\n",
        "\n",
        "Here, we can identify low performing segments. By looking at performance breakdown by feature, you can dig even deeper to see which segment within each feature of the model is underperforming. In this case, we are filtering on `STATE`=`CA`, we observe `ENTRY_MODE`, which has the highest performance impact, comes to the top.\n",
        "\n",
        "Some of the immediate insights surfaced from the **Feature Performance Tab** are detailed below. \n",
        "1. Worst performing `ENTRY_MODE` includes `credentials_on_file`, followed by `manual`, and `_NULL`\n",
        "2. Worst performing `MERCHANT_TYPE` includes `Religious Organizations`,`Online Food Delivery`, and `Tax Payments`\n",
        "3. Worst performing `MERCHANT_ID` includes `FL`, `CA`, and `NY`\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/perf_tab_entry_mode_filteron_ca.png)\n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/perf_tab_merchant_type_filteron_Ca.png)\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/perf_tab_merchant_id_filteron_ca.png)\n",
        "\n",
        "Moreover, we can compare the overall production dataset to other windows of production. Here, we can investigate what the production dataset looks like in a low performing segment. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/fraud_perftabx2.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX7enXEbYR79"
      },
      "source": [
        "# Step 7. Feature Performance Insights and Data Quality Checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ObKzcnvYR5c"
      },
      "source": [
        "Using the insights gathered from the **Feature Performance Tab**, we can take action to 1) prevent this type of fraud abuse from going undetected in the future and 2) use our findings to improve our model. As noted previously, the slice (feature/value combination) `ENTRY_MODE: credentials_on_file` was one of the worst performing segments for our model. Navigate back to the **Drift** tab and click into the `ENTRY_MODE` feature under the **Feature Drift** section. \n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/entry_mode.gif)\n",
        "\n",
        "Upon first glance, we see that `ENTRY_MODE` is starting to drift around 19th December. By clicking on the high drift region, we noice that our training dataset (Baseline distribution) did not have any `_NULL` values. Clicking on the **Data Quality** tab, we can confirm the cardinality of the feature increased on the 19th and started falling back down 6 days later. \n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/entry_mode_drift.png)\n",
        "\n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/data_quality_check.gif)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aVeTKB5YR2n"
      },
      "source": [
        "# Step 8. Model Performance Overview\n",
        "\n",
        "As we continue to check in and improve our model's performance, we want to be able to quickly and efficiently view all our important model metrics in a single pane. In the same way we set up a **Model Performance Dashboard** to view our model's most important metrics in a single configurable layout. \n",
        "\n",
        "Navigate to the **Templates** section on the left sidebar and scroll down to click on the **Scored Model**. From there select your model, features you care to investigate, and positive class `FRAUD`. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/model_overview_fraud.gif)\n",
        "\n",
        "In addition to the default widgets Arize sets up for your dashboard, you can configure custom metrics your team cares about. In only a few clicks I added a few widgets to give me a single glance view of my model's **Accuracy**, **False Positive Rate**, and **False Negative Rate** as standalone statistics widgets. To visualize these metrics over time I also created a timeseries widget and overlayed three plots showcase the fluctuation of my metrics over time. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/fraud_model_overview.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRCgFg4uYRzj"
      },
      "source": [
        "# Step 9. Business Metrics \n",
        "\n",
        "Sometimes, we need metrics other than traditional statistical measures to define model performance. Business Impact is a way to measure your score model's Payoff at different thresholds (i.e, decision boundary for a score model). The Arize platform allows you to enter custom formulas, mapping model performance to your definition of model performance. Navigate to the **Business Impact** tab to set up a custom formula used to calculate the business impact of our model's performance to the overall profit/loss of your company. For example, the diagram below estimates the profit/loss of a decision made by our model. \n",
        "![image](https://storage.googleapis.com/arize-assets/tutorials/use-cases/bizimpact1.png)\n",
        "\n",
        "Capturing this in our **Business Impact** tab visualizes the profit/loss based on our model's prediction threshold for fraud classification. \n",
        "\n",
        "![image](https://storage.googleapis.com/arize-assets/fixtures/CC_FRAUD/business_metrics.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzMgOCYLYf6D"
      },
      "source": [
        "Visualize the potential profit/loss based on these weighted decision values in Arize's Business Impact tab. Understand your business's overall profit/loss based on your model's prediction threshold for fraud classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jZ9lFAebcpX"
      },
      "source": [
        "# üìö Conclusion \n",
        "In this walkthrough we've shown how Arize can be used to log prediction data for a model, pinpoint model performance degradations, set up monitors to proactively catch future issues, create dashboards for at a glance model understanding, and calculate business impact metrics through custom formulas. \n",
        "\n",
        "We completed the following tasks: \n",
        "1. Uploaded data from a credit card transaction fraud model \n",
        "2. Set up a model baseline (Training V1.0) and managed Performance, Data Quality, and Drift monitors\n",
        "3. Created a Feature Performance Heatmap to surface low performing cohorts impacting our model which helped narrow down our undetected fraudulent transactions to certain `ENTRY_MODE`s and `MERCHANT_TYPE`s coming from a few specific `STATE`s.\n",
        "4. Identified correlations between our model's degrading performance with individual feature drift and distribution variance\n",
        "5. Created a model Performance Dashboard to visualize important metrics at a glance with custom timeseries metrics for ongoing analysis \n",
        "6. Captured our potential profit/loss based on our model's classification threshold using the Business Impact tab\n",
        "\n",
        "We identified the following areas of concern: \n",
        "1. `_NULL` values for the feature `ENTRY_MODE`. This leads us to believe that we need to upsample this type of feature/value combination or fix an upstream datasource to omit this undetermined value. \n",
        "2. Suspicious activity coming from `MERCHANT_TYPE`: `Online Food Delivery`, `Religious Organizations`, `Pawn Shops and Salvage Yards`, `Automotive Tire Sotres`, and  `Tax Payments`, `ENTRY_MODE` : `credential_on_file` and `manual`. Specifically we noticed drift of these categories fluctuating on certain dates and coming from a small subset of `STATES`, namely `CA`, and `NY`. We must look into the POS systems across these states to understand what type of organized fraud is happening from these regions while retraining our model to detect anomalous food delivery and erroneous tax payment transactions. \n",
        "3. We also noticed that our model performs poorly on certain `MERCHANT_ID`s when filtered on `STATES`, namely `CA`, and `NY`. Perhaps a new model strategy is needed to form stronger inferences. \n",
        "\n",
        "Though we covered a lot of ground, this is just scratching the surface of what the Arize platform can do. We urge you to explore more of Arize, either on your own or through one of our many other tutorials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es52tD8lbceL"
      },
      "source": [
        "# About Arize\n",
        "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
        "- Automated ML monitoring and model monitoring\n",
        "- Workflows to troubleshoot model performance\n",
        "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
        "- Model prediction cohort analysis\n",
        "- Pre-deployment model validation\n",
        "- Integrated model explainability\n",
        "\n",
        "### Website\n",
        "Visit Us At: https://arize.com/model-monitoring/\n",
        "\n",
        "### Additional Resources\n",
        "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
        "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
        "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
        "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
        "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
        "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
        "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
        "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
        "\n",
        "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Credit Card Fraud Use Case.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ec6620dbdb1ae7ae605320a7ce7472136ac4f41aa18fe452eefaab7683971943"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit (conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

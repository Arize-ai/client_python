{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANZZFeZjIQy_"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"200\"/>\n",
        "\n",
        "# Getting Started with the Arize Platform - Predicting Claims in Insurance\n",
        "\n",
        "**In this walkthrough, we are going to investigate various performance related aspects of an insurance use-case. More specificlly we will be using the Arize platform to monitor claim prediction performance.**\n",
        "\n",
        "You manage the Machine Learning models for an insurance company. You have spent a great deal of your time collecting data and traning models for best performance. With your models now in production you need tools to detect drift, identify any issues or get insights into how to improve your models. In this walkthrough we will look at a few scenarios common to an insurance use-case and more specifically looking at claims probability predictions versus actuals for a block of general liability insurance covering small businesses.\n",
        "\n",
        "You will learn to:\n",
        "\n",
        "1. Get training and production data into the Arize platform\n",
        "2. Setup performance dashboards\n",
        "3. Setup threshold alerts\n",
        "4. Understand where the model is underperforming\n",
        "5. Discover the root cause of issues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45qJcDSiKrAf"
      },
      "source": [
        "# Step 1. Getting the Data\n",
        "First step is to load a preexisting dataset that represents a insurance use-case including training and production data. Using a preexisting dataset illustrates how simple it is to plug into the Arize platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yuj4lOn3VLVs",
        "outputId": "017fedd2-d865-4426-ca5d-11f37543b6c5"
      },
      "outputs": [],
      "source": [
        "!pip install -q arize\n",
        "\n",
        "import pandas as pd\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import Environments, ModelTypes\n",
        "\n",
        "url = \"https://storage.googleapis.com/arize-assets/fixtures/use_cases/insurance\"\n",
        "df = {env: pd.read_csv(f\"{url}/{env}.zip\") for env in [\"feat\", \"train\", \"prod\"]}\n",
        "feature_column_names = df[\"feat\"][\"Feature\"].tolist()\n",
        "\n",
        "# Update prediction timestamps\n",
        "from datetime import datetime\n",
        "\n",
        "ts_shift = datetime.now().timestamp() - df[\"prod\"][\"prediction_ts\"].max()\n",
        "df[\"prod\"].eval(\"prediction_ts = prediction_ts + @ts_shift\", inplace=True)\n",
        "\n",
        "print(\"‚úÖ Data successfully loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect the Data \n",
        "\n",
        "Take a quick look at the dataset. The data represents a model designed and trained to evaluate the probability that a user will file an insurance claim. The dataset contains one month of data and the performance will be evaluated by comparing:\n",
        "\n",
        "*   **PREDICTION**: The probability of a fraud transaction predicted by the model \n",
        "*   **ACTUAL**: Fraud or not fraud based on ground truth collected by credit card users\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"train\"][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMjE6vwOOKS-"
      },
      "source": [
        "# Step 2. Sending Data into Arize üí´\n",
        "\n",
        "Now that we have our data configured, we are ready to integrate into Arize. We do this by logging (sending) important data we want to analyze to the platform. There, the data will be easily visualized and investigated to source our problem.\n",
        "\n",
        "For our model, we are going to log:\n",
        "\n",
        "*   feature data\n",
        "*   predictions\n",
        "*   actuals\n",
        "\n",
        "## Import and Setup Arize Client\n",
        "\n",
        "The first step is to setup our Arize client. After that we will log the data.\n",
        "\n",
        "First, copy the Arize `API_KEY` and `SPACE_KEY` from your admin page shown below! Copy those over to the set-up section. We will also be setting up some metadata to use across all logging.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptEmVNV3Poyy",
        "outputId": "5988dcdb-5275-4a6e-f4f9-58d98bde436e"
      },
      "outputs": [],
      "source": [
        "SPACE_KEY = \"SPACE_KEY\"\n",
        "API_KEY = \"API_KEY\"\n",
        "\n",
        "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
        "\n",
        "# model_id the model name that will show up in Arize\n",
        "model_id = \"insurance-use-case\"\n",
        "model_version = \"v1.0\"  # Version of model - can be any string\n",
        "\n",
        "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else:\n",
        "    print(\"‚úÖ Arize setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GeHqNxm4tuk"
      },
      "source": [
        "## Log Training & Production Data\n",
        "Now that our Arize client is setup, let's go ahead and log all of our data to the platform. \n",
        "\n",
        "Arize lets you log predictions first and actuals later, and will match them up by the same `prediction_id` when both are ready. But for the purpose of this demo, we'll log predictions and actual together.\n",
        "\n",
        "For details on how **`arize.pandas.logger`** can log predictions and actuals separately, visit out documentations page below.\n",
        "\n",
        "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)\n",
        "\n",
        "Key parameters:\n",
        "\n",
        "| Schema Argument Name | Description | \n",
        "| --- | --- |\n",
        "| prediction_id_column_name| list of unique ids you can use to use to match each record \n",
        "| timestamp_column_name| timestamps for when predictions were made \n",
        "| prediction_label_column_name| tells Arize which column contains the predictions (\"Filed a Claim\"/\"No Claims\")\n",
        "| prediction_score_column_name| tells Arize which column contains the predicted probability that a user \"Filed a Claim\" (probability 0 to 1 where 1 = \"Filed a Claim\")\n",
        "| actual_label_column_name| tells Arize which column contains the actual results from field data (\"Filed a Claim\"/\"No Claims\")\n",
        "| actual_score_column_name | same as the actual label but expresed as 0 or 1\n",
        "| feature_column_names| names of the columns representing features \n",
        "\n",
        "\n",
        "We will use [ModelTypes.SCORE_CATEGORICAL](https://docs.arize.com/arize/product-guides-1/models/model-types) to log our model into Arize. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udfVckHQ2egV",
        "outputId": "a6c7d0f5-e63f-4968-c009-9bfbfc8f44d0"
      },
      "outputs": [],
      "source": [
        "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
        "schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",\n",
        "    prediction_label_column_name=\"prediction_label\",\n",
        "    prediction_score_column_name=\"prediction_score\",\n",
        "    actual_label_column_name=\"actual_label\",\n",
        "    actual_score_column_name=\"actual_score\",\n",
        "    feature_column_names=feature_column_names,\n",
        ")\n",
        "\n",
        "# Log Pandas DataFrame\n",
        "response = arize_client.log(\n",
        "    dataframe=df[\"train\"],\n",
        "    schema=schema,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
        "    environment=Environments.TRAINING,\n",
        ")\n",
        "\n",
        "# If successful, the server will return a status_code of 200\n",
        "if response.status_code != 200:\n",
        "    print(f\"logging failed with response code {response.status_code}, {response.text}\")\n",
        "else:\n",
        "    print(\n",
        "        f\"‚úÖ You have successfully logged {len(df['train']):,} training data points to Arize\"\n",
        "    )\n",
        "\n",
        "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
        "schema = Schema(\n",
        "    prediction_id_column_name=\"prediction_id\",\n",
        "    timestamp_column_name=\"prediction_ts\",\n",
        "    prediction_label_column_name=\"prediction_label\",\n",
        "    prediction_score_column_name=\"prediction_score\",\n",
        "    actual_label_column_name=\"actual_label\",\n",
        "    actual_score_column_name=\"actual_score\",\n",
        "    feature_column_names=feature_column_names,\n",
        ")\n",
        "\n",
        "# Log Pandas DataFrame\n",
        "response = arize_client.log(\n",
        "    dataframe=df[\"prod\"],\n",
        "    schema=schema,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    model_type=ModelTypes.SCORE_CATEGORICAL,\n",
        "    environment=Environments.PRODUCTION,\n",
        ")\n",
        "\n",
        "# If successful, the server will return a status_code of 200\n",
        "if response.status_code != 200:\n",
        "    print(f\"logging failed with response code {response.status_code}, {response.text}\")\n",
        "else:\n",
        "    print(\n",
        "        f\"‚úÖ You have successfully logged {len(df['prod']):,} production data points to Arize\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqWVSsS_loeL"
      },
      "source": [
        "# Coffee Time! ‚òïÔ∏è\n",
        "Note that the Arize performs takes about 10 minutes to index the data. While the model should appear immediately, the data will not show up untill the indexing is done. Feel free to go grab a cup of coffee as Arize works its magic! üîÆ\n",
        "\n",
        "**‚ö†Ô∏è DON'T SKIP:**\n",
        "In order to move on to the next step, make sure your actuals and training/validation sets are loaded into the platform. To check:\n",
        "1. Naviate to models from the left bar, locate and click on model **insurance-use-case**\n",
        "2. On the **Overview Tab** and make sure you see the actuals as shown below.\n",
        "3. Actual data will show up under **Model Health**. Once the number changes from **0 Actuals** to **Actuals** (with summary statistics such as cardinality listed in the tables), your production actuals will have been fully recorded on Arize!\n",
        "4. Verify the list of features under **Model Health**. \n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/use_cases/insurance/img/initial_overview.png\" width=\"800\"/>\n",
        "\n",
        "Arize can automatically configure monitors that are best suited to your data. From the banner at the top of the screen, simply click **Set up Model** then select **Training Version v1.0** and click **NEXT**. Select **Filed a Claim** as **Positive Class**. Click **NEXT** three more times with Arize's default recommended settings.\n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/use_cases/img/initial_setup_banner.png)\n",
        "\n",
        "You will now see that the baseline has been set and **Drift**, **Data Quality**, and **Performance** monitors have been created!!!\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/use_cases/insurance/img/initial_setup_monitors.png\" width=\"300\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHWdqQE4io-E"
      },
      "source": [
        "# Step 3. Analyzing feature drift\n",
        "During intial model setup, Arize automatically calculates drift (and sets up drift monitors) for each feature available in your dataset. Drift is defaulted to a statistical measure of Population Stability Index (PSI) over a given period. We will use these graphs to monitor overall trends. From the model overview page, select the **MSADSCR** feature and you should notice the change in MSA distribution. Use the PSI graph to select a period of interest. We see that Los Angeles and Dallas have been gaining more businesses than they had in the training dataset.\n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/use_cases/insurance/img/MSA_Drift.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYb5i_zQErxT"
      },
      "source": [
        "# Step 4. Analyzing and detecting missing data\n",
        "In the production data, you might have already noticed some drift on the **experienced_business** feature. To further investigate, from the **experienced_business** feature page, navigate to the **Data Quality** tab. Here we notice missing values are being introduced in the **experienced_business** feature using the Percent Empty graph. Make sure to view the last 30 days by selecting the correct range in the top right corner of the screen. Arize keeps tracks of feature cardinality and empty/missing values over time to help pin-point when the issue started.\n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/use_cases/insurance/img/Percent_Empty.png)\n",
        "\n",
        "To automatically be notified of missing values getting introduced in production, create a custom monitor for feature **experienced_business**. From the model **Monitors** tab click **New Monitor** and chose **Data Quality Monitor**. Enter these parameters:\n",
        "\n",
        "* Dimension -> Feature --> experienced_business\n",
        "* Aggregation -> Percent Empty\n",
        "* Set a low threshold\n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/use_cases/insurance/img/Percent_Empty_Monitor.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT2jfrjCCB7p"
      },
      "source": [
        "\n",
        "**Congratulations!** üéâ   You have created your first monitor that will keep you alerted of any changes in your production environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKvYu2Pja173"
      },
      "source": [
        "# Step 6. Analyzing model performance\n",
        "The screen capture below shows how to set up a **Model Performance Dashboard** to monitor the expected vs actual probability of filing a claim.\n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/use_cases/insurance/img/perfdash.gif)\n",
        "\n",
        "The screen capture below shows how to set up a **Feature Performance Dashboard** to drill down into root causes of model underperformance.\n",
        "\n",
        "![image.png](https://storage.googleapis.com/arize-assets/fixtures/use_cases/insurance/img/heatdash.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPpV4OgVXhCZ"
      },
      "source": [
        "---\n",
        "# Conclusion\n",
        "\n",
        "In this walkthrough we've shown how Arize can be used to log prediction data for a model, pinpoint model performance degredation, and set up monitors to catch future issues. We have been able to identify 3 areas of concern:\n",
        "\n",
        "1. Production distribution has drifted from training data.\n",
        "2. Missing values are appearing in production. Further investigation is needed.\n",
        "3. The model is underperforming in certain segments. Retraining may be needed.\n",
        "\n",
        "Summary of the analysis and tools:\n",
        "\n",
        "Concern                   | Detection                       | Root Cause Analysis Tools\n",
        "--------------------------|---------------------------------|----\n",
        "Data Drift  | Use a **Drift Monitor**             | - Built-in distribution graphs on each feature<br>- Review distribution at different time intervals\n",
        "Bad  data            | Use a **Data Quality Monitor**      | - Built-in cardinality graphs<br>- Built-in Empty over Time graph<br>- Create Data Quality Monitors\n",
        "Inaccuracy                | Use a **Model Performance Monitor**<br>Use a **Feature Performance Heatmap** | - Actual vs Expected timeseries widget<br>- Filter on features and values to narrow down issues\n",
        "\n",
        "<br>\n",
        "\n",
        "Though we covered a lot of ground, this is just scratching the surface of what the Arize platform can do. We urge you to explore more of Arize, either on your own or through one of our many other tutorials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RgPKS9qG2ehZ"
      },
      "source": [
        "### About Arize\n",
        "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
        "- Automated ML monitoring and model monitoring\n",
        "- Workflows to troubleshoot model performance\n",
        "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
        "- Model prediction cohort analysis\n",
        "- Pre-deployment model validation\n",
        "- Integrated model explainability\n",
        "\n",
        "### Website\n",
        "Visit Us At: https://arize.com/model-monitoring/\n",
        "\n",
        "### Additional Resources\n",
        "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
        "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
        "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
        "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
        "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
        "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
        "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
        "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
        "\n",
        "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Insurance.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

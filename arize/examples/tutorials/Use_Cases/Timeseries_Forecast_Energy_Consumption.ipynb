{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Timeseries Forecast - Energy Consumption.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install arize[MimicExplainer] -q"
      ],
      "metadata": {
        "id": "Um_nh7X29Tac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timeseries Forecasting\n",
        "In this example, we are showing how timeseries forecasting data can be observed in the Arize platform by leveraging a Lag (delta between \"run date\" which indicated the day which the inference was made ***on*** and \"prediction timestamp\" which indicates when the prediction was made ***for***.\n",
        "\n",
        "This example is predicting therms to be generated each day for the next 14 days based on expected temperatures on western cities and renewable energy source outputs. Sales Forecasts, Product Demand, etc. can all be ingested in a similar fashion."
      ],
      "metadata": {
        "id": "g2j_mhIvDVn3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wDM6qKHKk9IJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from datetime import datetime, date, timezone\n",
        "from pandas.core.frame import DataFrame\n",
        "\n",
        "from arize.pandas.logger import Client, Schema\n",
        "from arize.utils.types import ModelTypes, Environments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Arize client\n",
        "SPACE_KEY = \"SPACE_KEY\"\n",
        "API_KEY = \"API_KEY\"\n",
        "RECEIVER_URI = \"https://api.arize.com/v1\"\n",
        "\n",
        "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"‚ùå NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "\n",
        "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY, uri=RECEIVER_URI)"
      ],
      "metadata": {
        "id": "GyvQHNwzzBn2"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction IDs need to be unique, even in the case where a prediction is for the same day, so actuals can be joined against the correct target. A hermetic way to accomplish this is by concatnating the run_date and the prediction_date.\n",
        "\n",
        "---\n",
        "### For the sake of this example, we are manipulating timestamps position them to coeincide with the time someone run this notebook - for convinience purposes only."
      ],
      "metadata": {
        "id": "FsSbHTKqFbBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def prep_data(df: DataFrame):\n",
        "  # We'll shift timestamps so the last \"run\" of the prediction timeline occurs today\n",
        "  days_to_shift = (datetime.today() - datetime.strptime(df['run_date'].max(), \"%Y-%m-%d\")).days\n",
        "  df['run_date'] = (pd.to_datetime(df['run_date']) + pd.DateOffset(days=days_to_shift)).dt.strftime('%Y-%m-%d')\n",
        "  \n",
        "  # Prediction dates are also shifted in this example to line up with our model use case which \n",
        "  # predicts the next 14 days of energy use\n",
        "  df['prediction_timestamp'] = df['prediction_timestamp'] + (days_to_shift * 24 * 60 * 60)\n",
        "  df['Date'] = pd.to_datetime(df['prediction_timestamp'], unit='s').astype(str)\n",
        "\n",
        "  # We now need to generate an unique prediction ID - since we are making predictions for the same \n",
        "  # date multiple days leading up to the forecast date, the prediction id\n",
        "  # is a compound key with Date the model ran and date which the model is forecasting for\n",
        "  df['prediction_id'] = df['run_date'] + \"_\" + df['Date']\n",
        "  \n",
        "  # Since we have some data which only have predictions and no actuals (predictions made for future dates)\n",
        "  # mixed with data that contains both predictions and actuals, we'll split them into a historical and a forecast set\n",
        "  historical_data = df[df[\"reported_thermal\"].notnull()]\n",
        "  forecast_data = df[df[\"reported_thermal\"].isnull()]\n",
        "  return historical_data, forecast_data"
      ],
      "metadata": {
        "id": "C3GbmaoXTmN7"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we can send the data in."
      ],
      "metadata": {
        "id": "WKbNgG88G2Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet('https://storage.googleapis.com/arize-assets/tutorials/fixture_data/timeseries_energy_consumption_example.parquet.out')\n",
        "\n",
        "# First we prep the data, then we'll send over to Arize for visualizations.\n",
        "historical_data, forecast_data = prep_data(df)\n",
        "\n",
        "# We'll list out feature columns for convenience\n",
        "features = df.drop(columns=[\"Date\",\"run_date\",\"prediction_id\",\"prediction_timestamp\",\n",
        "                            \"predicted_thermal\",\"reported_thermal\",\"lag\"]).columns.to_list()\n",
        "\n",
        "MODEL_ID = \"Timeseries-Forecast-Model-5\"\n",
        "MODEL_VERSION = \"1.0\"\n",
        "\n",
        "# First send just the historical data (data which we already have actuals for)\n",
        "historical_response = arize_client.log(\n",
        "    dataframe=historical_data,\n",
        "    model_id=MODEL_ID,\n",
        "    model_version=MODEL_VERSION,\n",
        "    model_type=ModelTypes.NUMERIC,\n",
        "    environment=Environments.PRODUCTION,\n",
        "    schema=Schema(prediction_id_column_name=\"prediction_id\",\n",
        "                  feature_column_names=features,\n",
        "                  timestamp_column_name=\"prediction_timestamp\",\n",
        "                  prediction_label_column_name=\"predicted_thermal\",\n",
        "                  actual_label_column_name=\"reported_thermal\",\n",
        "                  tag_column_names=[\n",
        "                                    \"run_date\", # date which the inference was made on\n",
        "                                    \"lag\" # number of days between run_date and prediction_timestamp\n",
        "                                    ],\n",
        "\n",
        "    ),\n",
        "    # Since we don't have pre-calculated Shap Values, we can enable Surrugate\n",
        "    # Explainability to get SHAP values for our features\n",
        "    surrogate_explainability=True,\n",
        ")\n",
        "\n",
        "# Next send forecast data, notice we removed the actual_label_column_name\n",
        "# argument from the Schema definition\n",
        "forecast_response = arize_client.log(\n",
        "    dataframe=forecast_data,\n",
        "    model_id=MODEL_ID,\n",
        "    model_version=MODEL_VERSION,\n",
        "    model_type=ModelTypes.NUMERIC,\n",
        "    environment=Environments.PRODUCTION,\n",
        "    schema=Schema(prediction_id_column_name=\"prediction_id\",\n",
        "                  feature_column_names=features,\n",
        "                  timestamp_column_name=\"prediction_timestamp\",\n",
        "                  prediction_label_column_name=\"predicted_thermal\",\n",
        "                  tag_column_names=[\n",
        "                                    \"run_date\", # date which the inference was made on\n",
        "                                    \"lag\" # number of days between run_date and prediction_timestamp\n",
        "                                    ],\n",
        "\n",
        "    ),\n",
        "    surrogate_explainability=True,\n",
        ")"
      ],
      "metadata": {
        "id": "xF5e11a2ABA8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
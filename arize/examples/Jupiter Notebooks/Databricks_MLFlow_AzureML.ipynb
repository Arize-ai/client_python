{"cells":[{"cell_type":"markdown","source":["## Arize AI Quick Start: Training and Serving Models with Microsoft Azure ML\n\n##### NOTE: We do not recommend using *Run All* because it takes several minutes to deploy and update models; models cannot be queried until they are active.\n\nThis part of the guide consists of the following sections:\n\n#### Setup\n* Launch an Azure Databricks cluster\n* Install Arize SDK\n* Install MLflow\n* Install the Azure ML SDK\n* Create or load an Azure ML Workspace\n\n\n#### Training a Model\n* Use MLflow Tracking to track experiment\n\n#### Building an Azure Container Image for model deployment\n* Use MLflow to build a Container Image for the trained model\n\n#### Deploy the model to expose a consumable API using Azure Container Instances (ACI)\n* Create an ACI webservice deployment using the model's Container Image\n\n#### Querying the deployed model in ACI\n* Load a sample input vector from the diabetes dataset\n* Evaluate the sample input vector by sending an HTTP request\n\n#### Publishing prediction results to Arize\n* Log resulting prediction output along with input vector using Arize's SDK \n\n#### Alternatively, if using Kubernetes: Deploy the model using Azure Kubernetes Service (AKS)\n* Option 1: Create a new AKS cluster\n* Option 2: Connect to an existing AKS cluster\n* Deploy to the model's image to the specified AKS cluster\n\n#### Querying the deployed model in AKS\n* Load a sample input vector from the wine dataset\n* Evaluate the sample input vector by sending an HTTP request\n\n#### Updating the AKS deployment\n* Build an Azure Container Image for another model\n* Deploy the new model's image to the AKS cluster\n* Query the updated model\n\n#### Cleaning up the deployments\n* Terminate the ACI webservice\n* Terminate the AKS webservice\n* Remove the AKS cluster from the Azure ML Workspace\n\nThis notebook uses the `diabetes` dataset in scikit-learn and predicts the progression metric (a quantitative measure of disease progression after one year after) based on BMI, blood pressure, etc. It uses the scikit-learn ElasticNet linear regression model, where we vary the `alpha` and `l1_ratio` parameters for tuning. For more information on ElasticNet, refer to:\n  * [Elastic net regularization](https://en.wikipedia.org/wiki/Elastic_net_regularization)\n  * [Regularization and Variable Selection via the Elastic Net](https://web.stanford.edu/~hastie/TALKS/enet_talk.pdf)"],"metadata":{}},{"cell_type":"markdown","source":["**Note:** This notebook expects that you use a Databricks hosted MLflow tracking server. If you would like to preview the Databricks MLflow tracking server, contact your Databricks sales representative to request access. To set up your own tracking server, see the instructions in [MLflow Tracking Servers](https://www.mlflow.org/docs/latest/tracking.html#mlflow-tracking-servers) and configure your connection to your tracking server by running [mlflow.set_tracking_uri](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_tracking_uri)."],"metadata":{}},{"cell_type":"markdown","source":["## Setup"],"metadata":{}},{"cell_type":"markdown","source":["1. Ensure you are using or create a cluster specifying \n  * **Databricks Runtime Version:** Databricks Runtime 5.0 or above \n  * **Python Version:** Python > 3.5.3\n1. Install required libraries or if using Databricks Runtime 5.1 or above, run Cmd 5.\n   1. Create required libraries.\n    * Source **PyPI** and enter `arize`.\n    * Source **PyPI** and enter `mlflow[extras]`. This installs mlflow and all its dependencies.\n    * Source **PyPI** and enter `azureml-sdk[databricks]`.\n   1. Install the libraries into the cluster.\n1. Attach this notebook to the cluster."],"metadata":{}},{"cell_type":"code","source":["!pip install arize mlflow[extras] azureml-sdk[databricks]"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["#### Write Your ML Code Based on the`train_diabetes.py` Code\nThis tutorial is based on the MLflow's [train_diabetes.py](https://github.com/mlflow/mlflow/blob/master/examples/sklearn_elasticnet_diabetes/train_diabetes.py) example, which uses the `sklearn.diabetes` built-in dataset to predict disease progression based on various factors."],"metadata":{}},{"cell_type":"code","source":["# Import various libraries including matplotlib, sklearn, mlflow\nimport os\nimport warnings\nimport sys\n\nimport pandas as pd\nimport numpy as np\nfrom itertools import cycle\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import lasso_path, enet_path\nfrom sklearn import datasets\n\n# Import mlflow\nimport mlflow\nimport mlflow.sklearn\n\n# Load Diabetes datasets\ndiabetes = datasets.load_diabetes()\nX = diabetes.data\ny = diabetes.target\n\n# Create pandas DataFrame for sklearn ElasticNet linear_model\nY = np.array([y]).transpose()\nd = np.concatenate((X, Y), axis=1)\ncols = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'progression']\ndata = pd.DataFrame(d, columns=cols)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["#### Train the Diabetes Model\nThe next function trains ElasticNet linear regression based on the input parameters of `alpha (in_alpha)` and `l1_ratio (in_l1_ratio)`.\n\nIn addition, this function uses MLflow Tracking to record its\n* parameters\n* metrics\n* model\n\n**Tip:** Use `with mlflow.start_run:` in the Python code to create a new MLflow run. This is the recommended way to use MLflow in notebook cells. Whether your code completes or exits with an error, the `with` context will make sure to close the MLflow run, so you don't have to call `mlflow.end_run`."],"metadata":{}},{"cell_type":"code","source":["# train_diabetes\n#   Uses the sklearn Diabetes dataset to predict diabetes progression using ElasticNet\n#       The predicted \"progression\" column is a quantitative measure of disease progression one year after baseline\n#       http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\ndef train_diabetes(data, in_alpha, in_l1_ratio):\n  # Evaluate metrics\n  def eval_metrics(actual, pred):\n      rmse = np.sqrt(mean_squared_error(actual, pred))\n      mae = mean_absolute_error(actual, pred)\n      r2 = r2_score(actual, pred)\n      return rmse, mae, r2\n\n  warnings.filterwarnings(\"ignore\")\n  np.random.seed(40)\n\n  # Split the data into training and test sets. (0.75, 0.25) split.\n  train, test = train_test_split(data)\n\n  # The predicted column is \"progression\" which is a quantitative measure of disease progression one year after baseline\n  train_x = train.drop([\"progression\"], axis=1)\n  test_x = test.drop([\"progression\"], axis=1)\n  train_y = train[[\"progression\"]]\n  test_y = test[[\"progression\"]]\n\n  if float(in_alpha) is None:\n    alpha = 0.05\n  else:\n    alpha = float(in_alpha)\n    \n  if float(in_l1_ratio) is None:\n    l1_ratio = 0.05\n  else:\n    l1_ratio = float(in_l1_ratio)\n  \n  # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n  with mlflow.start_run():\n    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n    lr.fit(train_x, train_y)\n\n    predicted_qualities = lr.predict(test_x)\n\n    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\n    # Print out ElasticNet model metrics\n    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n    print(\"  RMSE: %s\" % rmse)\n    print(\"  MAE: %s\" % mae)\n    print(\"  R2: %s\" % r2)\n\n    # Set tracking_URI first and then reset it back to not specifying port\n    # Note, we had specified this in an earlier cell\n    #mlflow.set_tracking_uri(mlflow_tracking_URI)\n\n    # Log mlflow attributes for mlflow UI\n    mlflow.log_param(\"alpha\", alpha)\n    mlflow.log_param(\"l1_ratio\", l1_ratio)\n    mlflow.log_metric(\"rmse\", rmse)\n    mlflow.log_metric(\"r2\", r2)\n    mlflow.log_metric(\"mae\", mae)\n    mlflow.sklearn.log_model(lr, \"model\")\n    modelpath = \"/dbfs/mlflow/test_diabetes/model-%f-%f\" % (alpha, l1_ratio)\n    mlflow.sklearn.save_model(lr, modelpath)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["#### Experiment with Different Parameters\n\nCall `train_diabetes` with different parameters. Later, you'll be able to visualize all these runs in the MLflow experiment."],"metadata":{}},{"cell_type":"code","source":["%fs rm -r dbfs:/mlflow/test_diabetes"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# alpha and l1_ratio values of 0.01, 0.01\ntrain_diabetes(data, 0.01, 0.01)\n\n# alpha and l1_ratio values of 0.01, 0.75\ntrain_diabetes(data, 0.01, 0.75)\n\n# alpha and l1_ratio values of 0.01, .5\ntrain_diabetes(data, 0.01, .5)\n\n# alpha and l1_ratio values of 0.01, 1\ntrain_diabetes(data, 0.01, 1)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## View the run, experiment, run details, and notebook revision\n\n1. Click the **Runs** icon in the notebook context bar to display the Runs sidebar. In the sidebar, you can view the run parameters and metrics. For example: <img src=\"https://docs.databricks.com/_static/images/mlflow/mlflow-notebook-experiments.gif\"/>\n   \n1. Click the External Link icon <img src=\"https://docs.databricks.com/_static/images/external-link.png\"/> in the Runs context bar to view the notebook experiment. For example: <img src=\"https://docs.databricks.com/_static/images/mlflow/quick-start-nb-experiment.png\"/>"],"metadata":{}},{"cell_type":"markdown","source":["### Create or load an Azure ML Workspace"],"metadata":{}},{"cell_type":"markdown","source":["Before models can be deployed to Azure ML, you must create or obtain an Azure ML Workspace. The `azureml.core.Workspace.create()` function will load a workspace of a specified name or create one if it does not already exist. For more information about creating an Azure ML Workspace, see the [Azure ML Workspace management documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-workspace)."],"metadata":{}},{"cell_type":"code","source":["import azureml\nfrom azureml.core import Workspace\n\nworkspace_name = \"Test_MLflow\"\nworkspace_location=\"westus2\"\nresource_group = \"Test_MLflow\"\nsubscription_id = \"d44ffbaa-b9ad-45e1-9841-8835ec6bd7e1\"\n\nworkspace = Workspace.create(name = workspace_name,\n                             location = workspace_location,\n                             resource_group = resource_group,\n                             subscription_id = subscription_id,\n                             exist_ok=True)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## Build an Azure Container Image for model deployment"],"metadata":{}},{"cell_type":"markdown","source":["### Use MLflow to build a Container Image for the trained model\n\nUse the `mlflow.azuereml.build_image` function to build an Azure Container Image for the trained MLflow model. This function also registers the MLflow model with a specified Azure ML workspace. The resulting image can be deployed to Azure Container Instances (ACI) or Azure Kubernetes Service (AKS) for real-time serving."],"metadata":{}},{"cell_type":"markdown","source":["Specify the run ID associated with an ElasticNet training run from. You can find a run ID and model path from the experiment run, which can be found on the run details page:\n\n![image](https://docs.azuredatabricks.net/_static/images/mlflow/mlflow-deployment-example-run-info.png)"],"metadata":{}},{"cell_type":"code","source":["run_id1 = \"2cdc865cd53a420cb12036ea08c62083\"\nmodel_uri = \"runs:/\" + run_id1 + \"/model\""],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["import mlflow.azureml\n\nmodel_image, azure_model = mlflow.azureml.build_image(model_uri=model_uri, \n                                                      workspace=workspace,\n                                                      model_name=\"model\",\n                                                      image_name=\"model\",\n                                                      description=\"Sklearn ElasticNet image for predicting diabetes progression\",\n                                                      synchronous=False)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["model_image.wait_for_creation(show_output=True)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["## Deploy the model to expose a consumable API using [Azure Container Instances (ACI)](https://docs.microsoft.com/en-us/azure/container-instances/)\n\nUsing the Azure ML SDK, deploy the Container Image for the trained MLflow model to ACI."],"metadata":{}},{"cell_type":"code","source":["from azureml.core.webservice import AciWebservice, Webservice\n\ndev_webservice_name = \"diabetes-model\"\ndev_webservice_deployment_config = AciWebservice.deploy_configuration()\ndev_webservice = Webservice.deploy_from_image(name=dev_webservice_name, image=model_image, deployment_config=dev_webservice_deployment_config, workspace=workspace)\n\ndev_webservice.wait_for_deployment()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["## Query the deployed model in AzureML"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nfrom sklearn import datasets\n\n#### Load diabetes dataset\ndiabetes = datasets.load_diabetes()\n\n#### Create sample input vector\nX = diabetes.data\ny = diabetes.target\nY = np.array([y]).transpose()\nd = np.concatenate((X, Y), axis=1)\ncols = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'progression']\ndata = pd.DataFrame(d, columns=cols)\nsample = data.drop([\"progression\"], axis=1).iloc[[0]]\n                                                 \nquery_input = sample.to_json(orient='split')\nquery_input = eval(query_input)\nquery_input.pop('index', None)\n\n#print(query_input)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["#### Evaluate the sample input vector by sending an HTTP request\nQuery the ACI webservice's scoring endpoint by sending an HTTP POST request that contains the input vector."],"metadata":{}},{"cell_type":"code","source":["import requests\nimport json\nimport uuid \n  \ndef query_endpoint_example(scoring_uri, inputs, service_key=None):\n  headers = {\n    \"Content-Type\": \"application/json\",\n  }\n  if service_key is not None:\n    headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=service_key)\n    \n  print(\"Sending batch prediction request with inputs: {}\".format(inputs))\n  response = requests.post(scoring_uri, data=json.dumps(inputs), headers=headers)\n  preds = json.loads(response.text)\n  print(\"Received response: {}\".format(preds))\n  return preds"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["dev_webservice.scoring_uri\nmodel_id='diabetes-model'\nmodel_version='2cdc865cd53a420cb12036ea08c62083'"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["### Arize Helper Utility\ndef construct_label_map(inputs):\n  keys = inputs['columns']\n  values = inputs['data'][0]\n  print(f'keys: {keys}')\n  print(f'values: {values}')\n  labels = {}\n  for i, key in enumerate(keys):\n    labels[key] = str(values[i])\n  return labels\n"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["from arize.api import Client as client\n","\n","## Instantiate arize client\n","arize = client(account_id=1, api_key='87sYFKXK9p6YeYXfazZr', uri='https://dev.arize.com/v1/log')\n","\n","dev_prediction = query_endpoint_example(scoring_uri=dev_webservice.scoring_uri, inputs=query_input)\n","\n","prediction_id=str(uuid.uuid4())\n","\n","print(\"Logging prediction to arize: {}\".format(prediction_id))\n","arize.log(\n","    model_id=model_id,\n","    model_version=model_version,\n","    prediction_id=prediction_id,\n","    prediction_value=dev_prediction[0],\n","    labels=construct_label_map(query_input),\n","    )"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["## Alternatively, if using Kubernetes: Deploy the model using [Azure Kubernetes Service (AKS)](https://azure.microsoft.com/en-us/services/kubernetes-service/). (Do Option 1 or Option 2)"],"metadata":{}},{"cell_type":"markdown","source":["### Option 1: Create a new AKS cluster\n\nIf you do not have an active AKS cluster for model deployment, create one using the Azure ML SDK."],"metadata":{}},{"cell_type":"code","source":["from azureml.core.compute import AksCompute, ComputeTarget\n\n# Use the default configuration (you can also provide parameters to customize this)\nprov_config = AksCompute.provisioning_configuration(vm_size='Standard_D16_v3')\n\naks_cluster_name = \"diabetes-cluster\" \n# Create the cluster\naks_target = ComputeTarget.create(workspace = workspace, \n                                  name = aks_cluster_name, \n                                  provisioning_configuration = prov_config)\n\n# Wait for the create process to complete\naks_target.wait_for_completion(show_output = True)\nprint(aks_target.provisioning_state)\nprint(aks_target.provisioning_errors)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":["### Option 2: Connect to an existing AKS cluster\n\nIf you already have an active AKS cluster running, you can add it to your Workspace using the Azure ML SDK."],"metadata":{}},{"cell_type":"code","source":["from azureml.core.compute import AksCompute, ComputeTarget\n\n# Get the resource group from https://porta..azure.com -> Find your resource group\nresource_group = \"<resource-group>\"\n\n# Give the cluster a local name\naks_cluster_name = \"diabetes-cluster\"\n\n# Attatch the cluster to your workgroup\nattach_config = AksCompute.attach_configuration(resource_group=resource_group, cluster_name=aks_cluster_name)\naks_target = ComputeTarget.attach(workspace, name=\"diabetes-compute\", attach_config)\n\n# Wait for the operation to complete\naks_target.wait_for_completion(True)\nprint(aks_target.provisioning_state)\nprint(aks_target.provisioning_errors)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":["### Deploy to the model's image to the specified AKS cluster"],"metadata":{}},{"cell_type":"code","source":["from azureml.core.webservice import Webservice, AksWebservice\n\n# Set configuration and service name\nprod_webservice_name = \"diabetes-model-prod\"\nprod_webservice_deployment_config = AksWebservice.deploy_configuration()\n\n# Deploy from image\nprod_webservice = Webservice.deploy_from_image(workspace = workspace, \n                                               name = prod_webservice_name,\n                                               image = model_image,\n                                               deployment_config = prod_webservice_deployment_config,\n                                               deployment_target = aks_target)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# Wait for the deployment to complete\nprod_webservice.wait_for_deployment(show_output = True)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["## Query the deployed model in production"],"metadata":{}},{"cell_type":"markdown","source":["#### Evaluate the sample input vector by sending an HTTP request\nQuery the AKS webservice's scoring endpoint by sending an HTTP POST request that includes the input vector. The production AKS deployment may require an authorization token (service key) for queries. Include this key in the HTTP request header."],"metadata":{}},{"cell_type":"code","source":["import requests\nimport json\n\ndef query_endpoint_example(scoring_uri, inputs, service_key=None):\n  headers = {\n    \"Content-Type\": \"application/json\",\n  }\n  if service_key is not None:\n    headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=service_key)\n    \n  print(\"Sending batch prediction request with inputs: {}\".format(inputs))\n  response = requests.post(scoring_uri, data=json.dumps(inputs), headers=headers)\n  preds = json.loads(response.text)\n  print(\"Received response: {}\".format(preds))\n  return preds"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["prod_scoring_uri = prod_webservice.scoring_uri\nprod_service_key = prod_webservice.get_keys()[0] if len(prod_webservice.get_keys()) > 0 else None"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["prod_prediction1 = query_endpoint_example(scoring_uri=prod_scoring_uri, service_key=prod_service_key, inputs=query_input)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":["## Update the production deployment"],"metadata":{}},{"cell_type":"markdown","source":["### Build an Azure Container Image for the new model"],"metadata":{}},{"cell_type":"code","source":["run_id2 = \"<run-id2>\"\nmodel_uri = \"runs:/\" + run_id2 + \"/model\""],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["import mlflow.azureml\n\nmodel_image_updated, azure_model_updated = mlflow.azureml.build_image(model_uri=model_uri, \n                                                                      workspace=workspace,\n                                                                      model_name=\"model-updated\",\n                                                                      image_name=\"model-updated\",\n                                                                      description=\"Sklearn ElasticNet image for predicting diabetes progression\",\n                                                                      synchronous=False)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["model_image_updated.wait_for_creation(show_output=True)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":["### Deploy the new model's image to the AKS cluster\n\nUsing the [`azureml.core.webservice.AksWebservice.update()`](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.akswebservice?view=azure-ml-py#update) function, replace the deployment's existing model image with the new model image."],"metadata":{}},{"cell_type":"code","source":["prod_webservice.update(image=model_image_updated)"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["prod_webservice.wait_for_deployment(show_output = True)"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":["### Query the updated model"],"metadata":{}},{"cell_type":"code","source":["prod_prediction2 = query_endpoint_example(scoring_uri=prod_scoring_uri, service_key=prod_service_key, inputs=query_input)"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":["## Compare the predictions"],"metadata":{}},{"cell_type":"code","source":["print(\"Run ID: {} Prediction: {}\".format(run_id1, prod_prediction1)) \nprint(\"Run ID: {} Prediction: {}\".format(run_id2, prod_prediction2))"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":["## Clean up the deployments"],"metadata":{}},{"cell_type":"markdown","source":["### Terminate the ACI webservice\n\nBecause ACI manages compute resources on your behalf, deleting the \"dev\" ACI webservice will remove all resources associated with the \"dev\" model deployment"],"metadata":{}},{"cell_type":"code","source":["dev_webservice.delete()"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":["### Terminate the AKS webservice\n\nThis terminates the real-time serving webservice running on the specified AKS cluster. It **does not** terminate the AKS cluster."],"metadata":{}},{"cell_type":"code","source":["prod_webservice.delete()"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":["### Remove the AKS cluster from the Azure ML Workspace\n\nIf the cluster was created using the Azure ML SDK (see **Option 1: Create a new AKS cluster**), remove it from the Azure ML Workspace will terminate the cluster, including all of its compute resources and deployments.\n\nIf the cluster was created independently (see **Option 2: Connect to an existing AKS cluster**), it will remain active after removal from the Azure ML Workspace."],"metadata":{}},{"cell_type":"code","source":["aks_target.delete()"],"metadata":{},"outputs":[],"execution_count":63}],"metadata":{"name":"MLflow Quick Start Part 1: Training and Logging","notebookId":2062321517797926},"nbformat":4,"nbformat_minor":0}
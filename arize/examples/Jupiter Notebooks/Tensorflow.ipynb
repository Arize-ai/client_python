{"cells":[{"cell_type":"markdown","source":["# Tutorial Instrumenting Tensorflow Estimators\n\n###### This is based on tensorflow's core [tutorial](https://www.tensorflow.org/tutorials/estimator/premade)"],"metadata":{"colab_type":"text","id":"H1yCdGFW4j_F"}},{"cell_type":"markdown","source":["This tutorial shows you\nhow to solve the Iris classification problem in TensorFlow using Estimators. An Estimator is TensorFlow's high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training. For more details see\n[Estimators](https://www.tensorflow.org/guide/estimator).\n\nNote that in TensorFlow 2.0, the [Keras API](https://www.tensorflow.org/guide/keras) can accomplish many of these same tasks, and is believed to be an easier API to learn. If you are starting fresh, we would recommend you start with Keras. For more information about the available high level APIs in TensorFlow 2.0, see [Standardizing on Keras](https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a)."],"metadata":{"colab_type":"text","id":"R4YZ_ievcY7p"}},{"cell_type":"markdown","source":["## First things first\n\nIn order to get started, you will first import TensorFlow and a number of libraries you will need."],"metadata":{"colab_type":"text","id":"8IFct0yedsTy"}},{"cell_type":"code","source":["!pip install arize"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["import tensorflow as tf\n","\n","import pandas as pd\n","\n","from arize.api import Client"],"metadata":{"colab":{},"colab_type":"code","id":"jPo5bQwndr9P"},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["## The data set\n\nThe sample program in this document builds and tests a model that\nclassifies Iris flowers into three different species based on the size of their\n[sepals](https://en.wikipedia.org/wiki/Sepal) and\n[petals](https://en.wikipedia.org/wiki/Petal).\n\n\nYou will train a model using the Iris data set. The Iris data set contains four features and one\n[label](https://developers.google.com/machine-learning/glossary/#label).\nThe four features identify the following botanical characteristics of\nindividual Iris flowers:\n\n* sepal length\n* sepal width\n* petal length\n* petal width\n\nBased on this information, you can define a few helpful constants for parsing the data:"],"metadata":{"colab_type":"text","id":"c5w4m5gncnGh"}},{"cell_type":"code","source":["CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\nSPECIES = ['Setosa', 'Versicolor', 'Virginica']"],"metadata":{"colab":{},"colab_type":"code","id":"lSyrXp_He_UE"},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["Next, download and parse the Iris data set using Keras and Pandas. Note that you keep distinct datasets for training and testing."],"metadata":{"colab_type":"text","id":"j6mTfIQzfC9w"}},{"cell_type":"code","source":["train_path = tf.keras.utils.get_file(\n    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\ntest_path = tf.keras.utils.get_file(\n    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n\ntrain = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\ntest = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"],"metadata":{"colab":{},"colab_type":"code","id":"PumyCN8VdGGc"},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["You can inspect your data to see that you have four float feature columns and one int32 label."],"metadata":{"colab_type":"text","id":"wHFxNLszhQjz"}},{"cell_type":"code","source":["train.head()"],"metadata":{"colab":{},"colab_type":"code","id":"WOJt-ML4hAwI"},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["For each of the datasets, split out the labels, which the model will be trained to predict."],"metadata":{"colab_type":"text","id":"jQJEYfVvfznP"}},{"cell_type":"code","source":["train_y = train.pop('Species')\ntest_y = test.pop('Species')\n\n# The label column has now been removed from the features.\ntrain.head()"],"metadata":{"colab":{},"colab_type":"code","id":"zM0wz2TueuA6"},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["## Overview of programming with Estimators\n\nNow that you have the data set up, you can define a model using a TensorFlow Estimator. An Estimator is any class derived from `tf.estimator.Estimator`. TensorFlow\nprovides a collection of\n`tf.estimator`\n(for example, `LinearRegressor`) to implement common ML algorithms. Beyond\nthose, you may write your own\n[custom Estimators](https://www.tensorflow.org/guide/custom_estimators).\nWe recommend using pre-made Estimators when just getting started.\n\nTo write a TensorFlow program based on pre-made Estimators, you must perform the\nfollowing tasks:\n\n* Create one or more input functions.\n* Define the model's feature columns.\n* Instantiate an Estimator, specifying the feature columns and various\n  hyperparameters.\n* Call one or more methods on the Estimator object, passing the appropriate\n  input function as the source of the data.\n\nLet's see how those tasks are implemented for Iris classification."],"metadata":{"colab_type":"text","id":"jZx1L_1Vcmxv"}},{"cell_type":"markdown","source":["## Create input functions\n\nYou must create input functions to supply data for training,\nevaluating, and prediction.\n\nAn **input function** is a function that returns a `tf.data.Dataset` object\nwhich outputs the following two-element tuple:\n\n* [`features`](https://developers.google.com/machine-learning/glossary/#feature) - A Python dictionary in which:\n    * Each key is the name of a feature.\n    * Each value is an array containing all of that feature's values.\n* `label` - An array containing the values of the\n  [label](https://developers.google.com/machine-learning/glossary/#label) for\n  every example.\n\nJust to demonstrate the format of the input function, here's a simple\nimplementation:"],"metadata":{"colab_type":"text","id":"2OcguDfBcmmg"}},{"cell_type":"code","source":["def input_evaluation_set():\n    features = {'SepalLength': np.array([6.4, 5.0]),\n                'SepalWidth':  np.array([2.8, 2.3]),\n                'PetalLength': np.array([5.6, 3.3]),\n                'PetalWidth':  np.array([2.2, 1.0])}\n    labels = np.array([2, 1])\n    return features, labels"],"metadata":{"colab":{},"colab_type":"code","id":"nzr5vRr5caGF"},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Your input function may generate the `features` dictionary and `label` list any\nway you like. However, we recommend using TensorFlow's [Dataset API](https://www.tensorflow.org/guide/datasets), which can\nparse all sorts of data.\n\nThe Dataset API can handle a lot of common cases for you. For example,\nusing the Dataset API, you can easily read in records from a large collection\nof files in parallel and join them into a single stream.\n\nTo keep things simple in this example you are going to load the data with\n[pandas](https://pandas.pydata.org/), and build an input pipeline from this\nin-memory data:"],"metadata":{"colab_type":"text","id":"NpXvGjfnjHgY"}},{"cell_type":"code","source":["def input_fn(features, labels, training=True, batch_size=256):\n    \"\"\"An input function for training or evaluating\"\"\"\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n\n    # Shuffle and repeat if you are in training mode.\n    if training:\n        dataset = dataset.shuffle(1000).repeat()\n    \n    return dataset.batch(batch_size)\n"],"metadata":{"colab":{},"colab_type":"code","id":"T20u1anCi8NP"},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["## Define the feature columns\n\nA [**feature column**](https://developers.google.com/machine-learning/glossary/#feature_columns)\nis an object describing how the model should use raw input data from the\nfeatures dictionary. When you build an Estimator model, you pass it a list of\nfeature columns that describes each of the features you want the model to use.\nThe `tf.feature_column` module provides many options for representing data\nto the model.\n\nFor Iris, the 4 raw features are numeric values, so we'll build a list of\nfeature columns to tell the Estimator model to represent each of the four\nfeatures as 32-bit floating-point values. Therefore, the code to create the\nfeature column is:"],"metadata":{"colab_type":"text","id":"xIwcFT4MlZEi"}},{"cell_type":"code","source":["# Feature columns describe how to use the input.\nmy_feature_columns = []\nfor key in train.keys():\n    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"],"metadata":{"colab":{},"colab_type":"code","id":"ZTTriO8FlSML"},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["Feature columns can be far more sophisticated than those we're showing here.  You can read more about Feature Columns in [this guide](https://www.tensorflow.org/guide/feature_columns).\n\nNow that you have the description of how you want the model to represent the raw\nfeatures, you can build the estimator."],"metadata":{"colab_type":"text","id":"jpKkhMoZljco"}},{"cell_type":"markdown","source":["## Instantiate an estimator\n\nThe Iris problem is a classic classification problem. Fortunately, TensorFlow\nprovides several pre-made classifier Estimators, including:\n\n* `tf.estimator.DNNClassifier` for deep models that perform multi-class\n  classification.\n* `tf.estimator.DNNLinearCombinedClassifier` for wide & deep models.\n* `tf.estimator.LinearClassifier` for classifiers based on linear models.\n\nFor the Iris problem, `tf.estimator.DNNClassifier` seems like the best choice.\nHere's how you instantiated this Estimator:"],"metadata":{"colab_type":"text","id":"kuE59XHEl22K"}},{"cell_type":"code","source":["# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=my_feature_columns,\n    # Two hidden layers of 30 and 10 nodes respectively.\n    hidden_units=[30, 10],\n    # The model must choose between 3 classes.\n    n_classes=3)"],"metadata":{"colab":{},"colab_type":"code","id":"qnf4o2V5lcPn"},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["## Train, Evaluate, and Predict\n\nNow that you have an Estimator object, you can call methods to do the following:\n\n* Train the model.\n* Evaluate the trained model.\n* Use the trained model to make predictions."],"metadata":{"colab_type":"text","id":"tzzt5nUpmEe3"}},{"cell_type":"markdown","source":["### Train the model\n\nTrain the model by calling the Estimator's `train` method as follows:"],"metadata":{"colab_type":"text","id":"rnihuLdWmE75"}},{"cell_type":"code","source":["# Train the Model.\nclassifier.train(\n    input_fn=lambda: input_fn(train, train_y, training=True),\n    steps=5000)"],"metadata":{"colab":{},"colab_type":"code","id":"4jW08YtPl1iS"},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["Note that you wrap up your `input_fn` call in a\n[`lambda`](https://docs.python.org/3/tutorial/controlflow.html)\nto capture the arguments while providing an input function that takes no\narguments, as expected by the Estimator. The `steps` argument tells the method\nto stop training after a number of training steps."],"metadata":{"colab_type":"text","id":"ybiTFDmlmes8"}},{"cell_type":"markdown","source":["### Evaluate the trained model\n\nNow that the model has been trained, you can get some statistics on its\nperformance. The following code block evaluates the accuracy of the trained\nmodel on the test data:"],"metadata":{"colab_type":"text","id":"HNvJLH8hmsdf"}},{"cell_type":"code","source":["eval_result = classifier.evaluate(\n    input_fn=lambda: input_fn(test, test_y, training=False))\n\nprint('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"],"metadata":{"colab":{},"colab_type":"code","id":"A169XuO4mKxF"},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["Unlike the call to the `train` method, you did not pass the `steps`\nargument to evaluate. The `input_fn` for eval only yields a single\n[epoch](https://developers.google.com/machine-learning/glossary/#epoch) of data.\n\n\nThe `eval_result` dictionary also contains the `average_loss` (mean loss per sample), the `loss` (mean loss per mini-batch) and the value of the estimator's `global_step` (the number of training iterations it underwent)."],"metadata":{"colab_type":"text","id":"VnPMP5EHph17"}},{"cell_type":"markdown","source":["### Making predictions (inferring) from the trained model\n\nYou now have a trained model that produces good evaluation results.\nYou can now use the trained model to predict the species of an Iris flower\nbased on some unlabeled measurements. As with training and evaluation, you make\npredictions using a single function call:"],"metadata":{"colab_type":"text","id":"ur624ibpp52X"}},{"cell_type":"code","source":["# Instantiating Arize Client\n","\n","arize = Client(account_id=0,api_key='0000',uri='https://dev.arize.com/v1/log')"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["# Generate predictions from the model\nexpected = ['Setosa', 'Versicolor', 'Virginica']\npredict_x = {\n    'SepalLength': [5.1, 5.9, 6.9],\n    'SepalWidth': [3.3, 3.0, 3.1],\n    'PetalLength': [1.7, 4.2, 5.4],\n    'PetalWidth': [0.5, 1.5, 2.1],\n}\ndef input_fn(features, batch_size=256):\n    \"\"\"An input function for prediction.\"\"\"\n    # Convert the inputs to a Dataset without labels.\n    \n    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n  \npredictions = classifier.predict(\n    input_fn=lambda: input_fn(predict_x))"],"metadata":{"colab":{},"colab_type":"code","id":"wltc0jpgng38"},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["The `predict` method returns a Python iterable, yielding a dictionary of\nprediction results for each example. The following code logs predictions to Arize"],"metadata":{"colab_type":"text","id":"JsETKQo0rHvi"}},{"cell_type":"code","source":["import uuid\n\n## Helper fxn\ndef pub_to_arize(model_id, model_version, preds, label_map, arize):\n    for idx, pred in enumerate(preds):\n        labels = {}\n        for key, value in label_map.items():\n            labels[key] = str(value[idx])\n        class_id = pred_dict['class_ids'][0]\n        arize.log(\n          model_id=model_id,\n          model_version=model_version,\n          prediction_id=str(uuid.uuid4()),\n          prediction_value=SPECIES[class_id],\n          labels=labels\n        )\n        \npub_to_arize('tensorflow_tutorial_iris','v0.1',predictions,predict_x,arize)"],"metadata":{"colab":{},"colab_type":"code","id":"Efm4mLzkrCxp"},"outputs":[],"execution_count":35}],"metadata":{"colab":{"name":"premade.ipynb","collapsed_sections":[],"private_outputs":true,"toc_visible":true,"version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"name":"Tensorflow Model Instrumented With Arize","notebookId":547324007707617},"nbformat":4,"nbformat_minor":0}